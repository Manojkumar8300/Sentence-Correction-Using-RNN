{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7FO0jbdLNe",
    "outputId": "8546ff9b-b526-4114-d8d7-d635b0d740af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 9.69MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b2jZuZ3NMD0",
    "outputId": "ee875b84-1929-492f-bc3a-b9ee27d22093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGun8o_nNMHK",
    "outputId": "704d12ec-486b-41dd-9d6a-203a67b3886c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "Downloading fasttext-crawl-300d-2m.zip to /content\n",
      " 99% 1.43G/1.44G [00:06<00:00, 234MB/s]\n",
      "100% 1.44G/1.44G [00:06<00:00, 223MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d yekenot/fasttext-crawl-300d-2m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYvSALCWNMMS",
    "outputId": "b0425e45-661c-44ff-c501-4a0db7de9217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1545551987 bytes (1474 MiB)\n",
      "\n",
      "Extracting archive: fasttext-crawl-300d-2m.zip\n",
      "--\n",
      "Path = fasttext-crawl-300d-2m.zip\n",
      "Type = zip\n",
      "Physical Size = 1545551987\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 1\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       4516698366\n",
      "Compressed: 1545551987\n"
     ]
    }
   ],
   "source": [
    "!7z e fasttext-crawl-300d-2m.zip -o/content -r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L8fjyOdpdLRC"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kq3dgo0eNMPs",
    "outputId": "8f2d3a10-eeaa-4947-a202-2e585dad2dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fasttext Model\n",
      "Done. 2000000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Reading glove vectors in python: https://stackoverflow.com/a/38230349/4084039\n",
    "def fasttextModel(gloveFile):\n",
    "    print (\"Loading Fasttext Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}#for storing word and the corresponding embedding vector for that word\n",
    "    for line in f:\n",
    "        splitLine = line.split()#splitting the line and storing it in a list\n",
    "        word = splitLine[0]#getting the first element and storing it in word\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])#obtaining corresponding vector for that word\n",
    "        model[word] = embedding#storing word as key and embedding vector for that word as value\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "model = fasttextModel('/content/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vwVkeKqQdLTt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#creating DataFrame using preprocessed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "w24_JGmDdLWL",
    "outputId": "89f301cf-b4a8-4c50-a4ee-f6acd2f4fe76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#removing last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FOLd0rnFdLjx"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)#preprocessing source data\n",
    "df['target']=df['target'].apply(preprocess)#preprocessing target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "I2MMzLqQdLms",
    "outputId": "045df63f-8c28-4192-a294-8b3baefb98aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLbB1qx6oja7",
    "outputId": "85d461e5-a2ed-4067-a42c-0334f38ae152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Kn8IMU4LoZSW"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MlN7BR2tdLqK"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]#removing the datapoints where the source sentence length is greater than or equal to 170\n",
    "df=df[df['target'].apply(length)<200]#removing the datapoints where the source sentence length is greater than or equal to 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJiyjBaZfbqD",
    "outputId": "d723e5d1-fd81-4114-a0aa-74ae1ca03777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "sFhX3qniszPG",
    "outputId": "a1b01121-e179-4161-db51-5961ad44c4bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>&lt;start&gt; Hi! How did your week go? Haven't hear...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '<start> ' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + ' <end>'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "boQSuOdzszZf"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)#removing the target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "2IZQxQheF1Ew",
    "outputId": "a15f4675-c000-48f3-8b10-9169425742a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zY_3AB8NF_zb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)#splitting the data in ratio 99:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9dvlVbGGNzp",
    "outputId": "5645e952-cdde-4a16-9b21-af3b21e75b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+' <end>'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "r7unX08JGY7i"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer()#creating tokenziation\n",
    "tknizer_source.fit_on_texts(train['source'].values)#fitting on source data\n",
    "tknizer_target = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')#creating tokenziation\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)#fitting on target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdrwjwt3G1U_",
    "outputId": "467e9786-6705-476b-d143-f7540bc23a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3040\n",
      "3711\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())#target vocab size\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())#source vocab size\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5VU3LonHHh-",
    "outputId": "262bb7d1-515a-4194-a023-35010e42b5af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1440)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['<start>'], tknizer_target.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5tkWnX3kRBqe"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_matrix = np.zeros((vocab_size_source+1, 300))\n",
    "for word, i in tknizer_source.word_index.items():\n",
    "    embedding_vector = model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        encoder_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VSrlIp-WNqaw"
   },
   "outputs": [],
   "source": [
    "decoder_embedding_matrix = np.zeros((vocab_size_target+1, 300))\n",
    "for word, i in tknizer_target.word_index.items():\n",
    "    embedding_vector = model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        decoder_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "HMPfMXTaHQ2T"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True,name=\"embedding_layer_encoder\",weights=[encoder_embedding_matrix],trainable=False)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        \n",
    "        input_embedd                           = self.embedding(input_sequence)\n",
    "        lstm_state_h,lstm_state_c = states[0],states[1]\n",
    "        self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "        return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [np.zeros((batch_size,self.lstm_size)),np.zeros((batch_size,self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "u1ww6VsdHwAA"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\",weights=[decoder_embedding_matrix],trainable=False)\n",
    "        self.gru = tf.keras.layers.GRU(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sequence,initial_states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        \n",
    "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "        '''\n",
    "        target_embedd = self.embedding(input_sequence)\n",
    "        decoder_output,decoder_final_state_h = self.gru(target_embedd, initial_state=[initial_states[0]])\n",
    "        return decoder_output,decoder_final_state_h\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "DhNfgUq-H0SF"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size):\n",
    "        \n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.batch_size=batch_size\n",
    "        self.encoder = Encoder(vocab_size_source+1,300,256,encoder_inputs_length)\n",
    "        self.decoder = Decoder(vocab_size_target+1,300,256,decoder_inputs_length)\n",
    "        self.dense   = tf.keras.layers.Dense(output_vocab_size, activation='softmax')\n",
    "    \n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "        decoder_output,decoder_final_state_h= self.decoder(output,[encoder_h])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "preo2243H7Qh"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.one_hot_encoded = np.zeros((len(self.decoder_out_seq),self.target_len,vocab_size_target),dtype='float32')\n",
    "\n",
    "        for i,sentence in enumerate(self.decoder_out_seq):\n",
    "          for j,word in enumerate(sentence):\n",
    "            self.one_hot_encoded[i,j,word]=1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.one_hot_encoded\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hahhnu0PIgjo",
    "outputId": "f03aa9a9-33c6-4d00-d118-0cb8cfbd5cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 39) (512, 43) (512, 43, 3040)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,39,43)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,39,43)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "S3mtq-6TI62z"
   },
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XToH15GbJCHI"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "lAsyffZXW3er"
   },
   "outputs": [],
   "source": [
    "def changeLearningRate(epoch,lr):\n",
    "    if epoch % 3 == 0:\n",
    "      return lr*(0.5)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "gyOfVkYQWTcg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "import datetime\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "check_point = ModelCheckpoint('best_model_1.h5', monitor='val_loss',  verbose=1, save_best_only=True, mode='min',save_format='tf')\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIx_zCBDJEKu",
    "outputId": "eb152777-9349-4d11-8c57-1c2e54dd529d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 1s 422ms/step - loss: 2.7390 - accuracy: 0.0507 - val_loss: 1.6437 - val_accuracy: 0.0946\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 2.1927 - accuracy: 0.0677 - val_loss: 1.5412 - val_accuracy: 0.0946\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 2.1509 - accuracy: 0.0669 - val_loss: 1.5111 - val_accuracy: 0.0901\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 2.0908 - accuracy: 0.0870 - val_loss: 1.5020 - val_accuracy: 0.1081\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 1s 404ms/step - loss: 2.0622 - accuracy: 0.0852 - val_loss: 1.4941 - val_accuracy: 0.1126\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 1s 406ms/step - loss: 2.0396 - accuracy: 0.0860 - val_loss: 1.4884 - val_accuracy: 0.1216\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 1s 413ms/step - loss: 2.0213 - accuracy: 0.0895 - val_loss: 1.4831 - val_accuracy: 0.1126\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 1s 419ms/step - loss: 2.0094 - accuracy: 0.0920 - val_loss: 1.4778 - val_accuracy: 0.1081\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 1s 428ms/step - loss: 2.0009 - accuracy: 0.0930 - val_loss: 1.4739 - val_accuracy: 0.1081\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 1.9907 - accuracy: 0.0948 - val_loss: 1.4715 - val_accuracy: 0.1081\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 1s 422ms/step - loss: 1.9860 - accuracy: 0.0952 - val_loss: 1.4690 - val_accuracy: 0.1126\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 1.9806 - accuracy: 0.0956 - val_loss: 1.4663 - val_accuracy: 0.1216\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 1s 416ms/step - loss: 1.9759 - accuracy: 0.0973 - val_loss: 1.4653 - val_accuracy: 0.1216\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 1s 416ms/step - loss: 1.9734 - accuracy: 0.0984 - val_loss: 1.4644 - val_accuracy: 0.1171\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9708 - accuracy: 0.0995 - val_loss: 1.4636 - val_accuracy: 0.1216\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 1s 417ms/step - loss: 1.9684 - accuracy: 0.1004 - val_loss: 1.4632 - val_accuracy: 0.1261\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 1.9670 - accuracy: 0.1004 - val_loss: 1.4627 - val_accuracy: 0.1261\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 1s 414ms/step - loss: 1.9657 - accuracy: 0.1011 - val_loss: 1.4623 - val_accuracy: 0.1261\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 1.9645 - accuracy: 0.1015 - val_loss: 1.4621 - val_accuracy: 0.1261\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9638 - accuracy: 0.1017 - val_loss: 1.4619 - val_accuracy: 0.1261\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 1.9632 - accuracy: 0.1015 - val_loss: 1.4617 - val_accuracy: 0.1306\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 1s 413ms/step - loss: 1.9626 - accuracy: 0.1016 - val_loss: 1.4616 - val_accuracy: 0.1306\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9622 - accuracy: 0.1015 - val_loss: 1.4615 - val_accuracy: 0.1306\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 1s 414ms/step - loss: 1.9619 - accuracy: 0.1014 - val_loss: 1.4614 - val_accuracy: 0.1261\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 1s 414ms/step - loss: 1.9616 - accuracy: 0.1016 - val_loss: 1.4614 - val_accuracy: 0.1261\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 1.9614 - accuracy: 0.1017 - val_loss: 1.4613 - val_accuracy: 0.1261\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 1.9613 - accuracy: 0.1018 - val_loss: 1.4613 - val_accuracy: 0.1261\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 1s 424ms/step - loss: 1.9611 - accuracy: 0.1020 - val_loss: 1.4612 - val_accuracy: 0.1261\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 1.9610 - accuracy: 0.1020 - val_loss: 1.4612 - val_accuracy: 0.1261\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 1s 427ms/step - loss: 1.9609 - accuracy: 0.1019 - val_loss: 1.4612 - val_accuracy: 0.1261\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 1s 424ms/step - loss: 1.9609 - accuracy: 0.1019 - val_loss: 1.4612 - val_accuracy: 0.1261\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 1.9608 - accuracy: 0.1020 - val_loss: 1.4612 - val_accuracy: 0.1261\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 1s 425ms/step - loss: 1.9608 - accuracy: 0.1020 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 1s 416ms/step - loss: 1.9607 - accuracy: 0.1020 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 1.9607 - accuracy: 0.1020 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 1s 423ms/step - loss: 1.9607 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 1s 418ms/step - loss: 1.9607 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9607 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 1.9607 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 1s 413ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 1s 412ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 1s 414ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 1s 413ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 1s 415ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 1s 417ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 1s 414ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 1s 416ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 1s 417ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 1s 408ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 1s 421ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 1s 419ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 1s 416ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 1s 407ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 1s 398ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 1s 409ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 2.38418573772492e-09.\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 1.9606 - accuracy: 0.1019 - val_loss: 1.4611 - val_accuracy: 0.1261\n",
      "Epoch 00064: early stopping\n",
      "Model: \"encoder_decoder_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_8 (Encoder)          multiple                  1683968   \n",
      "_________________________________________________________________\n",
      "decoder_8 (Decoder)          multiple                  1340844   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  781280    \n",
      "=================================================================\n",
      "Total params: 3,806,092\n",
      "Trainable params: 1,780,192\n",
      "Non-trainable params: 2,025,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "model  = Encoder_decoder(encoder_inputs_length=39,decoder_inputs_length=43,output_vocab_size=vocab_size_target,batch_size=512)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=[early_stop,lrschedule])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "AK-rVmwTQ1WK"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Iufu14J0JVp7"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "         pass the predicted_out to the dense layer\n",
    "         update the states=[state_h,state_c]\n",
    "         And get the index of the wordcc with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "         Update the input_to_decoder with current predictions\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=39)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['<start>']]])\n",
    "  pred = []\n",
    "  #Here 43 is the max_length of the sequence\n",
    "  for i in range(43):\n",
    "    infe_output, state_h = model.layers[1](cur_vec,[state_h])\n",
    "    infe_output = model.layers[2](infe_output)\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='<end>'):\n",
    "      break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axGMlispS2ex",
    "outputId": "59f78d6d-6f32-4ebf-d49c-7e04d467f6ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899                         <start> Malays are all woods.\n",
       "52      <start> Yeap. I will call you in a while? I'm ...\n",
       "1597              <start> Where? Can I come and find you?\n",
       "847     <start> No need for me to introduce. Someone a...\n",
       "189     <start> Ben asks us to wait at the MRT bus sto...\n",
       "1713                                          <start> Ok.\n",
       "1818               <start> I'll be late. I will call you.\n",
       "591                 <start> 2:30 then. Where will you be?\n",
       "1450    <start> Haha. Hey, MERINA is my name. OK, fema...\n",
       "175          <start> Joey: Hi! Does anybody want to chat?\n",
       "1136                                     <start> No need.\n",
       "786                     <start> Yes. Sure. Evening right?\n",
       "1966                    <start> Oops. Sorry. I am coming.\n",
       "1144    <start> Sigh, what's new man? So this is her n...\n",
       "35      <start> I am working in NTUC Income, selling i...\n",
       "1821    <start> Hey, are you in the LT already? I'm on...\n",
       "1139    <start> You worse than me. Eat more of everyth...\n",
       "1103    <start> Sigh. I still have my friends. Then ne...\n",
       "1287                  <start> Don't know yet, see Andrew.\n",
       "218     <start> No. Suddenly get sick one. Hehe. Your ...\n",
       "Name: target_in, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['target_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nknpSF7BRs1b",
    "outputId": "1cfe4ab8-29dd-4cde-ad7f-1f0002f6c574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output is:  i don't know you you you you\n",
      "The predicted output is:  hey i am you you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  hey i am you you you you you you you you\n",
      "The predicted output is:  you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  hey i am you you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  hey i am you you you you you you you you\n",
      "The predicted output is:  hey i am you you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n",
      "The predicted output is:  i don't know you you you you you you you\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  predicted=predict(i)\n",
    "  print(\"The predicted output is: \",predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnpQs8_gLAQr",
    "outputId": "12f44957-d865-499f-fa77-ffcfd618fbf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgU2eYtdQpUF",
    "outputId": "755b4a3b-7271-41ce-e814-46a31f6c864f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 20 test data sentences is:  0.059428793291298146\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 20 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdJlwYZdRpHL",
    "outputId": "33493256-56b4-46b7-9f69-6e770d80b3eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.4578141331660858,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.16842040746952797,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5623413251903491,\n",
       " 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLVzLq8jX3j7"
   },
   "source": [
    "Character_Level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "b8apihPtV6he",
    "outputId": "c199af47-f157-48b5-b0c4-38b0c0f2d75e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "4           4  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "tXs6gAuwV6js"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "K2ZI7m4WV6mn"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "vNi3h6NvV6o-",
    "outputId": "72a2acf4-ab2b-49e8-a3a7-2fe11b828b05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PScoGleBV6sq",
    "outputId": "d0b810e6-d5a6-427f-f3c7-f31770732a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "kJ9NIzerUMyF"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "zCNdCYXYXBG3"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]\n",
    "df=df[df['target'].apply(length)<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeXF3evYXBKD",
    "outputId": "66ea872e-90f4-4f7d-c4fe-6605c49f7690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "9l_rKDqJUMzo",
    "outputId": "80269a35-08f3-45d7-9db6-a48f88657425"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>\\tHi! How did your week go? Haven't heard from...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '\\t' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + '\\n'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "hcopkrX_UM1J"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "rhxX-xF2UM35",
    "outputId": "fda3f62a-17d6-400b-8267-923af34ea946"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "5NkUjDVOUM7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNbMHZiDVmk8",
    "outputId": "80117215-af39-4f9d-e69b-295affff0904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+'\\n'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "NJ_LVN21TIo3"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_source.fit_on_texts(train['source'].values)\n",
    "tknizer_target = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVIMypotTIqx",
    "outputId": "a6150a69-b4c7-41e6-ef2a-c06d0f113186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVua0TLRTIsf",
    "outputId": "1c8725e4-fd92-40d4-d993-a580ba4b512f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 85)"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['\\t'], tknizer_target.word_index['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "_aZK3PseTIuK"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True,name=\"embedding_layer_encoder\")\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        \n",
    "        input_embedd                           = self.embedding(input_sequence)\n",
    "        lstm_state_h,lstm_state_c = states[0],states[1]\n",
    "        self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "        return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [np.zeros((batch_size,self.lstm_size)),np.zeros((batch_size,self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "rcyCMrG2TIxv"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
    "        self.gru = tf.keras.layers.GRU(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sequence,initial_states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        \n",
    "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "        '''\n",
    "        target_embedd = self.embedding(input_sequence)\n",
    "        decoder_output,decoder_final_state_h = self.gru(target_embedd, initial_state=[initial_states[0]])\n",
    "        return decoder_output,decoder_final_state_h\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "PZh5UkmWTI0f"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size):\n",
    "        \n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.batch_size=batch_size\n",
    "        self.encoder = Encoder(vocab_size_source+1,512,256,encoder_inputs_length)\n",
    "        self.decoder = Decoder(vocab_size_target+1,512,256,decoder_inputs_length)\n",
    "        self.dense   = tf.keras.layers.Dense(output_vocab_size, activation='softmax')\n",
    "    \n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "        decoder_output,decoder_final_state_h= self.decoder(output,[encoder_h])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "Q33T-iHDUYQU"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.one_hot_encoded = np.zeros((len(self.decoder_out_seq),self.target_len,vocab_size_target),dtype='float32')\n",
    "\n",
    "        for i,sentence in enumerate(self.decoder_out_seq):\n",
    "          for j,word in enumerate(sentence):\n",
    "            self.one_hot_encoded[i,j,word]=1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.one_hot_encoded\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVCq83XIUd3l",
    "outputId": "f78f27c5-d603-4983-b5fc-01affdb1c31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 170) (512, 200) (512, 200, 92)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,170,200)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,170,200)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "OfLQfvZI3y9c"
   },
   "outputs": [],
   "source": [
    "def changeLearningRate(epoch,lr):\n",
    "    if epoch % 3 == 0:\n",
    "      return lr*(0.5)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "FZVVEVD43zA5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "import datetime\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "check_point = ModelCheckpoint('best_model_1.h5', monitor='val_loss',  verbose=1, save_best_only=True, mode='min',save_format='tf')\n",
    "lrschedule = LearningRateScheduler(changeLearningRate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk0YayPGUkN7",
    "outputId": "dbfc34f1-dd21-496b-e7ec-3571bdf3ddf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 71s 35s/step - loss: 1.5354 - accuracy: 0.1540 - val_loss: 1.4060 - val_accuracy: 0.1758\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 1.2939 - accuracy: 0.1434 - val_loss: 1.0846 - val_accuracy: 0.2136\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.004999999888241291.\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 1.1312 - accuracy: 0.2131 - val_loss: 1.0058 - val_accuracy: 0.2218\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 1.0474 - accuracy: 0.2404 - val_loss: 0.9583 - val_accuracy: 0.2515\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.9980 - accuracy: 0.2758 - val_loss: 0.9234 - val_accuracy: 0.2804\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0024999999441206455.\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.9639 - accuracy: 0.2975 - val_loss: 0.8932 - val_accuracy: 0.2804\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 0.9391 - accuracy: 0.2971 - val_loss: 0.8745 - val_accuracy: 0.2967\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.9212 - accuracy: 0.3076 - val_loss: 0.8580 - val_accuracy: 0.2990\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0012499999720603228.\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.9079 - accuracy: 0.3118 - val_loss: 0.8472 - val_accuracy: 0.3101\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.8997 - accuracy: 0.3154 - val_loss: 0.8415 - val_accuracy: 0.3101\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 0.8936 - accuracy: 0.3171 - val_loss: 0.8355 - val_accuracy: 0.3153\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0006249999860301614.\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.8876 - accuracy: 0.3226 - val_loss: 0.8304 - val_accuracy: 0.3153\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 2s 502ms/step - loss: 0.8831 - accuracy: 0.3221 - val_loss: 0.8280 - val_accuracy: 0.3160\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.8804 - accuracy: 0.3223 - val_loss: 0.8257 - val_accuracy: 0.3123\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0003124999930150807.\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.8777 - accuracy: 0.3218 - val_loss: 0.8236 - val_accuracy: 0.3123\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.8756 - accuracy: 0.3221 - val_loss: 0.8225 - val_accuracy: 0.3131\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.8744 - accuracy: 0.3219 - val_loss: 0.8215 - val_accuracy: 0.3138\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.00015624999650754035.\n",
      "3/3 [==============================] - 2s 514ms/step - loss: 0.8732 - accuracy: 0.3213 - val_loss: 0.8206 - val_accuracy: 0.3093\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.8722 - accuracy: 0.3205 - val_loss: 0.8201 - val_accuracy: 0.3093\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8716 - accuracy: 0.3208 - val_loss: 0.8196 - val_accuracy: 0.3093\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 7.812499825377017e-05.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8710 - accuracy: 0.3212 - val_loss: 0.8191 - val_accuracy: 0.3086\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.8705 - accuracy: 0.3216 - val_loss: 0.8189 - val_accuracy: 0.3086\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.8702 - accuracy: 0.3222 - val_loss: 0.8186 - val_accuracy: 0.3101\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 3.9062499126885086e-05.\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.8699 - accuracy: 0.3225 - val_loss: 0.8183 - val_accuracy: 0.3108\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.8697 - accuracy: 0.3229 - val_loss: 0.8182 - val_accuracy: 0.3123\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 2s 515ms/step - loss: 0.8695 - accuracy: 0.3231 - val_loss: 0.8181 - val_accuracy: 0.3131\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.9531249563442543e-05.\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.8694 - accuracy: 0.3231 - val_loss: 0.8180 - val_accuracy: 0.3138\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 0.8692 - accuracy: 0.3231 - val_loss: 0.8179 - val_accuracy: 0.3138\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.8692 - accuracy: 0.3232 - val_loss: 0.8178 - val_accuracy: 0.3138\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 9.765624781721272e-06.\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.8691 - accuracy: 0.3232 - val_loss: 0.8178 - val_accuracy: 0.3138\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 2s 506ms/step - loss: 0.8690 - accuracy: 0.3232 - val_loss: 0.8177 - val_accuracy: 0.3138\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.8690 - accuracy: 0.3233 - val_loss: 0.8177 - val_accuracy: 0.3138\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 4.882812390860636e-06.\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.8689 - accuracy: 0.3233 - val_loss: 0.8177 - val_accuracy: 0.3138\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.8689 - accuracy: 0.3234 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.8689 - accuracy: 0.3234 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 2.441406195430318e-06.\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.8689 - accuracy: 0.3234 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.8689 - accuracy: 0.3234 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 1.220703097715159e-06.\n",
      "3/3 [==============================] - 2s 500ms/step - loss: 0.8688 - accuracy: 0.3234 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 2s 501ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 6.103515488575795e-07.\n",
      "3/3 [==============================] - 2s 491ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 2s 510ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 2s 502ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 3.0517577442878974e-07.\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 1.5258788721439487e-07.\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 7.629394360719743e-08.\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 54/100\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 3.814697180359872e-08.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 2s 502ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 56/100\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 2s 508ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 1.907348590179936e-08.\n",
      "3/3 [==============================] - 2s 513ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 58/100\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 2s 499ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 2s 503ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 9.53674295089968e-09.\n",
      "3/3 [==============================] - 2s 509ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 2s 492ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 62/100\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 2s 504ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 4.76837147544984e-09.\n",
      "3/3 [==============================] - 2s 505ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 64/100\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 2.38418573772492e-09.\n",
      "3/3 [==============================] - 2s 498ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 2.38418573772492e-09.\n",
      "3/3 [==============================] - 2s 511ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 66/100\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 2.38418573772492e-09.\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 1.19209286886246e-09.\n",
      "3/3 [==============================] - 2s 507ms/step - loss: 0.8688 - accuracy: 0.3235 - val_loss: 0.8176 - val_accuracy: 0.3138\n",
      "Epoch 00067: early stopping\n",
      "Model: \"encoder_decoder_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_12 (Encoder)         multiple                  840704    \n",
      "_________________________________________________________________\n",
      "decoder_12 (Decoder)         multiple                  638976    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  23644     \n",
      "=================================================================\n",
      "Total params: 1,503,324\n",
      "Trainable params: 1,503,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "model  = Encoder_decoder(encoder_inputs_length=170,decoder_inputs_length=200,output_vocab_size=vocab_size_target,batch_size=512)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps,callbacks=[early_stop,lrschedule])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "uIsxBsjZW79j"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "_JI8L5VjW8Bk"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "         pass the predicted_out to the dense layer\n",
    "         update the states=[state_h,state_c]\n",
    "         And get the index of the wordcc with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "         Update the input_to_decoder with current predictions\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=170)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['\\t']]])\n",
    "  pred = []\n",
    "  #Here 200 is the max_length of the sequence\n",
    "  for i in range(200):\n",
    "    infe_output, state_h = model.layers[1](cur_vec,[state_h])\n",
    "    infe_output = model.layers[2](infe_output)\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='\\n'):\n",
    "      break\n",
    "    translated_sentence = ''.join(pred)\n",
    "\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SYABmhxW8G0",
    "outputId": "981af738-b6d7-4e07-e633-d93602595f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Actual Output is:\n",
      "Hey u called me huh.. Wat's up leh?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "u got cash card w u now.. xin wan to photostat something..\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "I registered 4 it liao... I put class 13 first den class 14...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Wat ü doing tml? Want to go out?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Hey xin ah...R we goin 4 lesson on thurs? Oh fri rite, we r attendin e theory lesson hor...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Yeah...U hav a knack 4 sms-ing me when i'm just step 4rm knockin out.Funny thing is..I actually bother 2 reply..Which usually isn't e case.Nitey then go\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "That's great news. Sorry for the late reply. Left phone in car. Have a goodnight anyways :)\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Is it times new roman font 12 double spacing?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Haha... Sorrie abit blurr liao... Havin too much lesson... So hows life for u?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Yar lor in soc face muz be v thick one...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Nite has end for another day, morning has come in a special way. May you smile like the sunny rays and leaves your worries at the blue blue bay.\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Really how much...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "I'm ok wif anything..and you're e bdåy girl! You decide... Haha...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "eh she gave back the test papers ah. ?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "You study wat course?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "juz fine. opps...Hi...how 'bout u?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "yun, if i cant make it u still going?Jos told me they going mohmd sultan, cover charge 12bucks.coz my dinner is quite late,abt 7 plus.\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "That's how pple learn rite ?\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Leona lei... I anything lor... I'm free... But not too early...\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Not yet. where to buy\n",
      "The Predicted Output is:\n",
      "He ang tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou t\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  print(\"The Actual Output is:\")\n",
    "  print(i)\n",
    "  print(\"The Predicted Output is:\")\n",
    "  pred=predict(i)\n",
    "  print(pred)\n",
    "  print('>'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "yEb2rA9McJnU"
   },
   "outputs": [],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAADuId4cPI_",
    "outputId": "efa6c146-8d8f-49a9-9bae-5d5387cdc698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 1000 test data sentences is:  0.0\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 1000 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JNnXh0VcUR5",
    "outputId": "6b52a132-c1c6-4344-9ba5-ade4a9a6e752"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4H7W6JIrerd4"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "table1=PrettyTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.field_names=['S.NO','MODEL','Average_Bleu_Score']\n",
    "table1.add_row([1,'Simple_ManytoMany_Characterlevel_LSTM_Model',0.32245004727098137])\n",
    "table1.add_row([2,'Simple_ManytoMany_Characterlevel_Bidirectional_LSTM_Model',0.289174940583241])\n",
    "table1.add_row([3,'Simple_ManytoMany_Wordlevel_LSTM_Model',0.3605904404428826])\n",
    "table1.add_row([4,'Simple_ManytoMany_Wordlevel_Bidirectional_LSTM_Model',0.39176783220696243])\n",
    "table1.add_row([5,'Simple_ManytoMany_Wordlevel_LSTM_Model(Fasttext_Embeddings)',0.44321749874121313])\n",
    "table1.add_row([6,'Simple_ManytoMany_Wordlevel_Bidirectional_LSTM_Model(Fasttext_Embeddings)',0.48304227467563887])\n",
    "table1.add_row([7,'Encoder_Decoder_Wordlevel_LSTM',0.17936797861081147])\n",
    "table1.add_row([8,'Encoder_Decoder_Characterlevel_LSTM',0.1318701360495755])\n",
    "table1.add_row([9,'Encoder_Decoder_Attention_Wordlevel_LSTM',0.010138124061366445])\n",
    "table1.add_row([10,'Encoder_Decoder_Attention_Characterlevel_LSTM',0.015891448522335924])\n",
    "table1.add_row([11,'Encoder_Decoder_Attention_Wordlevel_LSTM(Fasttext_Embeddings)',0.03251957333271974])\n",
    "table1.add_row([12,'Monotonic_Attention',0.19536971776642903])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------+----------------------+\n",
      "| S.NO |                                   MODEL                                   |  Average_Bleu_Score  |\n",
      "+------+---------------------------------------------------------------------------+----------------------+\n",
      "|  1   |                Simple_ManytoMany_Characterlevel_LSTM_Model                | 0.32245004727098137  |\n",
      "|  2   |         Simple_ManytoMany_Characterlevel_Bidirectional_LSTM_Model         |  0.289174940583241   |\n",
      "|  3   |                   Simple_ManytoMany_Wordlevel_LSTM_Model                  |  0.3605904404428826  |\n",
      "|  4   |            Simple_ManytoMany_Wordlevel_Bidirectional_LSTM_Model           | 0.39176783220696243  |\n",
      "|  5   |        Simple_ManytoMany_Wordlevel_LSTM_Model(Fasttext_Embeddings)        | 0.44321749874121313  |\n",
      "|  6   | Simple_ManytoMany_Wordlevel_Bidirectional_LSTM_Model(Fasttext_Embeddings) | 0.48304227467563887  |\n",
      "|  7   |                       Encoder_Decoder_Wordlevel_LSTM                      | 0.17936797861081147  |\n",
      "|  8   |                    Encoder_Decoder_Characterlevel_LSTM                    |  0.1318701360495755  |\n",
      "|  9   |                  Encoder_Decoder_Attention_Wordlevel_LSTM                 | 0.010138124061366445 |\n",
      "|  10  |               Encoder_Decoder_Attention_Characterlevel_LSTM               | 0.015891448522335924 |\n",
      "|  11  |       Encoder_Decoder_Attention_Wordlevel_LSTM(Fasttext_Embeddings)       | 0.03251957333271974  |\n",
      "|  12  |                            Monotonic_Attention                            | 0.19536971776642903  |\n",
      "+------+---------------------------------------------------------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "print(table1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Encoder_Decoder_LSTMGRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
