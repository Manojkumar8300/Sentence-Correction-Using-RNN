{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7FO0jbdLNe",
    "outputId": "afa30f62-f7f2-4199-b37a-8ad4c8c3ef7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 89.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_b2jZuZ3NMD0",
    "outputId": "9ebc1a8a-1547-4952-f9d1-deeda16468c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGun8o_nNMHK",
    "outputId": "1710a08e-bb36-4ef1-fdae-38c64749578e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "fasttext-crawl-300d-2m.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d yekenot/fasttext-crawl-300d-2m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYvSALCWNMMS",
    "outputId": "8165765d-35f2-4aa6-fc11-0daacb81a6e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1545551987 bytes (1474 MiB)\n",
      "\n",
      "Extracting archive: fasttext-crawl-300d-2m.zip\n",
      "--\n",
      "Path = fasttext-crawl-300d-2m.zip\n",
      "Type = zip\n",
      "Physical Size = 1545551987\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b\n",
      "Would you like to replace the existing file:\n",
      "  Path:     /content/crawl-300d-2M.vec\n",
      "  Size:     4516698366 bytes (4308 MiB)\n",
      "  Modified: 2019-09-27 20:43:22\n",
      "with the file from archive:\n",
      "  Path:     crawl-300d-2M.vec\n",
      "  Size:     4516698366 bytes (4308 MiB)\n",
      "  Modified: 2019-09-27 20:43:22\n",
      "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "
     ]
    }
   ],
   "source": [
    "!7z e fasttext-crawl-300d-2m.zip -o/content -r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L8fjyOdpdLRC"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kq3dgo0eNMPs",
    "outputId": "ac3b407e-31ac-4af3-9df9-7d2664f43524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fasttext Model\n",
      "Done. 2000000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Reading glove vectors in python: https://stackoverflow.com/a/38230349/4084039\n",
    "def fasttextModel(gloveFile):\n",
    "    print (\"Loading Fasttext Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}#for storing word and the corresponding embedding vector for that word\n",
    "    for line in f:\n",
    "        splitLine = line.split()#splitting the line and storing it in a list\n",
    "        word = splitLine[0]#getting the first element and storing it in word\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])#obtaining corresponding vector for that word\n",
    "        model[word] = embedding#storing word as key and embedding vector for that word as value\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "model = fasttextModel('/content/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vwVkeKqQdLTt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#creating DataFrame using preprocessed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "w24_JGmDdLWL",
    "outputId": "4255a390-4401-4e43-b457-d9b33303c3fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#removing last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FOLd0rnFdLjx"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)#preprocessing source data\n",
    "df['target']=df['target'].apply(preprocess)#preprocessing target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "I2MMzLqQdLms",
    "outputId": "72a27314-5a11-438e-a519-d8c15d3ad9b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLbB1qx6oja7",
    "outputId": "59b3f789-1ce5-4b4c-e482-86eef1769773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Kn8IMU4LoZSW"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MlN7BR2tdLqK"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]#removing the datapoints where the source sentence length is greater than or equal to 170\n",
    "df=df[df['target'].apply(length)<200]#removing the datapoints where the source sentence length is greater than or equal to 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJiyjBaZfbqD",
    "outputId": "7d5608d1-a954-460d-8ceb-5a2d8373c727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sFhX3qniszPG",
    "outputId": "6abfb63a-dfa5-41ac-a4c5-38b53d128cee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>&lt;start&gt; Hi! How did your week go? Haven't hear...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '<start> ' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + ' <end>'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "boQSuOdzszZf"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)#removing the target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "2IZQxQheF1Ew",
    "outputId": "7b010124-8935-487f-c82e-0baf74b12a6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zY_3AB8NF_zb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)#splitting the data in ratio 99:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9dvlVbGGNzp",
    "outputId": "a50bc1dd-3950-4e2f-d72f-30166ecd1962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+' <end>'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "r7unX08JGY7i"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer()#creating tokenziation\n",
    "tknizer_source.fit_on_texts(train['source'].values)#fitting on source data\n",
    "tknizer_target = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')#creating tokenziation\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)#fitting on target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdrwjwt3G1U_",
    "outputId": "a8e8964b-d4ea-4827-c59c-47131fabad0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3037\n",
      "3703\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())#target vocab size\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())#source vocab size\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5VU3LonHHh-",
    "outputId": "0124fbfe-2354-4083-82cc-a70dce33bff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1447)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['<start>'], tknizer_target.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5tkWnX3kRBqe"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_matrix = np.zeros((vocab_size_source+1, 300))\n",
    "for word, i in tknizer_source.word_index.items():\n",
    "    embedding_vector = model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        encoder_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VSrlIp-WNqaw"
   },
   "outputs": [],
   "source": [
    "decoder_embedding_matrix = np.zeros((vocab_size_target+1, 300))\n",
    "for word, i in tknizer_target.word_index.items():\n",
    "    embedding_vector = model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        decoder_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HMPfMXTaHQ2T"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True,name=\"embedding_layer_encoder\",weights=[encoder_embedding_matrix],trainable=False)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        \n",
    "        input_embedd                           = self.embedding(input_sequence)\n",
    "        lstm_state_h,lstm_state_c = states[0],states[1]\n",
    "        self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "        return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [np.zeros((batch_size,self.lstm_size)),np.zeros((batch_size,self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "u1ww6VsdHwAA"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\",weights=[decoder_embedding_matrix],trainable=False)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sequence,initial_states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        \n",
    "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "        '''\n",
    "        target_embedd = self.embedding(input_sequence)\n",
    "        decoder_output,decoder_final_state_h,decoder_final_state_c = self.lstm(target_embedd, initial_state=[initial_states[0], initial_states[1]])\n",
    "        return decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DhNfgUq-H0SF"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size):\n",
    "        \n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.batch_size=batch_size\n",
    "        self.encoder = Encoder(vocab_size_source+1,300,128,encoder_inputs_length)\n",
    "        self.decoder = Decoder(vocab_size_target+1,300,128,decoder_inputs_length)\n",
    "        self.dense   = tf.keras.layers.Dense(output_vocab_size, activation='softmax')\n",
    "    \n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "        decoder_output,decoder_final_state_h,decoder_final_state_c= self.decoder(output,[encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "preo2243H7Qh"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hahhnu0PIgjo",
    "outputId": "be344ea9-08bc-40a3-a184-79ba85beb9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 39) (512, 43) (512, 43)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,39,43)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,39,43)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3mtq-6TI62z",
    "outputId": "738cb806-8d98-4f44-9a5e-953e7be74101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-bdb3352f611a>:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XToH15GbJCHI"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIx_zCBDJEKu",
    "outputId": "5d6cfd85-99ec-4c94-b6b6-e0bca3c71077"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 2.7104 - accuracy: 0.0480 - val_loss: 1.8951 - val_accuracy: 0.0794\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 2.2126 - accuracy: 0.0686 - val_loss: 1.6150 - val_accuracy: 0.0833\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 2.1212 - accuracy: 0.0788 - val_loss: 1.5956 - val_accuracy: 0.0913\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 2.0691 - accuracy: 0.0857 - val_loss: 1.5894 - val_accuracy: 0.1071\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 2.0377 - accuracy: 0.0935 - val_loss: 1.5779 - val_accuracy: 0.0992\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 2.0195 - accuracy: 0.0941 - val_loss: 1.5682 - val_accuracy: 0.1071\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 1.9993 - accuracy: 0.0988 - val_loss: 1.5554 - val_accuracy: 0.1071\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.9775 - accuracy: 0.1074 - val_loss: 1.5461 - val_accuracy: 0.1071\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.9560 - accuracy: 0.1099 - val_loss: 1.5306 - val_accuracy: 0.1071\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.9366 - accuracy: 0.1152 - val_loss: 1.5196 - val_accuracy: 0.1151\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 1.9129 - accuracy: 0.1230 - val_loss: 1.5068 - val_accuracy: 0.1310\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.8937 - accuracy: 0.1250 - val_loss: 1.4931 - val_accuracy: 0.1349\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.8701 - accuracy: 0.1321 - val_loss: 1.4781 - val_accuracy: 0.1429\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 1.8460 - accuracy: 0.1379 - val_loss: 1.4648 - val_accuracy: 0.1508\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.8223 - accuracy: 0.1407 - val_loss: 1.4581 - val_accuracy: 0.1508\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.7985 - accuracy: 0.1443 - val_loss: 1.4456 - val_accuracy: 0.1508\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 1.7770 - accuracy: 0.1483 - val_loss: 1.4381 - val_accuracy: 0.1548\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 1.7559 - accuracy: 0.1503 - val_loss: 1.4315 - val_accuracy: 0.1587\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 1.7326 - accuracy: 0.1544 - val_loss: 1.4174 - val_accuracy: 0.1627\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.7083 - accuracy: 0.1573 - val_loss: 1.4157 - val_accuracy: 0.1706\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 1.6890 - accuracy: 0.1622 - val_loss: 1.4114 - val_accuracy: 0.1746\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.6656 - accuracy: 0.1671 - val_loss: 1.4038 - val_accuracy: 0.1746\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.6411 - accuracy: 0.1704 - val_loss: 1.3938 - val_accuracy: 0.1786\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 1s 158ms/step - loss: 1.6217 - accuracy: 0.1729 - val_loss: 1.3865 - val_accuracy: 0.1865\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.5984 - accuracy: 0.1767 - val_loss: 1.3786 - val_accuracy: 0.1786\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.5754 - accuracy: 0.1793 - val_loss: 1.3770 - val_accuracy: 0.1825\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 1.5548 - accuracy: 0.1835 - val_loss: 1.3704 - val_accuracy: 0.1786\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.5350 - accuracy: 0.1871 - val_loss: 1.3655 - val_accuracy: 0.1825\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.5126 - accuracy: 0.1907 - val_loss: 1.3592 - val_accuracy: 0.2024\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 1s 160ms/step - loss: 1.4912 - accuracy: 0.1950 - val_loss: 1.3575 - val_accuracy: 0.1865\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.4684 - accuracy: 0.1984 - val_loss: 1.3488 - val_accuracy: 0.1905\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 1.4476 - accuracy: 0.2053 - val_loss: 1.3444 - val_accuracy: 0.1984\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.4318 - accuracy: 0.2081 - val_loss: 1.3375 - val_accuracy: 0.2063\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.4081 - accuracy: 0.2126 - val_loss: 1.3277 - val_accuracy: 0.2024\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.3885 - accuracy: 0.2192 - val_loss: 1.3305 - val_accuracy: 0.1984\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 1.3665 - accuracy: 0.2229 - val_loss: 1.3255 - val_accuracy: 0.1984\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 1.3456 - accuracy: 0.2299 - val_loss: 1.3225 - val_accuracy: 0.2063\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 1.3283 - accuracy: 0.2342 - val_loss: 1.3228 - val_accuracy: 0.2063\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 1.3114 - accuracy: 0.2372 - val_loss: 1.3169 - val_accuracy: 0.1984\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 1.2887 - accuracy: 0.2447 - val_loss: 1.3125 - val_accuracy: 0.2103\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  1330848   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  1131048   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  391773    \n",
      "=================================================================\n",
      "Total params: 2,853,669\n",
      "Trainable params: 831,069\n",
      "Non-trainable params: 2,022,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "model  = Encoder_decoder(encoder_inputs_length=39,decoder_inputs_length=43,output_vocab_size=vocab_size_target,batch_size=512)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AK-rVmwTQ1WK"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Iufu14J0JVp7"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "         pass the predicted_out to the dense layer\n",
    "         update the states=[state_h,state_c]\n",
    "         And get the index of the wordcc with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "         Update the input_to_decoder with current predictions\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=39)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['<start>']]])\n",
    "  pred = []\n",
    "  #Here 43 is the max_length of the sequence\n",
    "  for i in range(43):\n",
    "    infe_output, state_h, state_c = model.layers[1](cur_vec,[state_h,state_c])\n",
    "    infe_output = model.layers[2](infe_output)\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='<end>'):\n",
    "      break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axGMlispS2ex",
    "outputId": "b7d84b95-0c8c-4353-fcd1-7f7baeee9ff3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266          <start> PJ. You're a Malay or Chinese, Rin?\n",
       "1469                  <start> Help me look out for tubes.\n",
       "769     <start> My sister and I are eating breakfast. ...\n",
       "1800                 <start> Make that 3! For God's sake!\n",
       "1064                <start> Are you all coming to school?\n",
       "1622      <start> Hee. Ok. See you another time. Big hug.\n",
       "1695    <start> Yes, I thought of it also but scare me...\n",
       "1675    <start> Are you going to send a mail? Tomorrow...\n",
       "1613                                <start> 26th of July.\n",
       "1726                <start> Today mango got 10% discount.\n",
       "821     <start> Don't ask. It is for a stupid reason. ...\n",
       "1227    <start> Okay. But Tuesday I've got dinner. So ...\n",
       "1286    <start> Oh. I see I see. I don't know. Message...\n",
       "785     <start> Haha. I'm going to buy sandals. How to...\n",
       "1107    <start> Ok, thanks. So do you think they would...\n",
       "282     <start> XY and I are meeting for dinner. I'm i...\n",
       "1151                                    <start> Yes. You?\n",
       "1252    <start> Hey hey, you are invited to my place t...\n",
       "1267    <start> Oh my, why is she like that? Is she ve...\n",
       "1323    <start> Thanks for the goodies! They taste rea...\n",
       "Name: target_in, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['target_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nknpSF7BRs1b",
    "outputId": "e936f117-73a4-4bbf-8f2f-ca4cb8565e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted output is:  i am still going to introduce\n",
      "The predicted output is:  i think i will be late\n",
      "The predicted output is:  i am going to go to the place to you\n",
      "The predicted output is:  i will be late\n",
      "The predicted output is:  i am going to chat\n",
      "The predicted output is:  hi care to chat with you\n",
      "The predicted output is:  hey i don't know i will be able to go out for the way\n",
      "The predicted output is:  i don't know i will be able to go out\n",
      "The predicted output is:  ok\n",
      "The predicted output is:  no need to go\n",
      "The predicted output is:  i don't know i will be able to go out for the way i don't know to go to go\n",
      "The predicted output is:  hey i don't know i will be able to go out for the way i think i think i think i will go to go to go to go\n",
      "The predicted output is:  hey i am going to go to watch\n",
      "The predicted output is:  haha ok i don't know i will be able to go out for the place\n",
      "The predicted output is:  hey i don't know i will be late\n",
      "The predicted output is:  i don't know i will be able to go out for the way i am not going to go\n",
      "The predicted output is:  ok\n",
      "The predicted output is:  hey i don't know i don't know i will be late late i am not going to see you\n",
      "The predicted output is:  hey i don't know i will be able to go out for the way i think i think i will be 35\n",
      "The predicted output is:  hey i don't know i will be able to go out for the way\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  predicted=predict(i)\n",
    "  print(\"The predicted output is: \",predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnpQs8_gLAQr",
    "outputId": "6c88f2aa-1969-4bf1-adab-ce08674bb1ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgU2eYtdQpUF",
    "outputId": "0d8d2519-62cf-442d-acde-419fdfd91f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 20 test data sentences is:  0.17936797861081147\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 20 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdJlwYZdRpHL",
    "outputId": "a13e058e-f801-4ed4-e7c4-a62e07c1ece4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.668740304976422,\n",
       " 0,\n",
       " 0.5724063666159062,\n",
       " 0.6051012508914458,\n",
       " 0,\n",
       " 0,\n",
       " 0.4728708045015879,\n",
       " 0.43092381945890607,\n",
       " 0,\n",
       " 0.23927141250362965,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.5980456132683322,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLVzLq8jX3j7"
   },
   "source": [
    "Character_Level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b8apihPtV6he",
    "outputId": "402854d9-05fd-4ee5-cdf2-36cb9c2af6db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "4           4  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tXs6gAuwV6js"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K2ZI7m4WV6mn"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vNi3h6NvV6o-",
    "outputId": "2021d9d8-a0c9-48d5-b611-46dfa53d2d97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PScoGleBV6sq",
    "outputId": "c67ec258-daa4-4bc4-c9ad-2f331f573de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kJ9NIzerUMyF"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zCNdCYXYXBG3"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]\n",
    "df=df[df['target'].apply(length)<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeXF3evYXBKD",
    "outputId": "32d7e5a2-4bd9-4f35-ddaf-c97c6c8e3450"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9l_rKDqJUMzo",
    "outputId": "a2a47656-66bb-4038-de38-b61ecfe2b4d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>\\tHi! How did your week go? Haven't heard from...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '\\t' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + '\\n'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hcopkrX_UM1J"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "rhxX-xF2UM35",
    "outputId": "67e22410-b3e9-46b8-a123-4a7230cec3db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5NkUjDVOUM7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNbMHZiDVmk8",
    "outputId": "0db7b031-e808-435c-e13b-60d289b2eab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+'\\n'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NJ_LVN21TIo3"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_source.fit_on_texts(train['source'].values)\n",
    "tknizer_target = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVIMypotTIqx",
    "outputId": "5f2648ef-c554-4646-b9be-cdf69a29c5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVua0TLRTIsf",
    "outputId": "87062216-2fbc-4a74-c09e-f769d6cd57ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 85)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['\\t'], tknizer_target.word_index['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_aZK3PseTIuK"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\",trainable=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "\n",
    "        input_embedd                           = self.embedding(input_sequence)\n",
    "        lstm_state_h,lstm_state_c = states[0],states[1]\n",
    "        self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "        return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "      \n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [np.zeros((batch_size,self.lstm_size)),np.zeros((batch_size,self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "rcyCMrG2TIxv"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\", trainable=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "    \n",
    "    def call(self,input_sequence,initial_states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        \n",
    "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "        '''\n",
    "        target_embedd = self.embedding(input_sequence)\n",
    "        decoder_output,decoder_final_state_h,decoder_final_state_c = self.lstm(target_embedd, initial_state=[initial_states[0], initial_states[1]])\n",
    "        return decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PZh5UkmWTI0f"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size):\n",
    "        \n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.batch_size=batch_size\n",
    "        self.encoder = Encoder(vocab_size_source+1,300,100,encoder_inputs_length)\n",
    "        self.decoder = Decoder(vocab_size_target+1,300,100,decoder_inputs_length)\n",
    "        self.dense   = tf.keras.layers.Dense(output_vocab_size, activation='softmax')\n",
    "    \n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        input,output = data[0], data[1]\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "        decoder_output,decoder_final_state_h,decoder_final_state_c= self.decoder(output,[encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Q33T-iHDUYQU"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVCq83XIUd3l",
    "outputId": "977608b6-14a8-444a-f594-e9ce0516bd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 170) (512, 200) (512, 200)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,170,200)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,170,200)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk0YayPGUkN7",
    "outputId": "757b97a5-a355-4f4b-9df4-5b1a7aa7c16f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 348ms/step - loss: 1.4916 - accuracy: 0.1226 - val_loss: 1.0614 - val_accuracy: 0.1744\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 1.1787 - accuracy: 0.1884 - val_loss: 1.0143 - val_accuracy: 0.1744\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 1.1388 - accuracy: 0.1823 - val_loss: 0.9851 - val_accuracy: 0.1776\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 332ms/step - loss: 1.1065 - accuracy: 0.1901 - val_loss: 0.9493 - val_accuracy: 0.2036\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 1.0596 - accuracy: 0.2329 - val_loss: 0.9110 - val_accuracy: 0.2466\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 1.0142 - accuracy: 0.2621 - val_loss: 0.8720 - val_accuracy: 0.2620\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.9679 - accuracy: 0.2843 - val_loss: 0.8407 - val_accuracy: 0.2960\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.9318 - accuracy: 0.2999 - val_loss: 0.8208 - val_accuracy: 0.2952\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 320ms/step - loss: 0.9056 - accuracy: 0.3050 - val_loss: 0.8032 - val_accuracy: 0.2952\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.8851 - accuracy: 0.3097 - val_loss: 0.7873 - val_accuracy: 0.3082\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.8671 - accuracy: 0.3281 - val_loss: 0.7721 - val_accuracy: 0.3204\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.8507 - accuracy: 0.3348 - val_loss: 0.7567 - val_accuracy: 0.3236\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.8355 - accuracy: 0.3404 - val_loss: 0.7452 - val_accuracy: 0.3301\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 332ms/step - loss: 0.8214 - accuracy: 0.3482 - val_loss: 0.7328 - val_accuracy: 0.3447\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.8085 - accuracy: 0.3593 - val_loss: 0.7227 - val_accuracy: 0.3439\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.7969 - accuracy: 0.3653 - val_loss: 0.7145 - val_accuracy: 0.3536\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 340ms/step - loss: 0.7862 - accuracy: 0.3718 - val_loss: 0.7059 - val_accuracy: 0.3642\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.7761 - accuracy: 0.3820 - val_loss: 0.6978 - val_accuracy: 0.3715\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.7662 - accuracy: 0.3865 - val_loss: 0.6915 - val_accuracy: 0.3698\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.7572 - accuracy: 0.3901 - val_loss: 0.6842 - val_accuracy: 0.3771\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 327ms/step - loss: 0.7483 - accuracy: 0.3978 - val_loss: 0.6780 - val_accuracy: 0.3788\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.7399 - accuracy: 0.4009 - val_loss: 0.6714 - val_accuracy: 0.3893\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 1s 327ms/step - loss: 0.7318 - accuracy: 0.4066 - val_loss: 0.6652 - val_accuracy: 0.3917\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.7237 - accuracy: 0.4116 - val_loss: 0.6582 - val_accuracy: 0.4006\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 1s 313ms/step - loss: 0.7162 - accuracy: 0.4175 - val_loss: 0.6519 - val_accuracy: 0.3958\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.7083 - accuracy: 0.4243 - val_loss: 0.6453 - val_accuracy: 0.4006\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.7016 - accuracy: 0.4272 - val_loss: 0.6392 - val_accuracy: 0.4039\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.6950 - accuracy: 0.4314 - val_loss: 0.6360 - val_accuracy: 0.4112\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.6886 - accuracy: 0.4386 - val_loss: 0.6301 - val_accuracy: 0.4128\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.6824 - accuracy: 0.4435 - val_loss: 0.6247 - val_accuracy: 0.4193\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.6766 - accuracy: 0.4463 - val_loss: 0.6205 - val_accuracy: 0.4217\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.6715 - accuracy: 0.4504 - val_loss: 0.6148 - val_accuracy: 0.4225\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.6659 - accuracy: 0.4551 - val_loss: 0.6117 - val_accuracy: 0.4274\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 0.6609 - accuracy: 0.4594 - val_loss: 0.6070 - val_accuracy: 0.4242\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.6555 - accuracy: 0.4644 - val_loss: 0.6031 - val_accuracy: 0.4404\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.6507 - accuracy: 0.4677 - val_loss: 0.6006 - val_accuracy: 0.4363\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 0.6464 - accuracy: 0.4707 - val_loss: 0.5968 - val_accuracy: 0.4331\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.6422 - accuracy: 0.4739 - val_loss: 0.5943 - val_accuracy: 0.4371\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.6382 - accuracy: 0.4781 - val_loss: 0.5930 - val_accuracy: 0.4453\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.6342 - accuracy: 0.4797 - val_loss: 0.5899 - val_accuracy: 0.4396\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 329ms/step - loss: 0.6300 - accuracy: 0.4843 - val_loss: 0.5866 - val_accuracy: 0.4485\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.6263 - accuracy: 0.4878 - val_loss: 0.5839 - val_accuracy: 0.4469\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.6221 - accuracy: 0.4913 - val_loss: 0.5809 - val_accuracy: 0.4558\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.6187 - accuracy: 0.4937 - val_loss: 0.5791 - val_accuracy: 0.4590\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.6153 - accuracy: 0.4975 - val_loss: 0.5760 - val_accuracy: 0.4623\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.6122 - accuracy: 0.4993 - val_loss: 0.5754 - val_accuracy: 0.4688\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.6093 - accuracy: 0.5002 - val_loss: 0.5729 - val_accuracy: 0.4639\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.6058 - accuracy: 0.5028 - val_loss: 0.5707 - val_accuracy: 0.4663\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 314ms/step - loss: 0.6032 - accuracy: 0.5049 - val_loss: 0.5684 - val_accuracy: 0.4720\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 1s 321ms/step - loss: 0.6005 - accuracy: 0.5077 - val_loss: 0.5670 - val_accuracy: 0.4761\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 320ms/step - loss: 0.5977 - accuracy: 0.5086 - val_loss: 0.5649 - val_accuracy: 0.4753\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.5949 - accuracy: 0.5115 - val_loss: 0.5635 - val_accuracy: 0.4801\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 1s 316ms/step - loss: 0.5922 - accuracy: 0.5123 - val_loss: 0.5631 - val_accuracy: 0.4745\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 1s 324ms/step - loss: 0.5900 - accuracy: 0.5138 - val_loss: 0.5628 - val_accuracy: 0.4801\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.5870 - accuracy: 0.5169 - val_loss: 0.5593 - val_accuracy: 0.4874\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.5847 - accuracy: 0.5187 - val_loss: 0.5575 - val_accuracy: 0.4834\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.5820 - accuracy: 0.5206 - val_loss: 0.5566 - val_accuracy: 0.4907\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.5801 - accuracy: 0.5225 - val_loss: 0.5552 - val_accuracy: 0.4891\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.5773 - accuracy: 0.5243 - val_loss: 0.5529 - val_accuracy: 0.4915\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.5757 - accuracy: 0.5261 - val_loss: 0.5519 - val_accuracy: 0.4923\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 1s 329ms/step - loss: 0.5735 - accuracy: 0.5274 - val_loss: 0.5520 - val_accuracy: 0.4923\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 1s 324ms/step - loss: 0.5714 - accuracy: 0.5295 - val_loss: 0.5487 - val_accuracy: 0.5077\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 1s 345ms/step - loss: 0.5691 - accuracy: 0.5314 - val_loss: 0.5475 - val_accuracy: 0.4972\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.5673 - accuracy: 0.5326 - val_loss: 0.5464 - val_accuracy: 0.5077\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 1s 329ms/step - loss: 0.5647 - accuracy: 0.5347 - val_loss: 0.5465 - val_accuracy: 0.5061\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.5631 - accuracy: 0.5356 - val_loss: 0.5466 - val_accuracy: 0.5069\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.5615 - accuracy: 0.5368 - val_loss: 0.5437 - val_accuracy: 0.5061\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.5593 - accuracy: 0.5391 - val_loss: 0.5416 - val_accuracy: 0.5118\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.5576 - accuracy: 0.5407 - val_loss: 0.5412 - val_accuracy: 0.5061\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 1s 322ms/step - loss: 0.5554 - accuracy: 0.5417 - val_loss: 0.5389 - val_accuracy: 0.5101\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 1s 319ms/step - loss: 0.5537 - accuracy: 0.5434 - val_loss: 0.5380 - val_accuracy: 0.5109\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 1s 324ms/step - loss: 0.5521 - accuracy: 0.5448 - val_loss: 0.5376 - val_accuracy: 0.5126\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 1s 316ms/step - loss: 0.5501 - accuracy: 0.5470 - val_loss: 0.5368 - val_accuracy: 0.5101\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.5478 - accuracy: 0.5486 - val_loss: 0.5335 - val_accuracy: 0.5134\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 1s 329ms/step - loss: 0.5454 - accuracy: 0.5500 - val_loss: 0.5337 - val_accuracy: 0.5199\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.5442 - accuracy: 0.5516 - val_loss: 0.5329 - val_accuracy: 0.5191\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 1s 334ms/step - loss: 0.5421 - accuracy: 0.5530 - val_loss: 0.5296 - val_accuracy: 0.5223\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.5404 - accuracy: 0.5544 - val_loss: 0.5298 - val_accuracy: 0.5255\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 1s 332ms/step - loss: 0.5391 - accuracy: 0.5552 - val_loss: 0.5290 - val_accuracy: 0.5215\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 1s 339ms/step - loss: 0.5371 - accuracy: 0.5566 - val_loss: 0.5262 - val_accuracy: 0.5280\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.5353 - accuracy: 0.5576 - val_loss: 0.5277 - val_accuracy: 0.5272\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 1s 326ms/step - loss: 0.5341 - accuracy: 0.5593 - val_loss: 0.5241 - val_accuracy: 0.5280\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.5316 - accuracy: 0.5605 - val_loss: 0.5231 - val_accuracy: 0.5361\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.5301 - accuracy: 0.5627 - val_loss: 0.5212 - val_accuracy: 0.5369\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.5279 - accuracy: 0.5633 - val_loss: 0.5198 - val_accuracy: 0.5320\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 0.5268 - accuracy: 0.5645 - val_loss: 0.5211 - val_accuracy: 0.5264\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 0.5249 - accuracy: 0.5658 - val_loss: 0.5199 - val_accuracy: 0.5377\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 1s 344ms/step - loss: 0.5239 - accuracy: 0.5660 - val_loss: 0.5180 - val_accuracy: 0.5385\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 1s 335ms/step - loss: 0.5222 - accuracy: 0.5679 - val_loss: 0.5167 - val_accuracy: 0.5377\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.5206 - accuracy: 0.5696 - val_loss: 0.5181 - val_accuracy: 0.5353\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 1s 336ms/step - loss: 0.5192 - accuracy: 0.5697 - val_loss: 0.5157 - val_accuracy: 0.5353\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 1s 328ms/step - loss: 0.5171 - accuracy: 0.5709 - val_loss: 0.5174 - val_accuracy: 0.5369\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.5162 - accuracy: 0.5722 - val_loss: 0.5170 - val_accuracy: 0.5377\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 0.5142 - accuracy: 0.5745 - val_loss: 0.5153 - val_accuracy: 0.5369\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.5122 - accuracy: 0.5761 - val_loss: 0.5129 - val_accuracy: 0.5418\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.5108 - accuracy: 0.5773 - val_loss: 0.5131 - val_accuracy: 0.5458\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 1s 315ms/step - loss: 0.5086 - accuracy: 0.5787 - val_loss: 0.5143 - val_accuracy: 0.5401\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 1s 332ms/step - loss: 0.5076 - accuracy: 0.5793 - val_loss: 0.5122 - val_accuracy: 0.5483\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 1s 331ms/step - loss: 0.5064 - accuracy: 0.5798 - val_loss: 0.5124 - val_accuracy: 0.5377\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 1s 338ms/step - loss: 0.5043 - accuracy: 0.5827 - val_loss: 0.5106 - val_accuracy: 0.5442\n",
      "Model: \"encoder_decoder_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  191000    \n",
      "_________________________________________________________________\n",
      "decoder_2 (Decoder)          multiple                  188000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  9191      \n",
      "=================================================================\n",
      "Total params: 388,191\n",
      "Trainable params: 388,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "model  = Encoder_decoder(encoder_inputs_length=170,decoder_inputs_length=200,output_vocab_size=vocab_size_target,batch_size=512)\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "uIsxBsjZW79j"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "_JI8L5VjW8Bk"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "         pass the predicted_out to the dense layer\n",
    "         update the states=[state_h,state_c]\n",
    "         And get the index of the wordcc with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "         Update the input_to_decoder with current predictions\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=170)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['\\t']]])\n",
    "  pred = []\n",
    "  #Here 200 is the max_length of the sequence\n",
    "  for i in range(200):\n",
    "    infe_output, state_h, state_c = model.layers[1](cur_vec,[state_h,state_c])\n",
    "    infe_output = model.layers[2](infe_output)\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='\\n'):\n",
    "      break\n",
    "    translated_sentence = ''.join(pred)\n",
    "\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SYABmhxW8G0",
    "outputId": "3d6c08fa-4a9a-4994-e0db-dec30f0a4d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Actual Output is:\n",
      "Y sad sad\n",
      "The Predicted Output is:\n",
      "Yes. I am not to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet yo\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Ding me on ya break fassyole! Blacko from londn\n",
      "The Predicted Output is:\n",
      "Anyone meet you all the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "OH YEAH,AND HAV A GREAT TIME IN NEWQUAY-SEND ME A POSTCARD !1 LOOK AFTER ALL THE GIRLS WHILE IM GONE(U KNOW THE 1IM TALKIN BOUT!)\n",
      "The Predicted Output is:\n",
      "Hell you go to go to meet you all the meet you all the meet you all the meet you all the meet you all the meet you all the meet you all going to go to go to go to go to go to go to go to go to go to g\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Haha... My pleasure lah... Muaks! Enjoy ùrself!\n",
      "The Predicted Output is:\n",
      "Helly are are are going to go to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet yo\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Going to reach already\n",
      "The Predicted Output is:\n",
      "I am not to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you ar\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Hey think tmr i will take bus down. Dont be late ah.... Cya\n",
      "The Predicted Output is:\n",
      "Hey, I don't know what to some already. I am not to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Hmmm b7l_jammer that is L ..Hotmail...Hmmm you add me msn ba...\n",
      "The Predicted Output is:\n",
      "Haha. I am not to meet you all the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Wat buses go to ur sch frm amk huh...\n",
      "The Predicted Output is:\n",
      "What then you want to go to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you ar\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Yupz...Hehe u like den gd lor...Hehe =)\n",
      "The Predicted Output is:\n",
      "Can meet you all the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to me\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Ger v wan to go cheong today? zouk .\n",
      "The Predicted Output is:\n",
      "No. I am not to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet yo\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Haha... Use ur imagination la... Cya tmr...\n",
      "The Predicted Output is:\n",
      "Haha. I am not to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "No nd me to intro someone oso got lotsa admirer liao wat... K la, thurs no changes liao ah...\n",
      "The Predicted Output is:\n",
      "No here to meet you all the meet you all the meet you all the meet you all the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Okay... Ü call us when ü reach... My drivin is at 240 tmr... Ü have 2 lessons? Or only one?\n",
      "The Predicted Output is:\n",
      "Ok, I am not to meet you all the be all the meet you all the meet you all the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Both me n leona will b late. Me going bedok mrt take train down, she stil in office. Mayb u go shop look 4 ideas first. She wan those working bag.\n",
      "The Predicted Output is:\n",
      "I am not to meet you all the meet you all the meet you all the meet you all the meet you all the meet you all the meet you all the meet you all the meet you are to meet you are to meet you are to meet\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "i'll be late...will call u\n",
      "The Predicted Output is:\n",
      "Yes. I am not to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet y\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Me 25 male...Chinese.Malaysian.\n",
      "The Predicted Output is:\n",
      "Then you want to go to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to m\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "HäPpY ChiLDrEN's DäE!! (. ^_ ^.) dun b shy to admit ür a kid coz i believe derez always a childish side to every1...enjoy ürself ñ relive those kiddish dayz!\n",
      "The Predicted Output is:\n",
      "Hi, what the some already. I am not to meet you all the be all the meet you all the meet you all the meet you all the meet you all the meet you all the meet you all going to go to go to go to go to go\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "got how many brand & model?\n",
      "The Predicted Output is:\n",
      "I am not to meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you ar\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "Ok then i settle my own\n",
      "The Predicted Output is:\n",
      "Okay, I don't know what to you are going to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to go to \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output is:\n",
      "What are u doing tonight.Go Geylang eat.\n",
      "The Predicted Output is:\n",
      "What then you are all be at the meet you all the meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet you are to meet yo\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  print(\"The Actual Output is:\")\n",
    "  print(i)\n",
    "  print(\"The Predicted Output is:\")\n",
    "  pred=predict(i)\n",
    "  print(pred)\n",
    "  print('>'*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEb2rA9McJnU",
    "outputId": "fc9a597e-da6c-4431-b58b-e179c0d5f3f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAADuId4cPI_",
    "outputId": "8b2a39c2-c425-44da-855e-726fc74463e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 1000 test data sentences is:  0.1318701360495755\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 1000 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JNnXh0VcUR5",
    "outputId": "f5ac6298-6e59-4f5a-ecd6-3bc5b23b62b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.3742031646082125,\n",
       " 0,\n",
       " 0.3760603093086394,\n",
       " 0.1690308509457033,\n",
       " 0,\n",
       " 0.3742031646082125,\n",
       " 0,\n",
       " 0.4494780405208269,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.447213595499958,\n",
       " 0,\n",
       " 0,\n",
       " 0.447213595499958]"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H7W6JIrerd4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Encoder_Decoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
