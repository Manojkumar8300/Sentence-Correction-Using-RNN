{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7FO0jbdLNe",
    "outputId": "bf2eddcb-a61e-43f7-be69-94f981adc8f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 2.70MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L8fjyOdpdLRC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vwVkeKqQdLTt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "w24_JGmDdLWL",
    "outputId": "8a0b61be-ade0-437c-95fe-248eec59211c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FOLd0rnFdLjx"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "I2MMzLqQdLms",
    "outputId": "bfea5a1e-7cd0-435f-c2a0-68c7f1556202"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLbB1qx6oja7",
    "outputId": "81a32256-deae-400d-cd1e-7584cc5a4c2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kn8IMU4LoZSW"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MlN7BR2tdLqK"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]\n",
    "df=df[df['target'].apply(length)<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJiyjBaZfbqD",
    "outputId": "69db92e6-fcb8-4e68-9c09-050ed38b5fdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "sFhX3qniszPG",
    "outputId": "d65b4c6b-3baa-4709-c810-2ec4e43a4027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>&lt;start&gt; Hi! How did your week go? Haven't hear...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '<start> ' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + ' <end>'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "boQSuOdzszZf"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "2IZQxQheF1Ew",
    "outputId": "2114e2d7-5068-414b-9a55-2c91c15fcfda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zY_3AB8NF_zb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9dvlVbGGNzp",
    "outputId": "24c79c6e-3b69-4fb3-e3b9-25d3e668c428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+' <end>'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r7unX08JGY7i"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer()\n",
    "tknizer_source.fit_on_texts(train['source'].values)\n",
    "tknizer_target = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdrwjwt3G1U_",
    "outputId": "1de2424a-cffb-4190-cfb7-9df1e8f7ef26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3039\n",
      "3708\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5VU3LonHHh-",
    "outputId": "fb142a44-1218-4a67-afc8-0405f44aac09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1447)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['<start>'], tknizer_target.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HMPfMXTaHQ2T"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer oupulstm_state_h,lstm_state_ct to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      \n",
    "      input_embedd                           = self.embedding(input_sequence)\n",
    "      lstm_state_h,lstm_state_c= states[0],states[1]\n",
    "      self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "      return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [tf.zeros((batch_size,self.lstm_size)),tf.zeros((batch_size,self.lstm_size))]\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "u1ww6VsdHwAA"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "    super().__init__()\n",
    "    self.scoring_function=scoring_function\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "\n",
    "    if self.scoring_function=='dot':\n",
    "      # Intialize variables needed for Dot score function here\n",
    "      pass\n",
    "    if self.scoring_function == 'general':\n",
    "      # Intialize variables needed for General score function here\n",
    "      self.weight=tf.keras.layers.Dense(att_units)\n",
    "    elif self.scoring_function == 'concat':\n",
    "      # Intialize variables needed for Concat score function here\n",
    "      self.weight1=tf.keras.layers.Dense(att_units)\n",
    "      self.weight2=tf.keras.layers.Dense(att_units)\n",
    "      self.v=tf.keras.layers.Dense(1)\n",
    "  \n",
    "  \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    \n",
    "    if self.scoring_function == 'dot':\n",
    "        # Implement Dot score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=2)\n",
    "        value=tf.matmul(encoder_output,decoder_hidden_state)\n",
    "    elif self.scoring_function == 'general':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=2)\n",
    "        value=tf.matmul(self.weight(encoder_output),decoder_hidden_state)\n",
    "    elif self.scoring_function == 'concat':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=1)\n",
    "        value=self.v(tf.nn.tanh(self.weight1(decoder_hidden_state)+self.weight2(encoder_output)))\n",
    "    attention_weights=tf.nn.softmax(value,axis=1)\n",
    "    context_vector=attention_weights*encoder_output\n",
    "    return tf.reduce_sum(context_vector,axis=1),attention_weights\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DhNfgUq-H0SF"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length \n",
    "      self.dec_units = dec_units\n",
    "      self.score_fun = score_fun\n",
    "      self.att_units = att_units\n",
    "      # we are using embedding_matrix and not training the embedding layer\n",
    "      self.embedding = tf.keras.layers.Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\", trainable=True)\n",
    "      self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
    "      self.dense = tf.keras.layers.Dense(self.tar_vocab_size)\n",
    "      self.attention = Attention(self.score_fun,self.att_units)\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    output = self.embedding(input_to_decoder)\n",
    "    context_vector,attention_weights = self.attention(state_h,encoder_output)\n",
    "    context_vector1 = tf.expand_dims(context_vector,1)\n",
    "    concat = tf.concat([output,context_vector1],axis=-1)\n",
    "    decoder_output,state_h,state_c = self.lstm(concat,initial_state=[state_h,state_c])\n",
    "    final_output = self.dense(decoder_output)\n",
    "    final_output = tf.reshape(final_output,(-1,final_output.shape[2]))\n",
    "    return final_output,state_h,state_c,attention_weights,context_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "97Rryo9n8VRH"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super(Decoder,self).__init__()\n",
    "      self.vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units=dec_units\n",
    "      self.att_units=att_units\n",
    "      self.score_fun=score_fun\n",
    "      self.onestepdecoder=One_Step_Decoder(self.vocab_size,self.embedding_dim,self.input_length,self.dec_units ,self.score_fun ,self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        all_outputs=tf.TensorArray(tf.float32,size=input_to_decoder.shape[1])\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        #Iterate till the length of the decoder input\n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            output,state_h,state_c,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
    "\n",
    "            # Store the output in tensorarray\n",
    "            all_outputs=all_outputs.write(timestep,output)\n",
    "        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        # Return the tensor array\n",
    "        return all_outputs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3Up5Qc-O8ZNa"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size,score_fun):\n",
    "    #Intialize objects from encoder decoder\n",
    "    super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "    self.batch_size=batch_size\n",
    "    self.encoder = Encoder(vocab_size_source+1,300,128,encoder_inputs_length)\n",
    "    self.decoder = Decoder(vocab_size_target+1,300,decoder_inputs_length,128,score_fun,128)\n",
    "    \n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    input,output = data[0], data[1]\n",
    "    initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "    encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "    decoder_output= self.decoder(output, encoder_output, encoder_h, encoder_c)\n",
    "    return decoder_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2UaWKKXL8cNb"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
    "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "preo2243H7Qh"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hahhnu0PIgjo",
    "outputId": "511888c0-c0b3-449e-f8dc-2fee4d4bb1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 39) (512, 43) (512, 43)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,39,43)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,39,43)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3mtq-6TI62z",
    "outputId": "6f50dbc4-a846-439b-afab-20acaf44c6ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-bdb3352f611a>:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XToH15GbJCHI"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MIx_zCBDJEKu",
    "outputId": "87be0fe6-f488-4377-8e8d-5a9e1a96ddc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.7480 - val_loss: 2.1525\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.3138 - val_loss: 1.6742\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.1388 - val_loss: 1.6743\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.1127 - val_loss: 1.6691\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0877 - val_loss: 1.6687\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 3s 997ms/step - loss: 2.0770 - val_loss: 1.6678\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0696 - val_loss: 1.6660\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0689 - val_loss: 1.6673\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0653 - val_loss: 1.6610\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0611 - val_loss: 1.6525\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0554 - val_loss: 1.6501\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0531 - val_loss: 1.6501\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0526 - val_loss: 1.6506\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0467 - val_loss: 1.6473\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 3s 995ms/step - loss: 2.0405 - val_loss: 1.6434\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0412 - val_loss: 1.6406\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0362 - val_loss: 1.6326\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0259 - val_loss: 1.6242\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0170 - val_loss: 1.6191\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.0039 - val_loss: 1.6164\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9921 - val_loss: 1.6097\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9881 - val_loss: 1.6019\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9725 - val_loss: 1.5966\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9652 - val_loss: 1.5874\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9470 - val_loss: 1.5802\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9339 - val_loss: 1.5761\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 3s 994ms/step - loss: 1.9240 - val_loss: 1.5676\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9093 - val_loss: 1.5616\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8943 - val_loss: 1.5545\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8795 - val_loss: 1.5468\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8640 - val_loss: 1.5409\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8551 - val_loss: 1.5359\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8404 - val_loss: 1.5304\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8232 - val_loss: 1.5223\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.8106 - val_loss: 1.5202\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7934 - val_loss: 1.5148\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7828 - val_loss: 1.5105\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7660 - val_loss: 1.5016\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7475 - val_loss: 1.5015\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7397 - val_loss: 1.4986\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7245 - val_loss: 1.4938\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7091 - val_loss: 1.4948\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6946 - val_loss: 1.4843\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6806 - val_loss: 1.4825\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6709 - val_loss: 1.4828\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6554 - val_loss: 1.4794\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6412 - val_loss: 1.4796\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6257 - val_loss: 1.4754\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6143 - val_loss: 1.4739\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6050 - val_loss: 1.4752\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5926 - val_loss: 1.4792\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5776 - val_loss: 1.4750\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5657 - val_loss: 1.4812\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5504 - val_loss: 1.4821\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5394 - val_loss: 1.4719\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5263 - val_loss: 1.4826\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5172 - val_loss: 1.4778\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5080 - val_loss: 1.4764\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4930 - val_loss: 1.4788\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4879 - val_loss: 1.4797\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.4751 - val_loss: 1.4854\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4650"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-077b737c7789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1226\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;34m\"\"\"Runs an evaluation execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1316\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1283\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1284\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1285\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2831\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2833\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3606\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3607\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3608\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3610\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m     \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     self.compiled_loss(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-ffdeee911166>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c3bfc02267d9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Call onestepdecoder for each token in decoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monestepdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Store the output in tensorarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-252336fceb78>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, state_h, state_c)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_vector1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4795\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tensordot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4797\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4798\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4799\u001b[0m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;31m# cast to preferred_dtype first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         ret = conversion_func(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
    "model  = encoder_decoder(encoder_inputs_length=39,decoder_inputs_length=43,output_vocab_size=vocab_size_target,batch_size=512,score_fun=\"concat\")\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AK-rVmwTQ1WK"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Iufu14J0JVp7"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=39)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['<start>']]])\n",
    "  pred = []\n",
    "  for i in range(43):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(cur_vec,en_outputs,state_h,state_c)\n",
    "    cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='<end>'):\n",
    "      break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nknpSF7BRs1b",
    "outputId": "91fb70c6-f84b-45c9-d015-27d0705a9443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Actual Output:\n",
      "Helo k.reen n p.ple.hw r u?care 2 chat any1?\n",
      "The predicted output is: \n",
      "hi care to chat\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Haha... Not accurate right....\n",
      "The predicted output is: \n",
      "ok\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "oh cz1102? ya dat was me.i offline liao.im in clubrm ma\n",
      "The predicted output is: \n",
      "hey are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "eh dont think so... Library can print?\n",
      "The predicted output is: \n",
      "hey i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Sigh wat's new man... So tis is her no wat bf?\n",
      "The predicted output is: \n",
      "hey i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Hey its meijun's bday today so we share n treat her to crepes k.\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Sen, u male o female\n",
      "The predicted output is: \n",
      "ok\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Yupz... Okie... But u r always e bz one...Haha... K la, guess i'll cya at our class bbq den...\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "So boring, sending sms\n",
      "The predicted output is: \n",
      "hi care to chat\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Me very hungry... Ü come down faster lei...\n",
      "The predicted output is: \n",
      "hey i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "i am dying of boredom at home!i need a job!arghz!any recommendations?\n",
      "The predicted output is: \n",
      "hey are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Pick me up at 6... Same place, car park there...\n",
      "The predicted output is: \n",
      "hey are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Hey... R u free tmr? Wan to go for a movie? Cöz me not workin tmr... =5\n",
      "The predicted output is: \n",
      "hey i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Hey dont save seat for rebecca... She's not going for lect.\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Thanx.thats wat i aim to do.Lolx...Now u can't use me...Too bad...I need to sleep now.No matter how much i wanna talk abt e sun moon n stars.Thanx 4\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Yun ah...Driving nid 2 bring é advance theory bk nt?\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Halo cy càrè for ä intro\n",
      "The predicted output is: \n",
      "hi care to chat\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Oh, hope ü have a good trip. Dun worry, i ll try hard not to miss you. Haha....  :-p\n",
      "The predicted output is: \n",
      "i am\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Rain,u busy nw? Y so quiet? Speak up.\n",
      "The predicted output is: \n",
      "hey are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual Output:\n",
      "Hey... You have driving lessons this weekend?\n",
      "The predicted output is: \n",
      "hey are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  print(\"The Actual Output:\")\n",
    "  print(i)\n",
    "  predicted=predict(i)\n",
    "  print(\"The predicted output is: \")\n",
    "  print(predicted)\n",
    "  print('>'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnpQs8_gLAQr",
    "outputId": "a4058e56-4cf6-4f24-f53d-658da5fc1c80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgU2eYtdQpUF",
    "outputId": "6cf68fe3-e1f6-4f1a-a69c-ee3eefcb5f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 20 test data sentences is:  0.010138124061366445\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 20 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdJlwYZdRpHL",
    "outputId": "2dfcce2b-ad04-415e-bd7c-2c0c47324991"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2025894847023147,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1.9007028956229227e-06,\n",
       " 0,\n",
       " 0,\n",
       " 0.00017109582211857066,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLVzLq8jX3j7"
   },
   "source": [
    "Character_Level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "b8apihPtV6he",
    "outputId": "3167481d-4442-4070-807c-119099356658"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "4           4  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tXs6gAuwV6js"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K2ZI7m4WV6mn"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "vNi3h6NvV6o-",
    "outputId": "d2757bf6-4416-4bfd-c85b-938b6480a7ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PScoGleBV6sq",
    "outputId": "47bb9b49-98b2-46b9-bc7a-d8e527e6a762"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kJ9NIzerUMyF"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zCNdCYXYXBG3"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]\n",
    "df=df[df['target'].apply(length)<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeXF3evYXBKD",
    "outputId": "09b17714-d100-4748-8528-9bc661e2204e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "9l_rKDqJUMzo",
    "outputId": "9f4b3a5e-839b-4098-8a74-1e7958285df1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>\\tHi! How did your week go? Haven't heard from...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '\\t' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + '\\n'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hcopkrX_UM1J"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "rhxX-xF2UM35",
    "outputId": "b891f3bc-e870-4a0d-cafc-cad69d2a48d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>\\tDo you want me to reserve seat for you or not?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>\\tYeap. You reaching? We ordered some Durian p...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>\\tThey become more expensive already. Mine is ...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>\\tI'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5NkUjDVOUM7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNbMHZiDVmk8",
    "outputId": "53814a9c-8201-484a-8daa-845818f467c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+'\\n'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NJ_LVN21TIo3"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_source.fit_on_texts(train['source'].values)\n",
    "tknizer_target = Tokenizer(filters=None,char_level=True,lower=False)\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVIMypotTIqx",
    "outputId": "35a08f25-e8ac-41dc-e5cd-bdf876ce5cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVua0TLRTIsf",
    "outputId": "fcfd668b-36cc-4ed7-e2e4-7ebbcf84bca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 85)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['\\t'], tknizer_target.word_index['\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_aZK3PseTIuK"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer oupulstm_state_h,lstm_state_ct to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      \n",
    "      input_embedd                           = self.embedding(input_sequence)\n",
    "      lstm_state_h,lstm_state_c= states[0],states[1]\n",
    "      self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "      return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [tf.zeros((batch_size,self.lstm_size)),tf.zeros((batch_size,self.lstm_size))]\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PZh5UkmWTI0f"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "  '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "  '''\n",
    "  def __init__(self,scoring_function, att_units):\n",
    "    super().__init__()\n",
    "    self.scoring_function=scoring_function\n",
    "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "\n",
    "    if self.scoring_function=='dot':\n",
    "      # Intialize variables needed for Dot score function here\n",
    "      pass\n",
    "    if self.scoring_function == 'general':\n",
    "      # Intialize variables needed for General score function here\n",
    "      self.weight=tf.keras.layers.Dense(att_units)\n",
    "    elif self.scoring_function == 'concat':\n",
    "      # Intialize variables needed for Concat score function here\n",
    "      self.weight1=tf.keras.layers.Dense(att_units)\n",
    "      self.weight2=tf.keras.layers.Dense(att_units)\n",
    "      self.v=tf.keras.layers.Dense(1)\n",
    "  \n",
    "  \n",
    "  def call(self,decoder_hidden_state,encoder_output):\n",
    "    '''\n",
    "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        Function returns context vector and attention weights(softmax - scores)\n",
    "    '''\n",
    "    \n",
    "    if self.scoring_function == 'dot':\n",
    "        # Implement Dot score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=2)\n",
    "        value=tf.matmul(encoder_output,decoder_hidden_state)\n",
    "    elif self.scoring_function == 'general':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=2)\n",
    "        value=tf.matmul(self.weight(encoder_output),decoder_hidden_state)\n",
    "    elif self.scoring_function == 'concat':\n",
    "        # Implement General score function here\n",
    "        decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=1)\n",
    "        value=self.v(tf.nn.tanh(self.weight1(decoder_hidden_state)+self.weight2(encoder_output)))\n",
    "    attention_weights=tf.nn.softmax(value,axis=1)\n",
    "    context_vector=attention_weights*encoder_output\n",
    "    return tf.reduce_sum(context_vector,axis=1),attention_weights\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZqLu3nywHmyM"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length \n",
    "      self.dec_units = dec_units\n",
    "      self.score_fun = score_fun\n",
    "      self.att_units = att_units\n",
    "      # we are using embedding_matrix and not training the embedding layer\n",
    "      self.embedding = tf.keras.layers.Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\", trainable=True)\n",
    "      self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
    "      self.dense = tf.keras.layers.Dense(self.tar_vocab_size)\n",
    "      self.attention = Attention(self.score_fun,self.att_units)\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    '''\n",
    "        One step decoder mechanisim step by step:\n",
    "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "      C. Concat the context vector with the step A output\n",
    "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "    '''\n",
    "    output = self.embedding(input_to_decoder)\n",
    "    context_vector,attention_weights = self.attention(state_h,encoder_output)\n",
    "    context_vector1 = tf.expand_dims(context_vector,1)\n",
    "    concat = tf.concat([output,context_vector1],axis=-1)\n",
    "    decoder_output,state_h,state_c = self.lstm(concat,initial_state=[state_h,state_c])\n",
    "    final_output = self.dense(decoder_output)\n",
    "    final_output = tf.reshape(final_output,(-1,final_output.shape[2]))\n",
    "    return final_output,state_h,state_c,attention_weights,context_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qjOxZZKPHmz1"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super(Decoder,self).__init__()\n",
    "      self.vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units=dec_units\n",
    "      self.att_units=att_units\n",
    "      self.score_fun=score_fun\n",
    "      self.onestepdecoder=One_Step_Decoder(self.vocab_size,self.embedding_dim,self.input_length,self.dec_units ,self.score_fun ,self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        all_outputs=tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1])\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        #Iterate till the length of the decoder input\n",
    "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            output,state_h,state_c,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state)\n",
    "\n",
    "            # Store the output in tensorarray\n",
    "            all_outputs=all_outputs.write(timestep,output)\n",
    "        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        # Return the tensor array\n",
    "        return all_outputs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "fp9nhmGsHm1q"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size,score_fun):\n",
    "    #Intialize objects from encoder decoder\n",
    "    super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "    self.batch_size=batch_size\n",
    "    self.encoder = Encoder(vocab_size_source+1,300,100,encoder_inputs_length)\n",
    "    self.decoder = Decoder(vocab_size_target+1,300,decoder_inputs_length,100,score_fun,100)\n",
    "    \n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    input,output = data[0], data[1]\n",
    "    initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "    encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "    decoder_output= self.decoder(output, encoder_output, encoder_h, encoder_c)\n",
    "    return decoder_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ygx_9YW9Hm2-"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
    "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Q33T-iHDUYQU"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVCq83XIUd3l",
    "outputId": "d7c8a356-3bfa-472e-ef67-9a874e9e0b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 170) (512, 200) (512, 200)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,170,200)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,170,200)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=512)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xk0YayPGUkN7",
    "outputId": "32381c27-8887-48cf-9695-9459207f71bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 16s 4s/step - loss: 1.4901 - val_loss: 0.9755\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.1887 - val_loss: 0.9433\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.1406 - val_loss: 0.9031\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.0853 - val_loss: 0.8608\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 8s 3s/step - loss: 1.0354 - val_loss: 0.8301\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9966 - val_loss: 0.8033\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9663 - val_loss: 0.7835\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9445 - val_loss: 0.7679\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9295 - val_loss: 0.7558\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9178 - val_loss: 0.7471\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9097 - val_loss: 0.7412\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9030 - val_loss: 0.7366\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8976 - val_loss: 0.7325\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8939 - val_loss: 0.7282\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8906 - val_loss: 0.7239\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8881 - val_loss: 0.7207\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8860 - val_loss: 0.7189\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8842 - val_loss: 0.7174\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8826 - val_loss: 0.7158\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8811 - val_loss: 0.7151\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8800 - val_loss: 0.7137\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8787 - val_loss: 0.7135\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8778 - val_loss: 0.7124\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8767 - val_loss: 0.7114\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8758 - val_loss: 0.7103\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8748 - val_loss: 0.7095\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8737 - val_loss: 0.7091\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8729 - val_loss: 0.7087\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8719 - val_loss: 0.7079\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8708 - val_loss: 0.7069\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8701 - val_loss: 0.7063\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8694 - val_loss: 0.7051\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8683 - val_loss: 0.7045\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8678 - val_loss: 0.7056\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8677 - val_loss: 0.7040\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8669 - val_loss: 0.7039\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8657 - val_loss: 0.7024\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8650 - val_loss: 0.7021\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8641 - val_loss: 0.7024\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8634 - val_loss: 0.7009\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8625 - val_loss: 0.6999\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8614 - val_loss: 0.6996\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8608 - val_loss: 0.7001\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8603 - val_loss: 0.6991\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8590 - val_loss: 0.6976\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8581 - val_loss: 0.6970\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8571 - val_loss: 0.6978\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8567 - val_loss: 0.6974\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8557 - val_loss: 0.6963\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8547 - val_loss: 0.6966\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8538 - val_loss: 0.6948\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8528 - val_loss: 0.6954\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8519 - val_loss: 0.6943\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8514 - val_loss: 0.6932\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8500 - val_loss: 0.6941\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8489 - val_loss: 0.6918\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8479 - val_loss: 0.6905\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8462 - val_loss: 0.6910\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8456 - val_loss: 0.6909\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8443 - val_loss: 0.6887\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8432 - val_loss: 0.6889\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8418 - val_loss: 0.6898\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8406 - val_loss: 0.6883\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8395 - val_loss: 0.6883\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8382 - val_loss: 0.6871\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8366 - val_loss: 0.6870\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8359 - val_loss: 0.6870\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8355 - val_loss: 0.6862\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8339 - val_loss: 0.6865\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8329 - val_loss: 0.6881\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8314 - val_loss: 0.6845\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8301 - val_loss: 0.6841\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8285 - val_loss: 0.6841\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8278 - val_loss: 0.6835\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8263 - val_loss: 0.6844\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8247 - val_loss: 0.6831\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8237 - val_loss: 0.6829\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8227 - val_loss: 0.6828\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8223 - val_loss: 0.6830\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8211 - val_loss: 0.6822\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8194 - val_loss: 0.6826\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8181 - val_loss: 0.6818\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8166 - val_loss: 0.6826\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8159 - val_loss: 0.6815\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8145 - val_loss: 0.6816\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8129 - val_loss: 0.6804\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8125 - val_loss: 0.6810\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8112 - val_loss: 0.6810\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8110 - val_loss: 0.6800\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8086 - val_loss: 0.6817\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8079 - val_loss: 0.6784\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8066 - val_loss: 0.6810\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8053 - val_loss: 0.6817\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8047 - val_loss: 0.6798\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8034 - val_loss: 0.6792\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8022 - val_loss: 0.6800\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.8015 - val_loss: 0.6783\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.7999 - val_loss: 0.6782\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.7985 - val_loss: 0.6777\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.7968 - val_loss: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e1ef9450>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
    "model  = encoder_decoder(encoder_inputs_length=170,decoder_inputs_length=200,output_vocab_size=vocab_size_target,batch_size=512,score_fun=\"concat\")\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=100, validation_data=test_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "uIsxBsjZW79j"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model7.h5\")\n",
    "batch_size=512\n",
    "units=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_JI8L5VjW8Bk"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=170)\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['\\t']]])\n",
    "  pred = []\n",
    "  #Here 20 is the max_length of the sequence\n",
    "  for i in range(200):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(cur_vec,en_outputs,state_h,state_c)\n",
    "    cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='\\n'):\n",
    "      break\n",
    "    translated_sentence = ''.join(pred)\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SYABmhxW8G0",
    "outputId": "b86496cc-d063-4df3-d93f-044a1ff3574b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello h r u\n",
      "Youcht t t t yot thathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathatha\n",
      "We saw fiona xie at taka... Haha...\n",
      "Yout t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "if u are in town. I take taxi myself.\n",
      "His at athat t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "U free tmr? Wana watch finding nemo...\n",
      "Whathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathathath\n",
      "Ü c da glasses nice n cn sit properly on è nose... It feels comfy then buy lor... Wat haf ü bot oredi?\n",
      "I at at t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "HAI!Nice 2 meet u! :- >im gal 18 chinese. U?hmm... <: > my hp num is 0165460953 more cheaper sms by phone!\n",
      "His. 30265306306:300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300163090963096300\n",
      "Haha. Sure anot? Oni a bit. Haha. Tats bc u go thailand mahz. Mine not more thn 15.\n",
      "Houthathath t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "Ok...I wait 4 u outside toilet...Raffles city rite?\n",
      "Hathathath t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "Ok then when i reach i go collect ticket first. Now i nothing to do watch tv.\n",
      "I t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "Call me\n",
      "Hi, bou t t t t yot t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t t t t th yot t \n",
      "Wow rot at home.... Ha ha..... Raining ma good weather to sleep.... Ha ha.....\n",
      "Whathatht t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "Get smth lo...Den nvm ba...Heh.\n",
      "I t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "i think what i hav told so far is no big secret...\n",
      "I t it it t it t it t t t t t t t t t t t t t t t t t t t t t t t t it t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "Ay i exam period ah...seow ah. Dyin--\n",
      "His ay ay ay t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "Help me record e guess3 ok? E back part...\n",
      "Hoout t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "how u noe there's no better ans ..\n",
      "Houthathath t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "It's ok.. Happy studying..\n",
      "Hing ay t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "we just come out from turf club. both of is made $800 each.\n",
      "I t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n",
      "Just left ofc...\n",
      "Yoffffffff t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t\n",
      "Tomw dinner at 7.30 either jap food or ron suggest sizzler. Wat u prefer?\n",
      "SMay at t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t t \n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  pred=predict(i)\n",
    "  print(i)\n",
    "  print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEb2rA9McJnU",
    "outputId": "9e38e4b0-3d14-4354-f206-4e91b02d4e6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAADuId4cPI_",
    "outputId": "06a4117e-ac6a-4fae-bc5b-1b905184ad63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 20 test data sentences is:  0.015891448522335924\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 20 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JNnXh0VcUR5",
    "outputId": "f2ebc4fe-0b76-482a-cade-76fcc259eaf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3178289704467185]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H7W6JIrerd4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Encoder_Decoder_Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
