{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxx7myitnx4h",
    "outputId": "82baeeca-73d5-4ad0-c7a2-474f7fe88d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 2.33MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gqplyfv9n1mw"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WsavarFgn8Nz"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#reading the data into DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "9AWotYpxn-F7",
    "outputId": "128ed774-6520-445a-dd05-ba73d084b415"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)#displaying top 4 four data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#removing the last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKafzf6ToWkC"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)#preprocessing on source data\n",
    "df['target']=df['target'].apply(preprocess)#perprocessing on target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xuh4SgNaoYS7",
    "outputId": "de1431fc-5cb6-4a29-acd0-9bdd277ac7c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZEm82GcoZ3L",
    "outputId": "577a2af1-3911-41e7-acb6-e88fc0f9c211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DJ84ehWAoj8H"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(len)<170]#removing source datapoints having length greater than equal to 170\n",
    "df=df[df['target'].apply(len)<200]#removing target datapoints having length greater than equal to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H2tW5L9omLr",
    "outputId": "2a9b85d1-0860-4b3d-d795-96704a9c6ce5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fl5VZWaaoqGn",
    "outputId": "a053b745-0a8f-4881-b8f3-16c671a0d814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970,)\n",
      "(20,)\n",
      "(1970,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['source']\n",
    "y=df['target']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01)#splitting the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbfvxkdGo_lk"
   },
   "source": [
    "Target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSCnXKY2owi5",
    "outputId": "50dbdd8f-1a1c-41c4-bbab-cdf93b5e31ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3034\n"
     ]
    }
   ],
   "source": [
    "target_tokenizer= Tokenizer()#tokenization on target\n",
    "target_tokenizer.fit_on_texts(y_train)#fitting on ytrain\n",
    "target_vocab_size= len(target_tokenizer.word_index) + 1#target vocab size\n",
    "print(len(target_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "gxTYBa17pCtV"
   },
   "outputs": [],
   "source": [
    "target_encoded_docs_train = target_tokenizer.texts_to_sequences(y_train)#converting text to integers\n",
    "target_encoded_docs_test = target_tokenizer.texts_to_sequences(y_test)#converting text to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "MhJLucaWpEbZ"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_train = pad_sequences(target_encoded_docs_train,padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VK90pD5pF1n",
    "outputId": "b9ccccb6-220f-4d44-b681-4e858dbd8923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 155,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "ZexKHcNJpHW2"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_test = pad_sequences(target_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzkkdeOspJYS",
    "outputId": "b1669d27-9a40-4517-e530-f9b8da380ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 157,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNdQqGlgpNij"
   },
   "source": [
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9xK62nUpLQX",
    "outputId": "653db7ac-fe77-4982-90f6-47c4d926df6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702\n"
     ]
    }
   ],
   "source": [
    "source_tokenizer= Tokenizer()#tokenization on source\n",
    "source_tokenizer.fit_on_texts(X_train)#fitting to X_train\n",
    "source_vocab_size= len(source_tokenizer.word_index) + 1#source vocab size\n",
    "print(len(source_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "YSP7v2ylpQkB"
   },
   "outputs": [],
   "source": [
    "source_encoded_docs_train = source_tokenizer.texts_to_sequences(X_train)#converting text to sequence\n",
    "source_encoded_docs_test = source_tokenizer.texts_to_sequences(X_test)#converting text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "Bn9h_emepTUT"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_train = pad_sequences(source_encoded_docs_train,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrJjoty8pU31",
    "outputId": "29e7306b-ac43-49b5-e07d-dd630b3c396a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "QfLn6qRFpWPY"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_test = pad_sequences(source_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jC1CxZ69pXr-",
    "outputId": "c3f31ebc-c3c5-4b9c-a008-7884d5c44671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 163,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "HbleYK91pbP4"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "target_padded_docs_train=target_padded_docs_train.reshape((*target_padded_docs_train.shape,1))\n",
    "target_padded_docs_test=target_padded_docs_test.reshape((*target_padded_docs_test.shape,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6-DnH2Opc-R",
    "outputId": "047a6a4c-96f9-4ccf-b5e8-74d707a54cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(target_padded_docs_train.shape)\n",
    "print(target_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "4yZxwxPqpfQ6"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "source_padded_docs_train=source_padded_docs_train.reshape((*source_padded_docs_train.shape,1))\n",
    "source_padded_docs_test=source_padded_docs_test.reshape((*source_padded_docs_test.shape,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo2683qsphSW",
    "outputId": "85856845-fe63-4b72-9753-8fe0bb0c1947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(source_padded_docs_train.shape)\n",
    "print(source_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex4KJakfpto9"
   },
   "source": [
    "Model1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlt5EKECpo4Z",
    "outputId": "8fd8ffa1-9a21-422c-9f87-446f713b8eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 43, 512)           1895936   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 43, 128)           328192    \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 43, 512)           66048     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 43, 3035)          1556955   \n",
      "=================================================================\n",
      "Total params: 3,847,131\n",
      "Trainable params: 3,847,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,512, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.LSTM(128, return_sequences=True)(embed)  \n",
    "dense=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512, activation='relu'))(lstm1)\n",
    "drop=tf.keras.layers.Dropout(0.5)(dense)\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(drop)\n",
    "3model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "XT-t_UjdprW2"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl-JYNZhp1Pa",
    "outputId": "f992adf8-1bc4-45d3-ad90-5e7a4af976e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 59s 57s/step - loss: 7.7430 - accuracy: 0.3208 - val_loss: 2.7519 - val_accuracy: 0.7698\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 3.4479 - accuracy: 0.6728 - val_loss: 2.5025 - val_accuracy: 0.7698\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 3.5213 - accuracy: 0.6728 - val_loss: 1.9935 - val_accuracy: 0.7721\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 2.7795 - accuracy: 0.6730 - val_loss: 1.5858 - val_accuracy: 0.7791\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 2.2776 - accuracy: 0.6807 - val_loss: 1.5165 - val_accuracy: 0.7709\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 2.2367 - accuracy: 0.6729 - val_loss: 1.5061 - val_accuracy: 0.7698\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 2.2036 - accuracy: 0.6739 - val_loss: 1.4808 - val_accuracy: 0.7779\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 2.1772 - accuracy: 0.6805 - val_loss: 1.4521 - val_accuracy: 0.7791\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 2.1343 - accuracy: 0.6825 - val_loss: 1.4368 - val_accuracy: 0.7814\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 2.1044 - accuracy: 0.6819 - val_loss: 1.4336 - val_accuracy: 0.7791\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 2.0708 - accuracy: 0.6837 - val_loss: 1.4310 - val_accuracy: 0.7814\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 2.0483 - accuracy: 0.6863 - val_loss: 1.4018 - val_accuracy: 0.7849\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 2.0173 - accuracy: 0.6879 - val_loss: 1.3817 - val_accuracy: 0.7849\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 1.9866 - accuracy: 0.6885 - val_loss: 1.3591 - val_accuracy: 0.7849\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 1.9527 - accuracy: 0.6894 - val_loss: 1.3418 - val_accuracy: 0.7872\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 1.9202 - accuracy: 0.6916 - val_loss: 1.3293 - val_accuracy: 0.7860\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 1.8916 - accuracy: 0.6921 - val_loss: 1.3174 - val_accuracy: 0.7884\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 1.8620 - accuracy: 0.6944 - val_loss: 1.3016 - val_accuracy: 0.7907\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.8346 - accuracy: 0.6972 - val_loss: 1.2932 - val_accuracy: 0.7919\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 1.8075 - accuracy: 0.6993 - val_loss: 1.2764 - val_accuracy: 0.7965\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.7780 - accuracy: 0.7020 - val_loss: 1.2680 - val_accuracy: 0.7942\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 1.7495 - accuracy: 0.7045 - val_loss: 1.2495 - val_accuracy: 0.8000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.7181 - accuracy: 0.7080 - val_loss: 1.2368 - val_accuracy: 0.8035\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.6881 - accuracy: 0.7115 - val_loss: 1.2230 - val_accuracy: 0.8058\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 1.6586 - accuracy: 0.7140 - val_loss: 1.2126 - val_accuracy: 0.8093\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 1.6247 - accuracy: 0.7168 - val_loss: 1.1898 - val_accuracy: 0.8140\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 1.5962 - accuracy: 0.7213 - val_loss: 1.1732 - val_accuracy: 0.8186\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 1.5594 - accuracy: 0.7254 - val_loss: 1.1697 - val_accuracy: 0.8233\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.5303 - accuracy: 0.7302 - val_loss: 1.1395 - val_accuracy: 0.8314\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 1.4953 - accuracy: 0.7371 - val_loss: 1.1235 - val_accuracy: 0.8349\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 1.4593 - accuracy: 0.7407 - val_loss: 1.1209 - val_accuracy: 0.8384\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.4236 - accuracy: 0.7477 - val_loss: 1.1059 - val_accuracy: 0.8419\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 1.3867 - accuracy: 0.7514 - val_loss: 1.0881 - val_accuracy: 0.8442\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 1.3504 - accuracy: 0.7583 - val_loss: 1.0822 - val_accuracy: 0.8453\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.3140 - accuracy: 0.7633 - val_loss: 1.0658 - val_accuracy: 0.8465\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 1.2742 - accuracy: 0.7691 - val_loss: 1.0565 - val_accuracy: 0.8488\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 1.2396 - accuracy: 0.7743 - val_loss: 1.0437 - val_accuracy: 0.8547\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.2227 - accuracy: 0.7780 - val_loss: 1.0457 - val_accuracy: 0.8523\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.2551 - accuracy: 0.7719 - val_loss: 1.0567 - val_accuracy: 0.8558\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 1.2022 - accuracy: 0.7853 - val_loss: 1.0322 - val_accuracy: 0.8593\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.1494 - accuracy: 0.7873 - val_loss: 1.0276 - val_accuracy: 0.8570\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 1.1155 - accuracy: 0.7881 - val_loss: 1.0399 - val_accuracy: 0.8570\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 1.0756 - accuracy: 0.7968 - val_loss: 1.0274 - val_accuracy: 0.8593\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.0426 - accuracy: 0.8013 - val_loss: 1.0311 - val_accuracy: 0.8605\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 1.0029 - accuracy: 0.8069 - val_loss: 1.0222 - val_accuracy: 0.8616\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.9696 - accuracy: 0.8117 - val_loss: 1.0364 - val_accuracy: 0.8640\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.9377 - accuracy: 0.8166 - val_loss: 1.0423 - val_accuracy: 0.8616\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.9083 - accuracy: 0.8210 - val_loss: 1.0496 - val_accuracy: 0.8628\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.8767 - accuracy: 0.8248 - val_loss: 1.0535 - val_accuracy: 0.8651\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.8457 - accuracy: 0.8306 - val_loss: 1.0778 - val_accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67c2382550>"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "NVpRawW5O5Vu"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/\n",
    "#Beam Search\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "def beam_search_decoder(data, k):\n",
    "\tsequences = [[list(), 0.0]]\n",
    "\t# walk over each step in sequence\n",
    "\t#print(sequences)\n",
    "\tfor row in data:\n",
    "\t\tall_candidates = list()\n",
    "\t\t# expand each current candidate\n",
    "\t\tfor i in range(len(sequences)):\n",
    "\t\t\tseq, score = sequences[i]\n",
    "\t\t\tfor j in range(len(row)):\n",
    "\t\t\t\tcandidate = [seq + [j], score - np.log(row[j])]\n",
    "\t\t\t\tall_candidates.append(candidate)\n",
    "\t\t# order all candidates by score\n",
    "\t\tordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "\t\tsequences = ordered[:k]\n",
    "\treturn sequences\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikH9dtb8sw5C",
    "outputId": "e574e8cb-0e35-430d-a4c9-b16517503a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey... Kick boxing on sunday is fully booked...\n",
      "Actual Output: \n",
      "Hey, kick boxing on Sunday is fully booked.\n",
      "Predicted Output for beam==3 : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey on sunday is booked\n",
      "hey on sunday is mobile\n",
      "hey on sunday is on\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Oh... I juz checked n realize my lesson is at 440...Haha, tt means i'll cya den...\n",
      "Actual Output: \n",
      "Oh. I just checked and realize my lesson is at 4:40. Haha, that means I'll see you then.\n",
      "Predicted Output for beam==3 : \n",
      "oh i just i and my lesson is at point afternoon that means i you then\n",
      "oh i just i and my lesson is at point afternoon that means i see then\n",
      "oh i just i and my lesson is at point haha that means i you then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Fetch us at 7pm\n",
      "Actual Output: \n",
      "Fetch us at 7pm.\n",
      "Predicted Output for beam==3 : \n",
      "corner us at\n",
      "million us at\n",
      "drink us at\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "6pm\n",
      "Actual Output: \n",
      "6 pm .\n",
      "Predicted Output for beam==3 : \n",
      "is\n",
      "at\n",
      "be\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "the inauguration thing is 9am at uni cultural centre.u know abt it?\n",
      "Actual Output: \n",
      "The inauguration thing is 9 am. at university cultural centre. You know about it?\n",
      "Predicted Output for beam==3 : \n",
      "the that is at university sleepy centre you know about it\n",
      "the that is at university chen centre you know about it\n",
      "the that is at university cultural centre you know about it\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "dun like tat leh MR joe.\n",
      "Actual Output: \n",
      "Don't like that Mr. Joe.\n",
      "Predicted Output for beam==3 : \n",
      "don't like that i a\n",
      "don't like that i i a\n",
      "don't like like i a\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How u look like\n",
      "Actual Output: \n",
      "How do you look like?\n",
      "Predicted Output for beam==3 : \n",
      "how you look like\n",
      "how you go like\n",
      "how are look like\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Im sorry ken!i dun chat tht things 1!\n",
      "Actual Output: \n",
      "I'm sorry, Ken! I don't chat that thing!\n",
      "Predicted Output for beam==3 : \n",
      "i'm sorry rv i don't chat things 1\n",
      "i'm sorry hun i don't chat things 1\n",
      "i'm sorry tina i don't chat things 1\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Joey: YOGI CARE 2 INTRO.\n",
      "Actual Output: \n",
      "Joey: Yogi care to introduce?\n",
      "Predicted Output for beam==3 : \n",
      "joey care to introduce\n",
      "joey introduce to introduce\n",
      "joey care to be\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Im working ... R ü ireena\n",
      "Actual Output: \n",
      "I'm working. Are you ireena?\n",
      "Predicted Output for beam==3 : \n",
      "i'm working are you\n",
      "i'm working are are\n",
      "i working are you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Wat time u be home then?\n",
      "Actual Output: \n",
      "What time will you be home then?\n",
      "Predicted Output for beam==3 : \n",
      "what time you be home\n",
      "what time you be home then\n",
      "what time you be home i\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "No problem! Close friends call me hammy. Haha, just call me whatever you like. Good day! :)\n",
      "Actual Output: \n",
      "No problem! Close friends call me hammy. Haha, just call me whatever you like. Good day!\n",
      "Predicted Output for beam==3 : \n",
      "no another stuff friends call me haha just you me when you to good\n",
      "no another stuff friends call me haha just you me when you to good is\n",
      "no another stuff friends call me haha just you me help you to good\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yun,dun nd hide k,ur classmate,chong kai qin is in same camp as me.U dare mit me at tiong bahru at 1.30pm lah\n",
      "Actual Output: \n",
      "Yun, don't need to hide, your classmate, Chong Kai Qin is in the same camp as me. You dare to meet me at Tiong Bahru at 1:30pm.\n",
      "Predicted Output for beam==3 : \n",
      "yun don't need ok your blessed is in same camp as me you tomorrow meet me at at tiong the 1 30 shots\n",
      "yun don't need ok your practice is in same camp as me you tomorrow meet me at at tiong the 1 30 shots\n",
      "yun don't need ok your blessed is in same camp as me you tomorrow meet me at at tiong the 1 30 package\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey... So ür fren bro alreadi in e com eng course? Cöz i wan to find out more abt it can help me ask? Thkz =5\n",
      "Actual Output: \n",
      "Hey. So your friend's brother is already in computer engineering course? Because I want to find out more about it can help me ask? Thanks.\n",
      "Predicted Output for beam==3 : \n",
      "hey so your your in in the in without st my i you to to to to to to can help you go can tomorrow\n",
      "hey so your your in in the without without st my i you to to to to to to can help you go can tomorrow\n",
      "hey so your your in in the in without st my i you to to to to to to can help me go can tomorrow\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "It's u .. Not me ..\n",
      "Actual Output: \n",
      "It's you. Not me.\n",
      "Predicted Output for beam==3 : \n",
      "it's you not me\n",
      "it's you not you\n",
      "happy you not me\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Help me feed e hamsters...\n",
      "Actual Output: \n",
      "Help me feed the hamsters.\n",
      "Predicted Output for beam==3 : \n",
      "help me wrong the\n",
      "help me nap the\n",
      "help me feed the\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha. Oops. I didnt see your msg. Ü want to go at 9?\n",
      "Actual Output: \n",
      "Haha. Sorry. I didn't see your message. You want to go at 9?\n",
      "Predicted Output for beam==3 : \n",
      "haha i didn't see your message you you to go to four\n",
      "haha i didn't see your message you you to go to four start\n",
      "haha i didn't see your message you you to go to four to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Dunno lei... Ben juz ask... He neva say... Aiyo y she like tai tai like dat always play mah jong...\n",
      "Actual Output: \n",
      "Don't know. Ben just asked. He never say. Why is she like an middle-aged lady like that always play mahjong?\n",
      "Predicted Output for beam==3 : \n",
      "don't don't once just ask he yes say i i she i on rich owl that trip bash is\n",
      "don't don't once just ask he yes say i i she it on rich owl that trip bash is\n",
      "don't don't once just ask he yes say i i she i on rich owl that trip bash your\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yup...Mit u at body shop\n",
      "Actual Output: \n",
      "Yes. Meet you at Body Shop.\n",
      "Predicted Output for beam==3 : \n",
      "yes meet you at body shop\n",
      "yes meet you at body her\n",
      "yes meet you at body and\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I am i am! Haha no need to save seat for rebecca\n",
      "Actual Output: \n",
      "I am I am! Haha, no need to save seat for Rebecca.\n",
      "Predicted Output for beam==3 : \n",
      "i am i am haha no need to save more for rebecca\n",
      "i am i am haha no need to save more for more\n",
      "i am i am haha no need to save more for on\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in x])\n",
    "  return y\n",
    "#calculating bleu score using beam search where K==3\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output for beam==3 : \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "\n",
    "  res=beam_search_decoder(x[0],3)\n",
    "\n",
    "  y1=prediction(res[0][0])\n",
    "  y1=y1.split(' ')\n",
    "  y_lst1=[]\n",
    "  for i in y1:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst1.append(i)\n",
    "  print(' '.join(y_lst1))\n",
    "\n",
    "\n",
    "  y2=prediction(res[1][0])\n",
    "  y2=y2.split(' ')\n",
    "  y_lst2=[]\n",
    "  for i in y2:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst2.append(i)\n",
    "  print(' '.join(y_lst2))\n",
    "\n",
    "  y3=prediction(res[2][0])\n",
    "  y3=y3.split(' ')\n",
    "  y_lst3=[]\n",
    "  for i in y3:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst3.append(i)\n",
    "  print(' '.join(y_lst3))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsqiQqLEtCnU",
    "outputId": "67ec37bc-1f18-4707-c19b-0966372dd21f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Bleu Score1 is:  0.38480691187655225\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Average Bleu Score2 is:  0.36163580184089766\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Average Bleu Score3 is:  0.3734191852349319\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_score1=[]\n",
    "bleu_score2=[]\n",
    "bleu_score3=[]\n",
    "\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "\n",
    "  res=beam_search_decoder(x[0],3)\n",
    "\n",
    "  y1=prediction(res[0][0])\n",
    "  y1=y1.split(' ')\n",
    "  y_lst1=[]\n",
    "  for i in y1:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst1.append(i)\n",
    "  bleu_score1.append(bleu.sentence_bleu([b[0].split(),],y_lst1))\n",
    "\n",
    "  y2=prediction(res[1][0])\n",
    "  y2=y2.split(' ')\n",
    "  y_lst2=[]\n",
    "  for i in y2:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst2.append(i)\n",
    "  bleu_score2.append(bleu.sentence_bleu([b[0].split(),],y_lst2))\n",
    "\n",
    "  y3=prediction(res[2][0])\n",
    "  y3=y3.split(' ')\n",
    "  y_lst3=[]\n",
    "  for i in y3:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst3.append(i)\n",
    "  bleu_score3.append(bleu.sentence_bleu([b[0].split(),],y_lst3))\n",
    "\n",
    "print(\"The Average Bleu Score1 is: \",sum(bleu_score1)/20)\n",
    "print('>'*180)\n",
    "print(\"The Average Bleu Score2 is: \",sum(bleu_score2)/20)\n",
    "print('>'*180)\n",
    "print(\"The Average Bleu Score3 is: \",sum(bleu_score3)/20)\n",
    "print('>'*180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1tc_fxeuI6I"
   },
   "source": [
    "Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjUr0ohmqi8p",
    "outputId": "0536161a-2147-4e83-b7bd-ededa7e407d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 43, 512)           1895936   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 43, 200)           490400    \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 43, 3035)          610035    \n",
      "=================================================================\n",
      "Total params: 2,996,371\n",
      "Trainable params: 2,996,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,512, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True))(embed)  \n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(lstm1)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "iXpqxfOhuNTz"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4g-6RMYuP_H",
    "outputId": "293e3cab-8627-4dad-c274-2724265041fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 4s 874ms/step - loss: 7.6971 - accuracy: 0.3259 - val_loss: 5.2202 - val_accuracy: 0.7698\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 4.6866 - accuracy: 0.6728 - val_loss: 1.9247 - val_accuracy: 0.7698\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.7107 - accuracy: 0.6728 - val_loss: 2.0169 - val_accuracy: 0.7698\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.9326 - accuracy: 0.6728 - val_loss: 1.9303 - val_accuracy: 0.7698\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.7293 - accuracy: 0.6737 - val_loss: 1.8979 - val_accuracy: 0.7698\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 2.5013 - accuracy: 0.6717 - val_loss: 1.6204 - val_accuracy: 0.7709\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 2.2420 - accuracy: 0.6735 - val_loss: 1.4918 - val_accuracy: 0.7756\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 2.1406 - accuracy: 0.6795 - val_loss: 1.4636 - val_accuracy: 0.7756\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 2.1163 - accuracy: 0.6844 - val_loss: 1.4504 - val_accuracy: 0.7791\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 2.1090 - accuracy: 0.6839 - val_loss: 1.4436 - val_accuracy: 0.7791\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.0970 - accuracy: 0.6844 - val_loss: 1.4331 - val_accuracy: 0.7779\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 2.0796 - accuracy: 0.6858 - val_loss: 1.4136 - val_accuracy: 0.7767\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 2.0534 - accuracy: 0.6899 - val_loss: 1.3890 - val_accuracy: 0.7826\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 2.0201 - accuracy: 0.6924 - val_loss: 1.3725 - val_accuracy: 0.7849\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 1.9935 - accuracy: 0.6913 - val_loss: 1.3610 - val_accuracy: 0.7826\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.9651 - accuracy: 0.6913 - val_loss: 1.3476 - val_accuracy: 0.7837\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.9356 - accuracy: 0.6929 - val_loss: 1.3348 - val_accuracy: 0.7826\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.9069 - accuracy: 0.6948 - val_loss: 1.3185 - val_accuracy: 0.7849\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.8763 - accuracy: 0.6975 - val_loss: 1.2984 - val_accuracy: 0.7860\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.8429 - accuracy: 0.6996 - val_loss: 1.2787 - val_accuracy: 0.7872\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.8082 - accuracy: 0.7010 - val_loss: 1.2591 - val_accuracy: 0.7895\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.7717 - accuracy: 0.7037 - val_loss: 1.2377 - val_accuracy: 0.7919\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.7335 - accuracy: 0.7076 - val_loss: 1.2126 - val_accuracy: 0.7942\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.6949 - accuracy: 0.7120 - val_loss: 1.1878 - val_accuracy: 0.8000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.6553 - accuracy: 0.7192 - val_loss: 1.1662 - val_accuracy: 0.8081\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.6147 - accuracy: 0.7265 - val_loss: 1.1468 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.5731 - accuracy: 0.7337 - val_loss: 1.1242 - val_accuracy: 0.8209\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.5308 - accuracy: 0.7402 - val_loss: 1.1069 - val_accuracy: 0.8291\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.4883 - accuracy: 0.7473 - val_loss: 1.0902 - val_accuracy: 0.8337\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.4461 - accuracy: 0.7547 - val_loss: 1.0731 - val_accuracy: 0.8372\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.4047 - accuracy: 0.7621 - val_loss: 1.0563 - val_accuracy: 0.8442\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 1.3630 - accuracy: 0.7682 - val_loss: 1.0421 - val_accuracy: 0.8453\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.3218 - accuracy: 0.7750 - val_loss: 1.0275 - val_accuracy: 0.8465\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.2818 - accuracy: 0.7815 - val_loss: 1.0125 - val_accuracy: 0.8488\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.2420 - accuracy: 0.7883 - val_loss: 1.0010 - val_accuracy: 0.8547\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.2037 - accuracy: 0.7944 - val_loss: 0.9922 - val_accuracy: 0.8581\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.1664 - accuracy: 0.8007 - val_loss: 0.9795 - val_accuracy: 0.8593\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.1290 - accuracy: 0.8070 - val_loss: 0.9709 - val_accuracy: 0.8616\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.0930 - accuracy: 0.8132 - val_loss: 0.9617 - val_accuracy: 0.8651\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.0571 - accuracy: 0.8190 - val_loss: 0.9520 - val_accuracy: 0.8651\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.0230 - accuracy: 0.8241 - val_loss: 0.9453 - val_accuracy: 0.8674\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.9890 - accuracy: 0.8287 - val_loss: 0.9389 - val_accuracy: 0.8663\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.9561 - accuracy: 0.8329 - val_loss: 0.9338 - val_accuracy: 0.8686\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.9242 - accuracy: 0.8370 - val_loss: 0.9315 - val_accuracy: 0.8686\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.8932 - accuracy: 0.8409 - val_loss: 0.9264 - val_accuracy: 0.8674\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.8641 - accuracy: 0.8442 - val_loss: 0.9248 - val_accuracy: 0.8698\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.8352 - accuracy: 0.8474 - val_loss: 0.9221 - val_accuracy: 0.8721\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.8082 - accuracy: 0.8498 - val_loss: 0.9187 - val_accuracy: 0.8733\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.7807 - accuracy: 0.8527 - val_loss: 0.9172 - val_accuracy: 0.8721\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.7557 - accuracy: 0.8551 - val_loss: 0.9166 - val_accuracy: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67caecaa10>"
      ]
     },
     "execution_count": 188,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJqigHnim0wz",
    "outputId": "ce76a383-f95b-4a08-b94b-0c813a923eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 0.7306 - accuracy: 0.8575 - val_loss: 0.9117 - val_accuracy: 0.8733\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.7071 - accuracy: 0.8601 - val_loss: 0.9130 - val_accuracy: 0.8744\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.6841 - accuracy: 0.8626 - val_loss: 0.9143 - val_accuracy: 0.8756\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.6617 - accuracy: 0.8648 - val_loss: 0.9150 - val_accuracy: 0.8733\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.6407 - accuracy: 0.8671 - val_loss: 0.9149 - val_accuracy: 0.8733\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.6204 - accuracy: 0.8699 - val_loss: 0.9132 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.6007 - accuracy: 0.8718 - val_loss: 0.9126 - val_accuracy: 0.8767\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.5823 - accuracy: 0.8743 - val_loss: 0.9142 - val_accuracy: 0.8756\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.5641 - accuracy: 0.8775 - val_loss: 0.9143 - val_accuracy: 0.8744\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.5471 - accuracy: 0.8793 - val_loss: 0.9148 - val_accuracy: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f67caf1de90>"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=10,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "-IZlJ5yUv8cF"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/\n",
    "#Beam Search\n",
    "\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "def beam_search_decoder(data, k):\n",
    "\tsequences = [[list(), 0.0]]\n",
    "\t# walk over each step in sequence\n",
    "\t#print(sequences)\n",
    "\tfor row in data:\n",
    "\t\tall_candidates = list()\n",
    "\t\t# expand each current candidate\n",
    "\t\tfor i in range(len(sequences)):\n",
    "\t\t\tseq, score = sequences[i]\n",
    "\t\t\tfor j in range(len(row)):\n",
    "\t\t\t\tcandidate = [seq + [j], score - np.log(row[j])]\n",
    "\t\t\t\tall_candidates.append(candidate)\n",
    "\t\t# order all candidates by score\n",
    "\t\tordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "\t\tsequences = ordered[:k]\n",
    "\treturn sequences\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkRLT22PmhOE",
    "outputId": "5bc2e90c-e51e-428f-fe4f-5443e8adebdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey... Kick boxing on sunday is fully booked...\n",
      "Actual Output: \n",
      "Hey, kick boxing on Sunday is fully booked.\n",
      "Predicted Output for beam==3 : \n",
      "hey on sunday is jo\n",
      "hey on sunday is green\n",
      "hey on sunday is 2nd\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Oh... I juz checked n realize my lesson is at 440...Haha, tt means i'll cya den...\n",
      "Actual Output: \n",
      "Oh. I just checked and realize my lesson is at 4:40. Haha, that means I'll see you then.\n",
      "Predicted Output for beam==3 : \n",
      "oh i just i and my lesson is at 4 haha then i'll i'll you then\n",
      "oh i just i and my lesson is at 4 haha then i'll i'll you you\n",
      "oh i just i and my lesson is at 4 haha then i'll i'll you meet\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Fetch us at 7pm\n",
      "Actual Output: \n",
      "Fetch us at 7pm.\n",
      "Predicted Output for beam==3 : \n",
      "fetch us at tiring\n",
      "fetch us at 40\n",
      "fetch us at minutes\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "6pm\n",
      "Actual Output: \n",
      "6 pm .\n",
      "Predicted Output for beam==3 : \n",
      "after\n",
      "taxi\n",
      "esplanade\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "the inauguration thing is 9am at uni cultural centre.u know abt it?\n",
      "Actual Output: \n",
      "The inauguration thing is 9 am. at university cultural centre. You know about it?\n",
      "Predicted Output for beam==3 : \n",
      "the thing is at university cultural centre you you about it\n",
      "the thing is at university cultural centre you about it\n",
      "the thing is at university group centre you you about it\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "dun like tat leh MR joe.\n",
      "Actual Output: \n",
      "Don't like that Mr. Joe.\n",
      "Predicted Output for beam==3 : \n",
      "don't like that like i hitting\n",
      "don't like like like i hitting\n",
      "don't like that like i letter\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How u look like\n",
      "Actual Output: \n",
      "How do you look like?\n",
      "Predicted Output for beam==3 : \n",
      "how you you like\n",
      "how you you\n",
      "how do you like\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Im sorry ken!i dun chat tht things 1!\n",
      "Actual Output: \n",
      "I'm sorry, Ken! I don't chat that thing!\n",
      "Predicted Output for beam==3 : \n",
      "i'm sorry buys i don't chat things 1\n",
      "i'm sorry devin i don't chat things 1\n",
      "i'm sorry harry i don't chat things 1\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Joey: YOGI CARE 2 INTRO.\n",
      "Actual Output: \n",
      "Joey: Yogi care to introduce?\n",
      "Predicted Output for beam==3 : \n",
      "joey care to introduce\n",
      "joey care 2 introduce\n",
      "joey care already introduce\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Im working ... R ü ireena\n",
      "Actual Output: \n",
      "I'm working. Are you ireena?\n",
      "Predicted Output for beam==3 : \n",
      "i'm working are you\n",
      "i'm working are\n",
      "i'm working you you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Wat time u be home then?\n",
      "Actual Output: \n",
      "What time will you be home then?\n",
      "Predicted Output for beam==3 : \n",
      "what time you be home then\n",
      "what time you you home then\n",
      "what time you be home early\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "No problem! Close friends call me hammy. Haha, just call me whatever you like. Good day! :)\n",
      "Actual Output: \n",
      "No problem! Close friends call me hammy. Haha, just call me whatever you like. Good day!\n",
      "Predicted Output for beam==3 : \n",
      "no no close friends call me haha i call me whatever you me good day\n",
      "no no close friends call me haha i call me whatever you good day\n",
      "no no close friends call me haha i call me whatever you i good day\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yun,dun nd hide k,ur classmate,chong kai qin is in same camp as me.U dare mit me at tiong bahru at 1.30pm lah\n",
      "Actual Output: \n",
      "Yun, don't need to hide, your classmate, Chong Kai Qin is in the same camp as me. You dare to meet me at Tiong Bahru at 1:30pm.\n",
      "Predicted Output for beam==3 : \n",
      "yun don't need i'm your seldom is of same camp as me you you meet me at at tiong at at 30 at\n",
      "yun don't need i'm your seldom is in same camp as me you you meet me at at tiong at at 30 at\n",
      "yun don't need i'm your cover is of same camp as me you you meet me at at tiong at at 30 at\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey... So ür fren bro alreadi in e com eng course? Cöz i wan to find out more abt it can help me ask? Thkz =5\n",
      "Actual Output: \n",
      "Hey. So your friend's brother is already in computer engineering course? Because I want to find out more about it can help me ask? Thanks.\n",
      "Predicted Output for beam==3 : \n",
      "hey so your the my in the moon my course i i want to to send to about be can can me ask thanks\n",
      "hey so your the my in the moon my course i i want to to to to about be can can me ask thanks\n",
      "hey so your the my in the moon my course i i want to to send to about be can can me ask\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "It's u .. Not me ..\n",
      "Actual Output: \n",
      "It's you. Not me.\n",
      "Predicted Output for beam==3 : \n",
      "it's you not me\n",
      "it's you you me\n",
      "it's you are me\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Help me feed e hamsters...\n",
      "Actual Output: \n",
      "Help me feed the hamsters.\n",
      "Predicted Output for beam==3 : \n",
      "help me lecture the\n",
      "help me lecture\n",
      "help me nopez the\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha. Oops. I didnt see your msg. Ü want to go at 9?\n",
      "Actual Output: \n",
      "Haha. Sorry. I didn't see your message. You want to go at 9?\n",
      "Predicted Output for beam==3 : \n",
      "haha i didn't see your message you you to go at 9\n",
      "haha i didn't see your message you want to go at 9\n",
      "haha i didn't see your message you you to to at 9\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Dunno lei... Ben juz ask... He neva say... Aiyo y she like tai tai like dat always play mah jong...\n",
      "Actual Output: \n",
      "Don't know. Ben just asked. He never say. Why is she like an middle-aged lady like that always play mahjong?\n",
      "Predicted Output for beam==3 : \n",
      "don't don't ben just ask he never says she why she always always always like that always play how\n",
      "don't know ben just ask he never says she why she always always always like that always play how\n",
      "don't don't ben just ask he never says she why she always always always like that always play\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yup...Mit u at body shop\n",
      "Actual Output: \n",
      "Yes. Meet you at Body Shop.\n",
      "Predicted Output for beam==3 : \n",
      "yes meet you at she's\n",
      "yes meet you at wear\n",
      "yes meet you at she's shop\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I am i am! Haha no need to save seat for rebecca\n",
      "Actual Output: \n",
      "I am I am! Haha, no need to save seat for Rebecca.\n",
      "Predicted Output for beam==3 : \n",
      "i am i am haha no need to save seat for rebecca to\n",
      "i am i am haha no need to save seat for rebecca i\n",
      "i am i am don't no need to save seat for rebecca to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in x])\n",
    "  return y\n",
    "#calculating bleu score using beam search where K==3\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output for beam==3 : \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "\n",
    "  res=beam_search_decoder(x[0],3)\n",
    "\n",
    "  y1=prediction(res[0][0])\n",
    "  y1=y1.split(' ')\n",
    "  y_lst1=[]\n",
    "  for i in y1:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst1.append(i)\n",
    "  print(' '.join(y_lst1))\n",
    "\n",
    "\n",
    "  y2=prediction(res[1][0])\n",
    "  y2=y2.split(' ')\n",
    "  y_lst2=[]\n",
    "  for i in y2:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst2.append(i)\n",
    "  print(' '.join(y_lst2))\n",
    "\n",
    "  y3=prediction(res[2][0])\n",
    "  y3=y3.split(' ')\n",
    "  y_lst3=[]\n",
    "  for i in y3:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst3.append(i)\n",
    "  print(' '.join(y_lst3))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2g8hsjmmhyE",
    "outputId": "5932e634-7490-44ea-cc32-f49160e029c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Bleu Score1 is:  0.3672876018410912\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Average Bleu Score2 is:  0.336078085901221\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Average Bleu Score3 is:  0.3697109749269815\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_score1=[]\n",
    "bleu_score2=[]\n",
    "bleu_score3=[]\n",
    "\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "\n",
    "  res=beam_search_decoder(x[0],3)\n",
    "\n",
    "  y1=prediction(res[0][0])\n",
    "  y1=y1.split(' ')\n",
    "  y_lst1=[]\n",
    "  for i in y1:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst1.append(i)\n",
    "  bleu_score1.append(bleu.sentence_bleu([b[0].split(),],y_lst1))\n",
    "\n",
    "  y2=prediction(res[1][0])\n",
    "  y2=y2.split(' ')\n",
    "  y_lst2=[]\n",
    "  for i in y2:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst2.append(i)\n",
    "  bleu_score2.append(bleu.sentence_bleu([b[0].split(),],y_lst2))\n",
    "\n",
    "  y3=prediction(res[2][0])\n",
    "  y3=y3.split(' ')\n",
    "  y_lst3=[]\n",
    "  for i in y3:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst3.append(i)\n",
    "  bleu_score3.append(bleu.sentence_bleu([b[0].split(),],y_lst3))\n",
    "\n",
    "print(\"The Average Bleu Score1 is: \",sum(bleu_score1)/20)\n",
    "print('>'*180)\n",
    "print(\"The Average Bleu Score2 is: \",sum(bleu_score2)/20)\n",
    "print('>'*180)\n",
    "print(\"The Average Bleu Score3 is: \",sum(bleu_score3)/20)\n",
    "print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqojT6aamvm8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentence_correction_wordlevel_manytomany_beamsearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
