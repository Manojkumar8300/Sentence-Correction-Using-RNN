{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxx7myitnx4h",
    "outputId": "e866302f-c2af-4d5a-9048-596cb477918f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 43.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gqplyfv9n1mw"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WsavarFgn8Nz"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#reading the data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "9AWotYpxn-F7",
    "outputId": "8584ac38-b4d1-4263-d8d1-6faccac5c048"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)#displaying top 4 four data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#removing the last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKafzf6ToWkC"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)#preprocessing on source data\n",
    "df['target']=df['target'].apply(preprocess)#perprocessing on target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "xuh4SgNaoYS7",
    "outputId": "f5a3f19c-6067-4e02-f7d9-a3d2d2a85d73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZEm82GcoZ3L",
    "outputId": "f05459b8-5e57-40d2-dace-cab35be9313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DJ84ehWAoj8H"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(len)<170]#removing source datapoints having length greater than equal to 170\n",
    "df=df[df['target'].apply(len)<200]#removing target datapoints having length greater than equal to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H2tW5L9omLr",
    "outputId": "f9a5176a-ab3b-47eb-f4c3-2cf07c3c91a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fl5VZWaaoqGn",
    "outputId": "94ee1dd8-08e1-480a-c08d-e715c4c4fd2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970,)\n",
      "(20,)\n",
      "(1970,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['source']\n",
    "y=df['target']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01)#splitting the data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "u1NbCZg3rpI5"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_test.to_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbfvxkdGo_lk"
   },
   "source": [
    "Target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSCnXKY2owi5",
    "outputId": "383c48f6-2667-4bed-b319-4a779cd07d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032\n"
     ]
    }
   ],
   "source": [
    "target_tokenizer= Tokenizer()#tokenization on target\n",
    "target_tokenizer.fit_on_texts(y_train)#fitting on ytrain\n",
    "target_vocab_size= len(target_tokenizer.word_index) + 1#target vocab size\n",
    "print(len(target_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gxTYBa17pCtV"
   },
   "outputs": [],
   "source": [
    "target_encoded_docs_train = target_tokenizer.texts_to_sequences(y_train)#converting text to integers\n",
    "target_encoded_docs_test = target_tokenizer.texts_to_sequences(y_test)#converting text to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MhJLucaWpEbZ"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_train = pad_sequences(target_encoded_docs_train,padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VK90pD5pF1n",
    "outputId": "e37105ef-6f41-4c37-c6f7-f487e361ad5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZexKHcNJpHW2"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_test = pad_sequences(target_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzkkdeOspJYS",
    "outputId": "551a8787-2683-4cbf-bd3b-f48320a58d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNdQqGlgpNij"
   },
   "source": [
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9xK62nUpLQX",
    "outputId": "264df537-2b0d-4a4d-d4b6-670d21d7df62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3703\n"
     ]
    }
   ],
   "source": [
    "source_tokenizer= Tokenizer()#tokenization on source\n",
    "source_tokenizer.fit_on_texts(X_train)#fitting to X_train\n",
    "source_vocab_size= len(source_tokenizer.word_index) + 1#source vocab size\n",
    "print(len(source_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YSP7v2ylpQkB"
   },
   "outputs": [],
   "source": [
    "source_encoded_docs_train = source_tokenizer.texts_to_sequences(X_train)#converting text to sequence\n",
    "source_encoded_docs_test = source_tokenizer.texts_to_sequences(X_test)#converting text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Bn9h_emepTUT"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_train = pad_sequences(source_encoded_docs_train,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrJjoty8pU31",
    "outputId": "aeef8608-3152-40fe-d1e8-b4458653be3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QfLn6qRFpWPY"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_test = pad_sequences(source_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jC1CxZ69pXr-",
    "outputId": "146e529a-c3c8-474a-be3f-740423b51a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HbleYK91pbP4"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "\n",
    "target_padded_docs_train=target_padded_docs_train.reshape((*target_padded_docs_train.shape,1))\n",
    "target_padded_docs_test=target_padded_docs_test.reshape((*target_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6-DnH2Opc-R",
    "outputId": "6902f66f-3db2-434b-bb79-02978e491fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(target_padded_docs_train.shape)\n",
    "print(target_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4yZxwxPqpfQ6"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "\n",
    "source_padded_docs_train=source_padded_docs_train.reshape((*source_padded_docs_train.shape,1))\n",
    "source_padded_docs_test=source_padded_docs_test.reshape((*source_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo2683qsphSW",
    "outputId": "6b5ff627-9ec9-4ee7-8fbf-5698ec6d601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(source_padded_docs_train.shape)\n",
    "print(source_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "j3ho8eL5vPMX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(source_encoded_docs_train).to_csv(\"source_encoded_docs_train.csv\")\n",
    "pd.DataFrame(source_encoded_docs_test).to_csv(\"source_encoded_docs_test.csv\")\n",
    "pd.DataFrame(target_encoded_docs_train).to_csv(\"target_encoded_docs_train.csv\")\n",
    "pd.DataFrame(target_encoded_docs_test).to_csv(\"target_encoded_docs_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex4KJakfpto9"
   },
   "source": [
    "Model1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlt5EKECpo4Z",
    "outputId": "f6cdcf81-7b9c-42e8-8900-9671b15363aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 43, 512)           1896448   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 43, 128)           328192    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 43, 512)           66048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 43, 3033)          1555929   \n",
      "=================================================================\n",
      "Total params: 3,846,617\n",
      "Trainable params: 3,846,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,512, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.LSTM(128, return_sequences=True)(embed)  \n",
    "dense=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512, activation='relu'))(lstm1)\n",
    "drop=tf.keras.layers.Dropout(0.5)(dense)\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(drop)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XT-t_UjdprW2"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl-JYNZhp1Pa",
    "outputId": "92ea1e88-4aae-4304-e527-9439d49838b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 682ms/step - loss: 7.6636 - accuracy: 0.3253 - val_loss: 2.8829 - val_accuracy: 0.6814\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 3.3623 - accuracy: 0.6737 - val_loss: 3.7915 - val_accuracy: 0.6814\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 3.5440 - accuracy: 0.6738 - val_loss: 3.1268 - val_accuracy: 0.6849\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.9334 - accuracy: 0.6277 - val_loss: 2.1335 - val_accuracy: 0.6907\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.2468 - accuracy: 0.6814 - val_loss: 2.0976 - val_accuracy: 0.6826\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.2337 - accuracy: 0.6770 - val_loss: 2.0702 - val_accuracy: 0.6826\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.1996 - accuracy: 0.6778 - val_loss: 2.0878 - val_accuracy: 0.6895\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.1723 - accuracy: 0.6818 - val_loss: 2.0516 - val_accuracy: 0.6895\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.1341 - accuracy: 0.6830 - val_loss: 2.0055 - val_accuracy: 0.6884\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.1038 - accuracy: 0.6839 - val_loss: 1.9801 - val_accuracy: 0.6907\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.0731 - accuracy: 0.6865 - val_loss: 1.9737 - val_accuracy: 0.6942\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.0512 - accuracy: 0.6876 - val_loss: 1.9464 - val_accuracy: 0.6907\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.0213 - accuracy: 0.6886 - val_loss: 1.9211 - val_accuracy: 0.6942\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.9878 - accuracy: 0.6887 - val_loss: 1.9127 - val_accuracy: 0.6953\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.9589 - accuracy: 0.6912 - val_loss: 1.8974 - val_accuracy: 0.6919\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.9291 - accuracy: 0.6931 - val_loss: 1.8791 - val_accuracy: 0.6907\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.8970 - accuracy: 0.6950 - val_loss: 1.8727 - val_accuracy: 0.6942\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.8681 - accuracy: 0.6959 - val_loss: 1.8493 - val_accuracy: 0.6942\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.8403 - accuracy: 0.6976 - val_loss: 1.8440 - val_accuracy: 0.6942\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.8105 - accuracy: 0.6993 - val_loss: 1.8314 - val_accuracy: 0.6988\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.7842 - accuracy: 0.7021 - val_loss: 1.8299 - val_accuracy: 0.7058\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.7562 - accuracy: 0.7040 - val_loss: 1.8196 - val_accuracy: 0.7081\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.7309 - accuracy: 0.7066 - val_loss: 1.8111 - val_accuracy: 0.7116\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.7078 - accuracy: 0.7096 - val_loss: 1.8135 - val_accuracy: 0.7140\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.6773 - accuracy: 0.7121 - val_loss: 1.8021 - val_accuracy: 0.7151\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.6516 - accuracy: 0.7151 - val_loss: 1.7920 - val_accuracy: 0.7174\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.6225 - accuracy: 0.7181 - val_loss: 1.8150 - val_accuracy: 0.7186\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.5917 - accuracy: 0.7226 - val_loss: 1.7871 - val_accuracy: 0.7256\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.5617 - accuracy: 0.7263 - val_loss: 1.7878 - val_accuracy: 0.7267\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.5382 - accuracy: 0.7308 - val_loss: 1.7456 - val_accuracy: 0.7326\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.5133 - accuracy: 0.7338 - val_loss: 1.8043 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.4798 - accuracy: 0.7402 - val_loss: 1.7593 - val_accuracy: 0.7384\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.4467 - accuracy: 0.7436 - val_loss: 1.7910 - val_accuracy: 0.7395\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 1.4099 - accuracy: 0.7485 - val_loss: 1.7919 - val_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.3756 - accuracy: 0.7540 - val_loss: 1.7466 - val_accuracy: 0.7465\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.3438 - accuracy: 0.7564 - val_loss: 1.8333 - val_accuracy: 0.7651\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.3087 - accuracy: 0.7656 - val_loss: 1.7408 - val_accuracy: 0.7605\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.2719 - accuracy: 0.7681 - val_loss: 1.7982 - val_accuracy: 0.7721\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.2379 - accuracy: 0.7742 - val_loss: 1.7827 - val_accuracy: 0.7733\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.2018 - accuracy: 0.7811 - val_loss: 1.7217 - val_accuracy: 0.7686\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.1695 - accuracy: 0.7825 - val_loss: 1.8738 - val_accuracy: 0.7767\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.1507 - accuracy: 0.7885 - val_loss: 1.7565 - val_accuracy: 0.7756\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.1208 - accuracy: 0.7932 - val_loss: 1.7998 - val_accuracy: 0.7756\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.0840 - accuracy: 0.7979 - val_loss: 1.8774 - val_accuracy: 0.7791\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.0505 - accuracy: 0.8041 - val_loss: 1.7933 - val_accuracy: 0.7767\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.0186 - accuracy: 0.8041 - val_loss: 1.9076 - val_accuracy: 0.7872\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.9887 - accuracy: 0.8124 - val_loss: 1.7677 - val_accuracy: 0.7791\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.9538 - accuracy: 0.8149 - val_loss: 1.9284 - val_accuracy: 0.7907\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.9254 - accuracy: 0.8213 - val_loss: 1.7607 - val_accuracy: 0.7837\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.8998 - accuracy: 0.8253 - val_loss: 1.9367 - val_accuracy: 0.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdec6dfbe90>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YiFHeHQ0p2-H"
   },
   "outputs": [],
   "source": [
    "x=model.predict(source_padded_docs_test[:1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "kLpjZU_jqXpa",
    "outputId": "4abff6fa-227f-402e-b06e-93f95912e5e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'hey i am still having stuff <PAD> if you reach <PAD> <PAD> <PAD> help it and me you to <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com\n",
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "\n",
    "' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sGCpWeiqdWm",
    "outputId": "38311ff6-ce33-412b-93ee-7f7b432f2a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866    I am still having breakfast. If you reach ther...\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skB3G_F2qfP_",
    "outputId": "90597e21-fae2-4081-b5c7-1c18bb6952ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866    Hey i am still having breakfast eh. If you rea...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikH9dtb8sw5C",
    "outputId": "8445c979-0666-411a-e291-0250236d0474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey i am still having breakfast eh. If you reach there first can help rebecca and me chope seats?\n",
      "Actual Output: \n",
      "I am still having breakfast. If you reach there first can you help me and Rebecca reserve seats?\n",
      "Predicted Output: \n",
      "hey i am still having stuff if you reach help it and me you to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh ü take then how i take bus later... Inside got money a not...\n",
      "Actual Output: \n",
      "If you take then how I take bus later? Inside got money or not?\n",
      "Predicted Output: \n",
      "huh you take then how i take bus me have your a not\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi neva worry bout da truth coz the truth will lead me 2 ur heart. It's the least a unique person like u deserve. Sleep tight or morning\n",
      "Actual Output: \n",
      "Hi, never worry about the truth because the truth will lead me to your heart. It's the least that a unique person like you deserve. Sleep tight or morning.\n",
      "Predicted Output: \n",
      "hi never worry about the because the will me to your one very the hang a you kb can you inform sleep unrestricted or the\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Take so long\n",
      "Actual Output: \n",
      "Take so long.\n",
      "Predicted Output: \n",
      "take so long\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey where r ü im here liao\n",
      "Actual Output: \n",
      "Hey, where are you? I'm here.\n",
      "Predicted Output: \n",
      "hey where are you i'm here already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi everyone hows ur day ?\n",
      "Actual Output: \n",
      "Hi everyone, how's your day?\n",
      "Predicted Output: \n",
      "hi everyone how's your day\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha- if no need make up ñ near my wkplace ñ not wk too late.can consider.tt is if ü can find such a place.ay,abt a mth ago she say she wk ere la. Hee-\n",
      "Actual Output: \n",
      "Haha. If no need to make up and near my workplace and does not work too late. Can consider. That is if you can find such a place. AY, about a month ago, she said she worked there.\n",
      "Predicted Output: \n",
      "haha if no need make up and near my workplace and not new too late can that is if you can find a place sorry about a month ago that say she next is but\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How i noe... Last time tis one is on offer wat...\n",
      "Actual Output: \n",
      "How I know. Last time this one is on offer.\n",
      "Predicted Output: \n",
      "how i know very time this one is for it what\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I reached already\n",
      "Actual Output: \n",
      "I reached already.\n",
      "Predicted Output: \n",
      "i reached already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haiyoh... It was so crowded... We didnt buy anything... Haha... Lots of pple in town. So mon we go facial with ü then go shopping?\n",
      "Actual Output: \n",
      "Ouch. It was so crowded. We didn't buy anything. Haha. There are lots of people in town. So Monday we go facial with you then go shopping?\n",
      "Predicted Output: \n",
      "thing was so crowded we didn't buy anything haha a of people in town so monday i go with you then go to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI MERINA NICE 2 CHAT WITH U. UR HP NO PLS. WHAT IS UR RACE?\n",
      "Actual Output: \n",
      "Hi Merina. It's nice to chat with you. Your hand phone number please. What is your race?\n",
      "Predicted Output: \n",
      "hi merina nice to chat with you your handphone no please what is your girl\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... After my drivin den free lor... Y?\n",
      "Actual Output: \n",
      "After my driving then I will be free. Why?\n",
      "Predicted Output: \n",
      "hmm after my is late free you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Erm anything lor...Can bring tmr? Thx =)\n",
      "Actual Output: \n",
      "Can anything be brought tomorrow? Thanks.\n",
      "Predicted Output: \n",
      "i anything can bring tomorrow that's\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Okay... they arent open on public holidays\n",
      "Actual Output: \n",
      "Okay. They aren't open on public holidays.\n",
      "Predicted Output: \n",
      "okay they accepted open on games\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... I'm carrying a broom with me so really paiseh to walk into lecture with it. I'm coming straight from home mah... Cya later then.\n",
      "Actual Output: \n",
      "Haha. I'm carrying a broom with me. So I'm really sorry to walk into lecture with it. I'm coming straight from home. See you later then.\n",
      "Predicted Output: \n",
      "haha i'm a with me so really sorry to to into another with it i'm coming password from home i'm see you then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... I'm watchin w my frens oredi... Paiseh...\n",
      "Actual Output: \n",
      "Hmm. I'm watching with my friends already. It's embarrassing.\n",
      "Predicted Output: \n",
      "hmm i'm watching with my friends\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey... Ü 've got driving today? my driving at 240.\n",
      "Actual Output: \n",
      "Hey. You have got driving today? My driving is at 2:40.\n",
      "Predicted Output: \n",
      "hey you got driving today my i at at\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "then it can moisturise our skin. and rub in circular motion. u wash face, tone,then put a bit of jelly and cream onto ur hand,and tap it on your face,\n",
      "Actual Output: \n",
      "Then it can moisturise our skin and rub in circular motion. You wash face, tone, then put a bit of jelly and cream onto your hand, and tap it on your face.\n",
      "Predicted Output: \n",
      "then it can our skin and in you haircut be then a a bit a of few for for and it on your be\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I'm pubbin now, gee, cant go online...After my drivin ah, hmmm, den where ur meetin....\n",
      "Actual Output: \n",
      "I'm in pub now. I can't go online. After my driving, then where are you meeting?\n",
      "Predicted Output: \n",
      "i'm to the i go go to my i i i is you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... Not accurate right....\n",
      "Actual Output: \n",
      "Haha. Not accurate, right?\n",
      "Predicted Output: \n",
      "haha not right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsqiQqLEtCnU",
    "outputId": "a57f6f15-a86f-4354-a88d-d4bc5b594ac1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2581911684267368, 0.21294807603873017, 0.14463972129203845, 0.7598356856515925, 0.4671379777282001, 0.5623413251903491, 0.30207246566144663, 0.23462350320528, 0.7598356856515925, 0.15909672318073625, 0.17122548504687662, 0.46199933699457096, 0.6389431042462724, 0.43012508513132625, 0.1828175732238544, 0.3081980909598119, 0.36177396082048563, 0.24573784957585945, 0.5502659908318907, 0]\n",
      "The Average Bleu Score is:  0.3605904404428826\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1tc_fxeuI6I"
   },
   "source": [
    "Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjUr0ohmqi8p",
    "outputId": "ae9694e9-5b1d-4b60-ab4e-f3cb8eec8468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 43, 512)           1896448   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 43, 200)           490400    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 43, 3033)          609633    \n",
      "=================================================================\n",
      "Total params: 2,996,481\n",
      "Trainable params: 2,996,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,512, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True))(embed)  \n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(lstm1)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "iXpqxfOhuNTz"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4g-6RMYuP_H",
    "outputId": "ef325ba3-aecc-4b96-e640-f1b6f3778a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 4s 865ms/step - loss: 7.6696 - accuracy: 0.3222 - val_loss: 5.3397 - val_accuracy: 0.6814\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 4.5154 - accuracy: 0.6737 - val_loss: 2.4947 - val_accuracy: 0.6814\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 2.7089 - accuracy: 0.6737 - val_loss: 2.7940 - val_accuracy: 0.6814\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 2.9144 - accuracy: 0.6737 - val_loss: 2.5952 - val_accuracy: 0.6814\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 2.7359 - accuracy: 0.6742 - val_loss: 2.3767 - val_accuracy: 0.6802\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.4859 - accuracy: 0.6713 - val_loss: 2.1571 - val_accuracy: 0.6767\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.2431 - accuracy: 0.6746 - val_loss: 2.0513 - val_accuracy: 0.6814\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.1384 - accuracy: 0.6804 - val_loss: 2.0430 - val_accuracy: 0.6907\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 2.1238 - accuracy: 0.6848 - val_loss: 2.1171 - val_accuracy: 0.6872\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 2.1175 - accuracy: 0.6847 - val_loss: 2.0871 - val_accuracy: 0.6872\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 2.1044 - accuracy: 0.6849 - val_loss: 2.0475 - val_accuracy: 0.6907\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.0834 - accuracy: 0.6873 - val_loss: 1.9701 - val_accuracy: 0.6907\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 2.0519 - accuracy: 0.6911 - val_loss: 1.9469 - val_accuracy: 0.6895\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 2.0203 - accuracy: 0.6912 - val_loss: 1.9451 - val_accuracy: 0.6872\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.9913 - accuracy: 0.6902 - val_loss: 1.9212 - val_accuracy: 0.6860\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.9605 - accuracy: 0.6923 - val_loss: 1.8990 - val_accuracy: 0.6907\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.9280 - accuracy: 0.6943 - val_loss: 1.8813 - val_accuracy: 0.6942\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.8964 - accuracy: 0.6971 - val_loss: 1.8585 - val_accuracy: 0.6953\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.8631 - accuracy: 0.7001 - val_loss: 1.8362 - val_accuracy: 0.7000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 1.8290 - accuracy: 0.7022 - val_loss: 1.8113 - val_accuracy: 0.7023\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.7940 - accuracy: 0.7051 - val_loss: 1.7887 - val_accuracy: 0.7058\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.7584 - accuracy: 0.7073 - val_loss: 1.7681 - val_accuracy: 0.7070\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 1.7228 - accuracy: 0.7107 - val_loss: 1.7467 - val_accuracy: 0.7070\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.6850 - accuracy: 0.7161 - val_loss: 1.7267 - val_accuracy: 0.7174\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.6486 - accuracy: 0.7207 - val_loss: 1.7093 - val_accuracy: 0.7233\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 1.6112 - accuracy: 0.7266 - val_loss: 1.6898 - val_accuracy: 0.7302\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 1.5730 - accuracy: 0.7339 - val_loss: 1.6672 - val_accuracy: 0.7372\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.5344 - accuracy: 0.7421 - val_loss: 1.6461 - val_accuracy: 0.7442\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 1.4959 - accuracy: 0.7480 - val_loss: 1.6250 - val_accuracy: 0.7512\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.4567 - accuracy: 0.7534 - val_loss: 1.6075 - val_accuracy: 0.7593\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 1.4181 - accuracy: 0.7596 - val_loss: 1.5918 - val_accuracy: 0.7640\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 1.3798 - accuracy: 0.7655 - val_loss: 1.5755 - val_accuracy: 0.7674\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 1.3417 - accuracy: 0.7719 - val_loss: 1.5621 - val_accuracy: 0.7767\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 1.3036 - accuracy: 0.7783 - val_loss: 1.5477 - val_accuracy: 0.7767\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.2660 - accuracy: 0.7841 - val_loss: 1.5371 - val_accuracy: 0.7756\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.2291 - accuracy: 0.7900 - val_loss: 1.5269 - val_accuracy: 0.7779\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 1.1923 - accuracy: 0.7963 - val_loss: 1.5147 - val_accuracy: 0.7791\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.1564 - accuracy: 0.8019 - val_loss: 1.5045 - val_accuracy: 0.7791\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 1.1213 - accuracy: 0.8075 - val_loss: 1.4951 - val_accuracy: 0.7802\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.0868 - accuracy: 0.8132 - val_loss: 1.4849 - val_accuracy: 0.7814\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 1.0525 - accuracy: 0.8183 - val_loss: 1.4780 - val_accuracy: 0.7826\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 1.0193 - accuracy: 0.8238 - val_loss: 1.4697 - val_accuracy: 0.7849\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.9866 - accuracy: 0.8288 - val_loss: 1.4615 - val_accuracy: 0.7837\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.9550 - accuracy: 0.8334 - val_loss: 1.4558 - val_accuracy: 0.7849\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.9244 - accuracy: 0.8370 - val_loss: 1.4431 - val_accuracy: 0.7826\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.8950 - accuracy: 0.8409 - val_loss: 1.4413 - val_accuracy: 0.7860\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.8660 - accuracy: 0.8443 - val_loss: 1.4315 - val_accuracy: 0.7895\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.8381 - accuracy: 0.8480 - val_loss: 1.4301 - val_accuracy: 0.7872\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.8116 - accuracy: 0.8509 - val_loss: 1.4286 - val_accuracy: 0.7895\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.7862 - accuracy: 0.8535 - val_loss: 1.4302 - val_accuracy: 0.7907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdd6569ab90>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "8VE32KpbuR-2"
   },
   "outputs": [],
   "source": [
    "x=model.predict(source_padded_docs_test[7:8])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "T373_iPAuVgd",
    "outputId": "5917cb9d-1991-4af5-d22b-9b2227d90273"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"how i know last time this one is on father's what <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "\n",
    "' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVToi8w8uXmD",
    "outputId": "0782f546-732d-40d8-ac34-6a91fb96ca8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128    How I know. Last time this one is on offer.\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[7:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCJBUmaiuaBc",
    "outputId": "4aa87a0b-3a81-4449-db4f-95332e9e9fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    How i noe... Last time tis one is on offer wat...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps4y3XayuccE",
    "outputId": "51f9e9f2-899c-4397-e2d6-cb2225924373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey i am still having breakfast eh. If you reach there first can help rebecca and me chope seats?\n",
      "Actual Output: \n",
      "I am still having breakfast. If you reach there first can you help me and Rebecca reserve seats?\n",
      "Predicted Output: \n",
      "hey i am still having work ask if you reach there first can help nap and me to and\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh ü take then how i take bus later... Inside got money a not...\n",
      "Actual Output: \n",
      "If you take then how I take bus later? Inside got money or not?\n",
      "Predicted Output: \n",
      "huh you take then how i to bus later you got money a or\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi neva worry bout da truth coz the truth will lead me 2 ur heart. It's the least a unique person like u deserve. Sleep tight or morning\n",
      "Actual Output: \n",
      "Hi, never worry about the truth because the truth will lead me to your heart. It's the least that a unique person like you deserve. Sleep tight or morning.\n",
      "Predicted Output: \n",
      "hi i worry about the because the will me to your like it's the school a you person like you lend sleep enjoy or number\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Take so long\n",
      "Actual Output: \n",
      "Take so long.\n",
      "Predicted Output: \n",
      "take so long\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey where r ü im here liao\n",
      "Actual Output: \n",
      "Hey, where are you? I'm here.\n",
      "Predicted Output: \n",
      "hey where are you are here you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi everyone hows ur day ?\n",
      "Actual Output: \n",
      "Hi everyone, how's your day?\n",
      "Predicted Output: \n",
      "hi everyone how's your day\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha- if no need make up ñ near my wkplace ñ not wk too late.can consider.tt is if ü can find such a place.ay,abt a mth ago she say she wk ere la. Hee-\n",
      "Actual Output: \n",
      "Haha. If no need to make up and near my workplace and does not work too late. Can consider. That is if you can find such a place. AY, about a month ago, she said she worked there.\n",
      "Predicted Output: \n",
      "haha if no need make up and near my workplace and is house too late can just that is if you can find a a of about a month ago she she she week a she\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How i noe... Last time tis one is on offer wat...\n",
      "Actual Output: \n",
      "How I know. Last time this one is on offer.\n",
      "Predicted Output: \n",
      "how i know last time this one is on father's what\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I reached already\n",
      "Actual Output: \n",
      "I reached already.\n",
      "Predicted Output: \n",
      "i reached already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haiyoh... It was so crowded... We didnt buy anything... Haha... Lots of pple in town. So mon we go facial with ü then go shopping?\n",
      "Actual Output: \n",
      "Ouch. It was so crowded. We didn't buy anything. Haha. There are lots of people in town. So Monday we go facial with you then go shopping?\n",
      "Predicted Output: \n",
      "i it was so i'll we didn't buy anything haha today of people in town so monday we go with you then go go to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI MERINA NICE 2 CHAT WITH U. UR HP NO PLS. WHAT IS UR RACE?\n",
      "Actual Output: \n",
      "Hi Merina. It's nice to chat with you. Your hand phone number please. What is your race?\n",
      "Predicted Output: \n",
      "hi merina nice to chat with you your hand no please please is your say\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... After my drivin den free lor... Y?\n",
      "Actual Output: \n",
      "After my driving then I will be free. Why?\n",
      "Predicted Output: \n",
      "hmm after my then free you haha\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Erm anything lor...Can bring tmr? Thx =)\n",
      "Actual Output: \n",
      "Can anything be brought tomorrow? Thanks.\n",
      "Predicted Output: \n",
      "i anything anything can bring tomorrow tomorrow\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Okay... they arent open on public holidays\n",
      "Actual Output: \n",
      "Okay. They aren't open on public holidays.\n",
      "Predicted Output: \n",
      "okay they nama open on public is\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... I'm carrying a broom with me so really paiseh to walk into lecture with it. I'm coming straight from home mah... Cya later then.\n",
      "Actual Output: \n",
      "Haha. I'm carrying a broom with me. So I'm really sorry to walk into lecture with it. I'm coming straight from home. See you later then.\n",
      "Predicted Output: \n",
      "haha i'm a with me so really sorry to for the lecture with it i'm coming rather from home i you later then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... I'm watchin w my frens oredi... Paiseh...\n",
      "Actual Output: \n",
      "Hmm. I'm watching with my friends already. It's embarrassing.\n",
      "Predicted Output: \n",
      "hmm i'm watching with my friends already friends\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey... Ü 've got driving today? my driving at 240.\n",
      "Actual Output: \n",
      "Hey. You have got driving today? My driving is at 2:40.\n",
      "Predicted Output: \n",
      "hey you got have today my driving at 2\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "then it can moisturise our skin. and rub in circular motion. u wash face, tone,then put a bit of jelly and cream onto ur hand,and tap it on your face,\n",
      "Actual Output: \n",
      "Then it can moisturise our skin and rub in circular motion. You wash face, tone, then put a bit of jelly and cream onto your hand, and tap it on your face.\n",
      "Predicted Output: \n",
      "then it can our let's and in you having one be a a a a and quite a first and it on a one\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I'm pubbin now, gee, cant go online...After my drivin ah, hmmm, den where ur meetin....\n",
      "Actual Output: \n",
      "I'm in pub now. I can't go online. After my driving, then where are you meeting?\n",
      "Predicted Output: \n",
      "i'm i now now can't then i after my later haha haha then where you you\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... Not accurate right....\n",
      "Actual Output: \n",
      "Haha. Not accurate, right?\n",
      "Predicted Output: \n",
      "haha not right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HTs2bpuv50q",
    "outputId": "9a41d4b9-503a-4043-b53b-a45eeb80f22b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27447938256311044, 0.22718709780542318, 0.3312232008397192, 0.7598356856515925, 0.4671379777282001, 0.5623413251903491, 0.30228791143745415, 0.3508439695638686, 0.7598356856515925, 0.16527975033438158, 0.17795291340072017, 0.5494128986804837, 0.6147881529512643, 0.4111336169005197, 0.22265046674893665, 0.3050975216056289, 0.6537993517025207, 0.3201518925576873, 0.37991784282579627, 0]\n",
      "The Average Bleu Score is:  0.39176783220696243\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentence_correction_wordleverl_manytomany.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
