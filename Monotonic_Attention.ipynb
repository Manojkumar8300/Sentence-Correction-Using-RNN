{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7FO0jbdLNe",
    "outputId": "e800a144-e439-410e-f444-b56f0c0422d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 43.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "L8fjyOdpdLRC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "vwVkeKqQdLTt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "w24_JGmDdLWL",
    "outputId": "2bd921da-356b-4458-8f1d-d67397358b97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "FOLd0rnFdLjx"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "I2MMzLqQdLms",
    "outputId": "3cfd82fd-53e4-4a33-d944-5161b9dd7ce3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLbB1qx6oja7",
    "outputId": "f39fe428-13ec-45bb-c35b-07bc612e2810"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Kn8IMU4LoZSW"
   },
   "outputs": [],
   "source": [
    "def length(text):#for calculating the length of the sentence\n",
    "    return len(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "MlN7BR2tdLqK"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(length)<170]\n",
    "df=df[df['target'].apply(length)<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJiyjBaZfbqD",
    "outputId": "404f8acb-1d66-44a9-e22f-b649e37f3d1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sFhX3qniszPG",
    "outputId": "0f6633dc-f634-4e00-e7be-50bd620f48c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "      <td>&lt;start&gt; Hi! How did your week go? Haven't hear...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "4  Hi! How did your week go? Haven heard from you...  ...  Hi! How did your week go? Haven't heard from y...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target_in'] = '<start> ' + df['target'].astype(str)\n",
    "df['target_out'] = df['target'].astype(str) + ' <end>'\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "boQSuOdzszZf"
   },
   "outputs": [],
   "source": [
    "df=df.drop('target',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "2IZQxQheF1Ew",
    "outputId": "af978dd9-8458-4c84-f64a-acaa5226b7ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target_in</th>\n",
       "      <th>target_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>&lt;start&gt; Do you want me to reserve seat for you...</td>\n",
       "      <td>Do you want me to reserve seat for you or not?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>&lt;start&gt; Yeap. You reaching? We ordered some Du...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>&lt;start&gt; They become more expensive already. Mi...</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>&lt;start&gt; I'm Thai. What do you do?</td>\n",
       "      <td>I'm Thai. What do you do? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  ...                                         target_out\n",
       "0                    U wan me to \"chop\" seat 4 u nt?  ...  Do you want me to reserve seat for you or not?...\n",
       "1  Yup. U reaching. We order some durian pastry a...  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  ...  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?  ...                    I'm Thai. What do you do? <end>\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "zY_3AB8NF_zb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(df, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9dvlVbGGNzp",
    "outputId": "b72ff5ab-495e-4870-fa3d-109e2fb6dbd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 3) (20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, validation.shape)\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['target_in']= str(train.iloc[0]['target_in'])+' <end>'\n",
    "train.iloc[0]['target_out']= str(train.iloc[0]['target_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "r7unX08JGY7i"
   },
   "outputs": [],
   "source": [
    "tknizer_source = Tokenizer()\n",
    "tknizer_source.fit_on_texts(train['source'].values)\n",
    "tknizer_target = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_target.fit_on_texts(train['target_in'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdrwjwt3G1U_",
    "outputId": "bd3fe213-fcb0-4b7b-c61e-17b8feca35e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3029\n",
      "3698\n"
     ]
    }
   ],
   "source": [
    "vocab_size_target=len(tknizer_target.word_index.keys())\n",
    "print(vocab_size_target)\n",
    "vocab_size_source=len(tknizer_source.word_index.keys())\n",
    "print(vocab_size_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5VU3LonHHh-",
    "outputId": "d625ff07-34ee-4147-f142-f48718468249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1439)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_target.word_index['<start>'], tknizer_target.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "HMPfMXTaHQ2T"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "        self.vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_length = input_length\n",
    "        self.lstm_size= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
    "                           mask_zero=True,name=\"embedding_layer_encoder\")\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "\n",
    "      '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer oupulstm_state_h,lstm_state_ct to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "      '''\n",
    "      \n",
    "      input_embedd                           = self.embedding(input_sequence)\n",
    "      lstm_state_h,lstm_state_c= states[0],states[1]\n",
    "      self.lstm_output,lstm_state_h,lstm_state_c=self.lstm(input_embedd)\n",
    "      return self.lstm_output,lstm_state_h,lstm_state_c\n",
    "\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "      '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "      return [tf.zeros((batch_size,self.lstm_size)),tf.zeros((batch_size,self.lstm_size))]\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "adsqBmXWl8Fu"
   },
   "outputs": [],
   "source": [
    "#https://github.com/UdiBhaskar/TfKeras-Custom-Layers/blob/master/Seq2Seq/clayers.py\n",
    "def _attention_score(dec_ht,\n",
    "                     enc_hs,\n",
    "                     attention_type,\n",
    "                     weightwa=None,\n",
    "                     weightua=None,\n",
    "                     weightva=None):\n",
    "    if attention_type == 'bahdanau':\n",
    "        score = weightva(tf.nn.tanh(weightwa(dec_ht) + weightua(enc_hs)))\n",
    "        score = tf.squeeze(score, [2])\n",
    "    elif attention_type == 'dot':\n",
    "        score = tf.matmul(dec_ht, enc_hs, transpose_b=True)\n",
    "        score = tf.squeeze(score, 1)\n",
    "    elif attention_type == 'general':\n",
    "        score = weightwa(enc_hs)\n",
    "        score = tf.matmul(dec_ht, score, transpose_b=True)\n",
    "        score = tf.squeeze(score, 1)\n",
    "    elif attention_type == 'concat':\n",
    "        dec_ht = tf.tile(dec_ht, [1, enc_hs.shape[1], 1])\n",
    "        score = weightva(tf.nn.tanh(weightwa(tf.concat((dec_ht, enc_hs), axis=-1))))\n",
    "        score = tf.squeeze(score, 2)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "0nTD6BW9zkck"
   },
   "outputs": [],
   "source": [
    "def _monotonic_attetion(probabilities, attention_prev, mode):\n",
    "\n",
    "    \"\"\"Compute monotonic attention distribution from choosing probabilities.\n",
    "    Implemented Based on -\n",
    "    https://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html\n",
    "    https://arxiv.org/pdf/1704.00784.pdf\n",
    "    Mainly implemented by referring\n",
    "    https://github.com/craffel/mad/blob/b3687a70615044359c8acc440e43a5e23dc58309/example_decoder.py#L22\n",
    "    # Arguments:\n",
    "        probabilities: Probability of choosing input sequence..\n",
    "                       Should be of shape (batch_size, max_length),\n",
    "                       and should all be in the range [0, 1].\n",
    "        attention_prev: The attention distribution from the previous output timestep.\n",
    "                            Should be of shape (batch_size, max_length).\n",
    "                            For the first output timestep,\n",
    "                            should be [1, 0, 0, ...,0] for all n in [0, ... batch_size - 1].\n",
    "        mode: How to compute the attention distribution.\n",
    "              Must be one of 'recursive', 'parallel', or 'hard'.\n",
    "              - 'recursive' uses tf.scan to recursively compute the distribution.\n",
    "              This is slowest but is exact, general, and does not suffer from\n",
    "              numerical instabilities.\n",
    "              - 'parallel' uses parallelized cumulative-sum and cumulative-product\n",
    "              operations to compute a closed-form solution to the recurrence relation\n",
    "              defining the attention distribution.  This makes it more efficient than 'recursive',\n",
    "              but it requires numerical checks which make the distribution non-exact.\n",
    "              This can be a problem in particular when max_length is long and/or\n",
    "              probabilities has entries very close to 0 or 1.\n",
    "              - 'hard' requires that  the probabilities in p_choose_i are all either 0 or 1,\n",
    "              and subsequently uses a more efficient and exact solution.\n",
    "    # Returns: A tensor of shape (batch_size, max_length) representing the attention distributions\n",
    "               for each sequence in the batch.\n",
    "    # Raises:\n",
    "             ValueError: if mode is not one of 'recursive', 'parallel', 'hard'.\"\"\"\n",
    "    if mode == 'hard':\n",
    "        #Remove any probabilities before the index chosen last time step\n",
    "        probabilities = probabilities*tf.cumsum(attention_prev, axis=1)\n",
    "        attention = probabilities*tf.math.cumprod(1-probabilities, axis=1, exclusive=True)\n",
    "    elif mode == 'recursive':\n",
    "        batch_size = tf.shape(input=probabilities)[0]\n",
    "        shifted_1mp_probabilities = tf.concat([tf.ones((batch_size, 1)),\\\n",
    "            1 - probabilities[:, :-1]], 1)\n",
    "        attention = probabilities*tf.transpose(a=tf.scan(lambda x, yz: tf.reshape(yz[0]*x + yz[1],\\\n",
    "            (batch_size,)), [tf.transpose(a=shifted_1mp_probabilities),\\\n",
    "                tf.transpose(a=attention_prev)], tf.zeros((batch_size,))))\n",
    "    elif mode == 'parallel':\n",
    "        cumprod_1mp_probabilities = tf.exp(tf.cumsum(tf.math.log(tf.clip_by_value(1-probabilities,\\\n",
    "            1e-10, 1)), axis=1, exclusive=True))\n",
    "        attention = probabilities*cumprod_1mp_probabilities*tf.cumsum(attention_prev/\\\n",
    "            tf.clip_by_value(cumprod_1mp_probabilities, 1e-10, 1.), axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'hard', 'parallel' or 'recursive' \")\n",
    "\n",
    "    return attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "GXR_0iYHzrkr"
   },
   "outputs": [],
   "source": [
    "class MonotonicBahdanauAttention(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    MonotonicBahdanauAttention\n",
    "    Implemented based on below paper\n",
    "        https://arxiv.org/pdf/1704.00784.pdf\n",
    "    # Arguments\n",
    "        units = number of hidden units to use.\n",
    "        mode = How to compute the attention distribution.\n",
    "              Must be one of 'recursive', 'parallel', or 'hard'.\n",
    "              - 'recursive' uses tf.scan to recursively compute the distribution.\n",
    "              This is slowest but is exact, general, and does not suffer from\n",
    "              numerical instabilities.\n",
    "              - 'parallel' uses parallelized cumulative-sum and cumulative-product\n",
    "              operations to compute a closed-form solution to the recurrence relation\n",
    "              defining the attention distribution.  This makes it more efficient than 'recursive',\n",
    "              but it requires numerical checks which make the distribution non-exact.\n",
    "              This can be a problem in particular when max_length is long and/or\n",
    "              probabilities has entries very close to 0 or 1.\n",
    "              - 'hard' requires that  the probabilities in p_choose_i are all either 0 or 1,\n",
    "              and subsequently uses a more efficient and exact solution.\n",
    "        return_aweights = Bool, whether to return attention weights or not.\n",
    "        scaling_factor = int/float to scale the score vector. default None=1\n",
    "        noise_std = standard deviation of noise which will be added before\n",
    "                    applying sigmoid function.(pre-sigmoid noise). If it is 0 or\n",
    "                    mode=\"hard\", we won't add any noise.\n",
    "        weights_initializer = initializer for weight matrix\n",
    "        weights_regularizer = Regularize the weights\n",
    "        weights_constraint = Constraint function applied to the weights\n",
    "    # Returns\n",
    "        context_vector = context vector after applying attention.\n",
    "        attention_weights = attention weights only if `return_aweights=True`.\n",
    "    # Inputs to the layer\n",
    "        inputs = dictionary with keys \"enocderHs\", \"decoderHt\", \"prevAttention\".\n",
    "                enocderHs = all the encoder hidden states,\n",
    "                            shape - (Batchsize, encoder_seq_len, enc_hidden_size)\n",
    "                decoderHt = hidden state of decoder at that timestep,\n",
    "                            shape - (Batchsize, dec_hidden_size)\n",
    "                prevAttention = Previous probability distribution of attention\n",
    "                                (previous attention weights)\n",
    "        mask = You can apply mask for padded values or any custom values\n",
    "               while calculating attention.\n",
    "               if you are giving mask for encoder and deocoder then you have\n",
    "               to give a dict similar to inputs. (keys: enocderHs, decoderHt)\n",
    "               else you can give only for enocoder normally.(one tensor)\n",
    "               mask shape should be (Batchsize, encoder_seq_len)\n",
    "    '''\n",
    " \n",
    "    def __init__(self, units,\n",
    "                 mode='parallel',\n",
    "                 return_aweights=False,\n",
    "                 scaling_factor=None,\n",
    "                 noise_std=0,\n",
    "                 weights_initializer='he_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 weights_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 weights_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        if 'name' not in kwargs:\n",
    "            kwargs['name'] = \"\"\n",
    "        super(MonotonicBahdanauAttention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.mode = mode\n",
    "        self.return_aweights = return_aweights\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.noise_std = noise_std\n",
    "        self.weights_initializer = tf.keras.initializers.get(weights_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.weights_regularizer = tf.keras.regularizers.get(weights_regularizer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.weights_constraint = tf.keras.constraints.get(weights_constraint)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "        self._wa = tf.keras.layers.Dense(self.units, use_bias=False,\\\n",
    "            kernel_initializer=weights_initializer, bias_initializer=bias_initializer,\\\n",
    "                kernel_regularizer=weights_regularizer, bias_regularizer=bias_regularizer,\\\n",
    "                    kernel_constraint=weights_constraint, bias_constraint=bias_constraint,\\\n",
    "                        name=self.name+\"Wa\")\n",
    "        self._ua = tf.keras.layers.Dense(self.units,\\\n",
    "            kernel_initializer=weights_initializer, bias_initializer=bias_initializer,\\\n",
    "                kernel_regularizer=weights_regularizer, bias_regularizer=bias_regularizer,\\\n",
    "                    kernel_constraint=weights_constraint, bias_constraint=bias_constraint,\\\n",
    "                        name=self.name+\"Ua\")\n",
    "        self._va = tf.keras.layers.Dense(1, use_bias=False, kernel_initializer=weights_initializer,\\\n",
    "            kernel_regularizer=weights_regularizer, bias_regularizer=bias_regularizer,\\\n",
    "                bias_initializer=bias_initializer, kernel_constraint=weights_constraint,\\\n",
    "                    bias_constraint=bias_constraint, name=self.name+\"Va\")\n",
    "        self.supports_masking = True\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''call'''\n",
    "        #assert isinstance(inputs, dict)\n",
    "       \n",
    " \n",
    "        if ('enocderHs' not in inputs.keys())or ('decoderHt' not in inputs.keys()\\\n",
    "            or 'prevAttention' not in inputs.keys()):\n",
    "            raise ValueError(\"Input to the layer must be a dict with \\\n",
    "            keys=['enocderHs','decoderHt', 'prevAttention']\")\n",
    " \n",
    "        #if isinstance(mask, dict):\n",
    "        #   mask_enc = mask.get('enocderHs', None)\n",
    "        #   mask_dec = mask.get('decoderHt', None)\n",
    "        #else:\n",
    "        #    mask_enc = mask\n",
    "        #    mask_dec = None\n",
    "        enc_out, dec_prev_hs = tf.cast(inputs['enocderHs'], tf.float32), \\\n",
    "            tf.cast(inputs['decoderHt'], tf.float32)\n",
    " \n",
    "        prev_attention = inputs['prevAttention']\n",
    "      \n",
    " \n",
    "        #if mask_dec is not None:\n",
    "           # dec_prev_hs = dec_prev_hs * tf.cast(mask_dec, dec_prev_hs.dtype)\n",
    "        #if mask_enc is not None:\n",
    "           # enc_out = enc_out * tf.cast(tf.expand_dims(mask_enc, 2), enc_out.dtype)\n",
    " \n",
    "        # decprev_hs - Decoder hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        dec_hidden_with_time_axis = tf.expand_dims(dec_prev_hs, 1)\n",
    "       \n",
    " \n",
    "        # score shape == (batch_size, max_length)\n",
    "        score = _attention_score(dec_ht=dec_hidden_with_time_axis, enc_hs=enc_out,\\\n",
    "                    attention_type='concat', weightwa=self._wa,\\\n",
    "                        weightua=self._ua, weightva=self._va)\n",
    " \n",
    "        if self.scaling_factor is not None:\n",
    "            score = score/tf.sqrt(self.scaling_factor)\n",
    " \n",
    "        if training:\n",
    "            if self.noise_std > 0:\n",
    "                random_noise = tf.random.normal(shape=tf.shape(input=score), mean=0,\\\n",
    "                    stddev=self.noise_std, dtype=score.dtype, seed=self.seed)\n",
    "                score = score + random_noise\n",
    " \n",
    "        #if mask_enc is not None:\n",
    "        #    score = score + (tf.cast(tf.math.equal(mask_enc, False), score.dtype)*-1e9)\n",
    " \n",
    "        if self.mode == 'hard':\n",
    "            probabilities = tf.cast(score > 0, score.dtype)\n",
    "        else:\n",
    "            probabilities = tf.sigmoid(score)\n",
    " \n",
    "        attention_weights = _monotonic_attetion(probabilities, prev_attention, self.mode)\n",
    "        attention_weights = tf.expand_dims(attention_weights, 1)\n",
    " \n",
    "        #context_vector shape (batch_size, hidden_size)\n",
    "        context_vector = tf.matmul(attention_weights, enc_out)\n",
    "        context_vector = tf.squeeze(context_vector, 1, name=\"context_vector\")\n",
    " \n",
    "        if self.return_aweights:\n",
    "         \n",
    "            return context_vector, tf.squeeze(attention_weights, 1, name='attention_weights')\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "DhNfgUq-H0SF"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,mode ,att_units):\n",
    "\n",
    "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "      super().__init__()\n",
    "      self.tar_vocab_size = tar_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length \n",
    "      self.dec_units = dec_units\n",
    "      self.mode = mode\n",
    "      self.att_units = att_units\n",
    "      # we are using embedding_matrix and not training the embedding layer\n",
    "      self.embedding = tf.keras.layers.Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True,name=\"embedding_layer_decoder\")\n",
    "      self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
    "      self.dense = tf.keras.layers.Dense(self.tar_vocab_size)\n",
    "      self.attention = MonotonicBahdanauAttention(self.att_units,mode=self.mode,return_aweights=True)\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c,attention_weights):\n",
    "\n",
    "   \n",
    "    inputs= dict()\n",
    "    inputs['enocderHs']=encoder_output\n",
    "    inputs['decoderHt']=state_h\n",
    "    inputs['prevAttention']=attention_weights\n",
    "\n",
    "    output = self.embedding(input_to_decoder)\n",
    "    context_vector,attention_weights = self.attention(inputs)\n",
    "    context_vector1 = tf.expand_dims(context_vector,1)\n",
    "    concat = tf.concat([output,context_vector1],axis=-1)\n",
    "    decoder_output,state_h,state_c = self.lstm(concat,initial_state=[state_h,state_c])\n",
    "    final_output = self.dense(decoder_output)\n",
    "    final_output = tf.reshape(final_output,(-1,final_output.shape[2]))\n",
    "    return final_output,state_h,state_c,attention_weights,context_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "97Rryo9n8VRH"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,mode ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super(Decoder,self).__init__()\n",
    "      self.vocab_size = out_vocab_size\n",
    "      self.embedding_dim = embedding_dim\n",
    "      self.input_length = input_length\n",
    "      self.dec_units=dec_units\n",
    "      self.att_units=att_units\n",
    "      self.mode=mode\n",
    "      self.onestepdecoder=One_Step_Decoder(self.vocab_size,self.embedding_dim,self.input_length,self.dec_units ,self.mode ,self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state,attention_weights ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        all_outputs=tf.TensorArray(tf.float32,size=tf.shape(input_to_decoder)[1])\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        #Iterate till the length of the decoder input\n",
    "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            output,state_h,state_c,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],encoder_output,decoder_hidden_state,decoder_cell_state,attention_weights)\n",
    "\n",
    "            # Store the output in tensorarray\n",
    "            all_outputs=all_outputs.write(timestep,output)\n",
    "        all_outputs=tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        # Return the tensor array\n",
    "        return all_outputs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "3Up5Qc-O8ZNa"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size,mode):\n",
    "    #Intialize objects from encoder decoder\n",
    "    super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "    self.batch_size=batch_size\n",
    "    self.encoder_inputs_length=encoder_inputs_length\n",
    "    self.decoder_inputs_length=decoder_inputs_length\n",
    "    self.encoder = Encoder(vocab_size_source+1,300,128,self.encoder_inputs_length)\n",
    "    self.decoder = Decoder(vocab_size_target+1,300,self.decoder_inputs_length,128,mode,128)\n",
    "    \n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    input,output = data[0], data[1]\n",
    "    attention_weights = np.zeros((self.batch_size,self.encoder_inputs_length),dtype='float32')\n",
    "    attention_weights[:,0]=1\n",
    "    initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "    encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
    "    decoder_output= self.decoder(output, encoder_output, encoder_h, encoder_c,attention_weights)\n",
    "    return decoder_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "2UaWKKXL8cNb"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
    "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "preo2243H7Qh"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, tknizer_source, tknizer_target, source_len,target_len):\n",
    "        self.encoder_inps = df['source'].values\n",
    "        self.decoder_inps = df['target_in'].values\n",
    "        self.decoder_outs = df['target_out'].values\n",
    "        self.tknizer_target = tknizer_target\n",
    "        self.tknizer_source = tknizer_source\n",
    "        self.source_len = source_len\n",
    "        self.target_len = target_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_source.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_target.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_target.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.source_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.target_len, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hahhnu0PIgjo",
    "outputId": "a3b25a9a-77d6-4af4-e7f7-5098a3c8a15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 39) (512, 39) (512, 39)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_source, tknizer_target,39,39)\n",
    "test_dataset  = Dataset(validation, tknizer_source, tknizer_target,39,39)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=20)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3mtq-6TI62z",
    "outputId": "e9e948d6-c533-4831-8288-89199001c622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-83-bdb3352f611a>:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "XToH15GbJCHI"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIx_zCBDJEKu",
    "outputId": "42f52f03-afb2-4884-9711-c1b274545df8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/260\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 3.0825\n",
      "Epoch 2/260\n",
      "3/3 [==============================] - 2s 765ms/step - loss: 2.5597\n",
      "Epoch 3/260\n",
      "3/3 [==============================] - 2s 792ms/step - loss: 2.4022\n",
      "Epoch 4/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 2.3590\n",
      "Epoch 5/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 2.3331\n",
      "Epoch 6/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 2.3062\n",
      "Epoch 7/260\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 2.2742\n",
      "Epoch 8/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 2.2484\n",
      "Epoch 9/260\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 2.2178\n",
      "Epoch 10/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 2.1843\n",
      "Epoch 11/260\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 2.1481\n",
      "Epoch 12/260\n",
      "3/3 [==============================] - 2s 796ms/step - loss: 2.1150\n",
      "Epoch 13/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 2.0810\n",
      "Epoch 14/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 2.0482\n",
      "Epoch 15/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 2.0164\n",
      "Epoch 16/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 1.9865\n",
      "Epoch 17/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 1.9572\n",
      "Epoch 18/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 1.9336\n",
      "Epoch 19/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 1.9052\n",
      "Epoch 20/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 1.8785\n",
      "Epoch 21/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 1.8536\n",
      "Epoch 22/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 1.8336\n",
      "Epoch 23/260\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 1.8096\n",
      "Epoch 24/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 1.7856\n",
      "Epoch 25/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.7616\n",
      "Epoch 26/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 1.7424\n",
      "Epoch 27/260\n",
      "3/3 [==============================] - 2s 779ms/step - loss: 1.7244\n",
      "Epoch 28/260\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 1.7009\n",
      "Epoch 29/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 1.6814\n",
      "Epoch 30/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 1.6587\n",
      "Epoch 31/260\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 1.6414\n",
      "Epoch 32/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 1.6219\n",
      "Epoch 33/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 1.6019\n",
      "Epoch 34/260\n",
      "3/3 [==============================] - 2s 745ms/step - loss: 1.5812\n",
      "Epoch 35/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 1.5608\n",
      "Epoch 36/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 1.5435\n",
      "Epoch 37/260\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 1.5222\n",
      "Epoch 38/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 1.5047\n",
      "Epoch 39/260\n",
      "3/3 [==============================] - 2s 810ms/step - loss: 1.4891\n",
      "Epoch 40/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 1.4701\n",
      "Epoch 41/260\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 1.4510\n",
      "Epoch 42/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 1.4390\n",
      "Epoch 43/260\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 1.4195\n",
      "Epoch 44/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 1.4016\n",
      "Epoch 45/260\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 1.3860\n",
      "Epoch 46/260\n",
      "3/3 [==============================] - 2s 811ms/step - loss: 1.3689\n",
      "Epoch 47/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 1.3540\n",
      "Epoch 48/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 1.3412\n",
      "Epoch 49/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 1.3250\n",
      "Epoch 50/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 1.3122\n",
      "Epoch 51/260\n",
      "3/3 [==============================] - 2s 752ms/step - loss: 1.2980\n",
      "Epoch 52/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 1.2844\n",
      "Epoch 53/260\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 1.2699\n",
      "Epoch 54/260\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 1.2544\n",
      "Epoch 55/260\n",
      "3/3 [==============================] - 2s 800ms/step - loss: 1.2422\n",
      "Epoch 56/260\n",
      "3/3 [==============================] - 2s 750ms/step - loss: 1.2350\n",
      "Epoch 57/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 1.2259\n",
      "Epoch 58/260\n",
      "3/3 [==============================] - 2s 755ms/step - loss: 1.2133\n",
      "Epoch 59/260\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 1.1994\n",
      "Epoch 60/260\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 1.1835\n",
      "Epoch 61/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 1.1678\n",
      "Epoch 62/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 1.1542\n",
      "Epoch 63/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.1408\n",
      "Epoch 64/260\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 1.1303\n",
      "Epoch 65/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.1190\n",
      "Epoch 66/260\n",
      "3/3 [==============================] - 2s 720ms/step - loss: 1.1053\n",
      "Epoch 67/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 1.0932\n",
      "Epoch 68/260\n",
      "3/3 [==============================] - 2s 800ms/step - loss: 1.0818\n",
      "Epoch 69/260\n",
      "3/3 [==============================] - 2s 728ms/step - loss: 1.0692\n",
      "Epoch 70/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 1.0593\n",
      "Epoch 71/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 1.0474\n",
      "Epoch 72/260\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 1.0372\n",
      "Epoch 73/260\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 1.0254\n",
      "Epoch 74/260\n",
      "3/3 [==============================] - 2s 758ms/step - loss: 1.0177\n",
      "Epoch 75/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.0073\n",
      "Epoch 76/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.9988\n",
      "Epoch 77/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.9863\n",
      "Epoch 78/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.9771\n",
      "Epoch 79/260\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 0.9656\n",
      "Epoch 80/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.9548\n",
      "Epoch 81/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.9427\n",
      "Epoch 82/260\n",
      "3/3 [==============================] - 2s 736ms/step - loss: 0.9296\n",
      "Epoch 83/260\n",
      "3/3 [==============================] - 2s 795ms/step - loss: 0.9243\n",
      "Epoch 84/260\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 0.9167\n",
      "Epoch 85/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.9074\n",
      "Epoch 86/260\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.9134\n",
      "Epoch 87/260\n",
      "3/3 [==============================] - 2s 757ms/step - loss: 0.8936\n",
      "Epoch 88/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.8800\n",
      "Epoch 89/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.8719\n",
      "Epoch 90/260\n",
      "3/3 [==============================] - 2s 750ms/step - loss: 0.8589\n",
      "Epoch 91/260\n",
      "3/3 [==============================] - 3s 759ms/step - loss: 0.8473\n",
      "Epoch 92/260\n",
      "3/3 [==============================] - 2s 751ms/step - loss: 0.8349\n",
      "Epoch 93/260\n",
      "3/3 [==============================] - 2s 762ms/step - loss: 0.8262\n",
      "Epoch 94/260\n",
      "3/3 [==============================] - 3s 843ms/step - loss: 0.8144\n",
      "Epoch 95/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.8019\n",
      "Epoch 96/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.7936\n",
      "Epoch 97/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.7820\n",
      "Epoch 98/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 0.7730\n",
      "Epoch 99/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.7635\n",
      "Epoch 100/260\n",
      "3/3 [==============================] - 2s 736ms/step - loss: 0.7517\n",
      "Epoch 101/260\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 0.7427\n",
      "Epoch 102/260\n",
      "3/3 [==============================] - 2s 735ms/step - loss: 0.7307\n",
      "Epoch 103/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.7200\n",
      "Epoch 104/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.7092\n",
      "Epoch 105/260\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.7016\n",
      "Epoch 106/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.6892\n",
      "Epoch 107/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.6790\n",
      "Epoch 108/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.6677\n",
      "Epoch 109/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.6590\n",
      "Epoch 110/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.6492\n",
      "Epoch 111/260\n",
      "3/3 [==============================] - 2s 788ms/step - loss: 0.6381\n",
      "Epoch 112/260\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.6309\n",
      "Epoch 113/260\n",
      "3/3 [==============================] - 2s 720ms/step - loss: 0.6218\n",
      "Epoch 114/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.6116\n",
      "Epoch 115/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.6065\n",
      "Epoch 116/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.5983\n",
      "Epoch 117/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.5883\n",
      "Epoch 118/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.5786\n",
      "Epoch 119/260\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.5712\n",
      "Epoch 120/260\n",
      "3/3 [==============================] - 2s 787ms/step - loss: 0.5622\n",
      "Epoch 121/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.5538\n",
      "Epoch 122/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.5455\n",
      "Epoch 123/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.5339\n",
      "Epoch 124/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.5258\n",
      "Epoch 125/260\n",
      "3/3 [==============================] - 2s 799ms/step - loss: 0.5153\n",
      "Epoch 126/260\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 0.5045\n",
      "Epoch 127/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.4963\n",
      "Epoch 128/260\n",
      "3/3 [==============================] - 2s 744ms/step - loss: 0.4880\n",
      "Epoch 129/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.4813\n",
      "Epoch 130/260\n",
      "3/3 [==============================] - 2s 745ms/step - loss: 0.4716\n",
      "Epoch 131/260\n",
      "3/3 [==============================] - 2s 720ms/step - loss: 0.4632\n",
      "Epoch 132/260\n",
      "3/3 [==============================] - 2s 778ms/step - loss: 0.4572\n",
      "Epoch 133/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.4472\n",
      "Epoch 134/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.4380\n",
      "Epoch 135/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.4292\n",
      "Epoch 136/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.4223\n",
      "Epoch 137/260\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.4145\n",
      "Epoch 138/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.4066\n",
      "Epoch 139/260\n",
      "3/3 [==============================] - 2s 745ms/step - loss: 0.3993\n",
      "Epoch 140/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.3921\n",
      "Epoch 141/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.3874\n",
      "Epoch 142/260\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 0.3793\n",
      "Epoch 143/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.3721\n",
      "Epoch 144/260\n",
      "3/3 [==============================] - 2s 748ms/step - loss: 0.3646\n",
      "Epoch 145/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.3578\n",
      "Epoch 146/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.3510\n",
      "Epoch 147/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.3473\n",
      "Epoch 148/260\n",
      "3/3 [==============================] - 2s 808ms/step - loss: 0.3403\n",
      "Epoch 149/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.3338\n",
      "Epoch 150/260\n",
      "3/3 [==============================] - 2s 743ms/step - loss: 0.3298\n",
      "Epoch 151/260\n",
      "3/3 [==============================] - 2s 740ms/step - loss: 0.3219\n",
      "Epoch 152/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.3180\n",
      "Epoch 153/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.3127\n",
      "Epoch 154/260\n",
      "3/3 [==============================] - 2s 778ms/step - loss: 0.3059\n",
      "Epoch 155/260\n",
      "3/3 [==============================] - 2s 728ms/step - loss: 0.2986\n",
      "Epoch 156/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.2926\n",
      "Epoch 157/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.2884\n",
      "Epoch 158/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.2821\n",
      "Epoch 159/260\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 0.2776\n",
      "Epoch 160/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.2717\n",
      "Epoch 161/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.2672\n",
      "Epoch 162/260\n",
      "3/3 [==============================] - 2s 716ms/step - loss: 0.2624\n",
      "Epoch 163/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.2560\n",
      "Epoch 164/260\n",
      "3/3 [==============================] - 2s 784ms/step - loss: 0.2526\n",
      "Epoch 165/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.2472\n",
      "Epoch 166/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.2415\n",
      "Epoch 167/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.2373\n",
      "Epoch 168/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.2327\n",
      "Epoch 169/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.2277\n",
      "Epoch 170/260\n",
      "3/3 [==============================] - 2s 740ms/step - loss: 0.2241\n",
      "Epoch 171/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 0.2204\n",
      "Epoch 172/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.2157\n",
      "Epoch 173/260\n",
      "3/3 [==============================] - 2s 746ms/step - loss: 0.2119\n",
      "Epoch 174/260\n",
      "3/3 [==============================] - 2s 738ms/step - loss: 0.2073\n",
      "Epoch 175/260\n",
      "3/3 [==============================] - 2s 782ms/step - loss: 0.2034\n",
      "Epoch 176/260\n",
      "3/3 [==============================] - 2s 736ms/step - loss: 0.2001\n",
      "Epoch 177/260\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1964\n",
      "Epoch 178/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.1916\n",
      "Epoch 179/260\n",
      "3/3 [==============================] - 2s 785ms/step - loss: 0.1877\n",
      "Epoch 180/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.1838\n",
      "Epoch 181/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.1802\n",
      "Epoch 182/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.1768\n",
      "Epoch 183/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.1731\n",
      "Epoch 184/260\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 0.1696\n",
      "Epoch 185/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.1665\n",
      "Epoch 186/260\n",
      "3/3 [==============================] - 2s 747ms/step - loss: 0.1645\n",
      "Epoch 187/260\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.1617\n",
      "Epoch 188/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.1599\n",
      "Epoch 189/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.1577\n",
      "Epoch 190/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.1550\n",
      "Epoch 191/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.1521\n",
      "Epoch 192/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.1490\n",
      "Epoch 193/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.1461\n",
      "Epoch 194/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.1445\n",
      "Epoch 195/260\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.1421\n",
      "Epoch 196/260\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 0.1396\n",
      "Epoch 197/260\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1367\n",
      "Epoch 198/260\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.1342\n",
      "Epoch 199/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.1328\n",
      "Epoch 200/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.1308\n",
      "Epoch 201/260\n",
      "3/3 [==============================] - 2s 776ms/step - loss: 0.1289\n",
      "Epoch 202/260\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1270\n",
      "Epoch 203/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.1250\n",
      "Epoch 204/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.1240\n",
      "Epoch 205/260\n",
      "3/3 [==============================] - 2s 780ms/step - loss: 0.1220\n",
      "Epoch 206/260\n",
      "3/3 [==============================] - 2s 719ms/step - loss: 0.1202\n",
      "Epoch 207/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.1186\n",
      "Epoch 208/260\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 0.1166\n",
      "Epoch 209/260\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.1144\n",
      "Epoch 210/260\n",
      "3/3 [==============================] - 2s 715ms/step - loss: 0.1126\n",
      "Epoch 211/260\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 0.1111\n",
      "Epoch 212/260\n",
      "3/3 [==============================] - 2s 753ms/step - loss: 0.1092\n",
      "Epoch 213/260\n",
      "3/3 [==============================] - 2s 781ms/step - loss: 0.1071\n",
      "Epoch 214/260\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.1051\n",
      "Epoch 215/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.1036\n",
      "Epoch 216/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.1020\n",
      "Epoch 217/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.1009\n",
      "Epoch 218/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.0995\n",
      "Epoch 219/260\n",
      "3/3 [==============================] - 2s 720ms/step - loss: 0.0981\n",
      "Epoch 220/260\n",
      "3/3 [==============================] - 2s 716ms/step - loss: 0.0974\n",
      "Epoch 221/260\n",
      "3/3 [==============================] - 2s 785ms/step - loss: 0.0962\n",
      "Epoch 222/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.0949\n",
      "Epoch 223/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.0935\n",
      "Epoch 224/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.0929\n",
      "Epoch 225/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.0916\n",
      "Epoch 226/260\n",
      "3/3 [==============================] - 2s 739ms/step - loss: 0.0904\n",
      "Epoch 227/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.0890\n",
      "Epoch 228/260\n",
      "3/3 [==============================] - 2s 781ms/step - loss: 0.0883\n",
      "Epoch 229/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.0874\n",
      "Epoch 230/260\n",
      "3/3 [==============================] - 2s 728ms/step - loss: 0.0873\n",
      "Epoch 231/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.0862\n",
      "Epoch 232/260\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 0.0851\n",
      "Epoch 233/260\n",
      "3/3 [==============================] - 2s 741ms/step - loss: 0.0842\n",
      "Epoch 234/260\n",
      "3/3 [==============================] - 2s 724ms/step - loss: 0.0829\n",
      "Epoch 235/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.0822\n",
      "Epoch 236/260\n",
      "3/3 [==============================] - 2s 737ms/step - loss: 0.0811\n",
      "Epoch 237/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.0801\n",
      "Epoch 238/260\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.0794\n",
      "Epoch 239/260\n",
      "3/3 [==============================] - 2s 718ms/step - loss: 0.0784\n",
      "Epoch 240/260\n",
      "3/3 [==============================] - 2s 720ms/step - loss: 0.0778\n",
      "Epoch 241/260\n",
      "3/3 [==============================] - 2s 809ms/step - loss: 0.0771\n",
      "Epoch 242/260\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 0.0763\n",
      "Epoch 243/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.0756\n",
      "Epoch 244/260\n",
      "3/3 [==============================] - 2s 722ms/step - loss: 0.0749\n",
      "Epoch 245/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.0744\n",
      "Epoch 246/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.0743\n",
      "Epoch 247/260\n",
      "3/3 [==============================] - 2s 717ms/step - loss: 0.0735\n",
      "Epoch 248/260\n",
      "3/3 [==============================] - 2s 708ms/step - loss: 0.0730\n",
      "Epoch 249/260\n",
      "3/3 [==============================] - 2s 723ms/step - loss: 0.0728\n",
      "Epoch 250/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.0725\n",
      "Epoch 251/260\n",
      "3/3 [==============================] - 2s 725ms/step - loss: 0.0719\n",
      "Epoch 252/260\n",
      "3/3 [==============================] - 2s 709ms/step - loss: 0.0714\n",
      "Epoch 253/260\n",
      "3/3 [==============================] - 2s 729ms/step - loss: 0.0706\n",
      "Epoch 254/260\n",
      "3/3 [==============================] - 2s 733ms/step - loss: 0.0700\n",
      "Epoch 255/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.0698\n",
      "Epoch 256/260\n",
      "3/3 [==============================] - 2s 732ms/step - loss: 0.0697\n",
      "Epoch 257/260\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 0.0687\n",
      "Epoch 258/260\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.0679\n",
      "Epoch 259/260\n",
      "3/3 [==============================] - 2s 727ms/step - loss: 0.0673\n",
      "Epoch 260/260\n",
      "3/3 [==============================] - 2s 721ms/step - loss: 0.0666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fe20e4150>"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "# Implement teacher forcing while training your model. You can do it two ways.\n",
    "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
    "# if decoder input is \n",
    "# <start> Hi how are you\n",
    "# decoder output should be\n",
    "# Hi How are you <end>\n",
    "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
    "\n",
    "# or\n",
    " \n",
    "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
    "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
    "model  = encoder_decoder(encoder_inputs_length=39,decoder_inputs_length=39,output_vocab_size=vocab_size_target,batch_size=512,mode=\"parallel\")\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//512\n",
    "valid_steps=validation.shape[0]//20\n",
    "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "AK-rVmwTQ1WK"
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "units=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Iufu14J0JVp7"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "  E. Call plot_attention(#params)\n",
    "  F. Return the predicted sentence\n",
    "  '''\n",
    "  initial_state_enc=[np.zeros((batch_size,units)),np.zeros((batch_size,units))]\n",
    "  inp_seq = tknizer_source.texts_to_sequences([input_sentence])\n",
    "  inp_seq = pad_sequences(inp_seq,padding='post',maxlen=39)\n",
    "  attention_weights = np.zeros((1,39),dtype='float32')\n",
    "  attention_weights[:,0]=1\n",
    "\n",
    "  en_outputs,state_h , state_c = model.layers[0](tf.constant(inp_seq),initial_state_enc)\n",
    "  cur_vec = tf.constant([[tknizer_target.word_index['<start>']]])\n",
    "  pred = []\n",
    "  #Here 43 is the max_length of the sequence\n",
    "  for i in range(39):\n",
    "    output,state_h,state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(cur_vec,en_outputs,state_h,state_c,attention_weights)\n",
    "    cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "    pred.append(tknizer_target.index_word[cur_vec[0][0]])\n",
    "    if(pred[-1]=='<end>'):\n",
    "      break\n",
    "    translated_sentence = ' '.join(pred)\n",
    "  return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nknpSF7BRs1b",
    "outputId": "a1a63ba1-9cac-48f2-b249-c19ba1840ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Actual output is:  Wow, haha, can go try b mistress 4 few days lor, get a taste of it... Aiya, in army one lor, u wont noe one.... Den mei one is kua's fren, thgt u noe liao...\n",
      "The predicted output is:  i just got time do you that i don't know what time then where are quite well hope you are you mum there maybe it's okay all depends on tuesday i've got like to see die we go and\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Same as u 1245... I oso wan shop, but cant leh, parents dun let me go out liao...\n",
      "The predicted output is:  ok i'm sorry to watch in camp too so how about so bored or smu for your give my like there and then end of her outside this show is there then there will tell you get it then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Aiya... Lk tt den no nd go oredi... So pissed... Dunno wat's wrong w it...\n",
      "The predicted output is:  hmm nevermind\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Lea my day fine. How's yrs? Lea yr real name?\n",
      "The predicted output is:  hmm sorry i think can meet you reach on the girl it will reach home from home now you get it by this from town anyway thanks for me your parents then maybe it's okay all depends on my\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  hahaha..hey, MERINA is my name. ok, female. where r u now JORDAN? malay?\n",
      "The predicted output is:  hey i just got time do work to go to watch in my work to meet you are in her by it by this is your 6 yiyun money rush friends may buy first for us singapore building all\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Should be well rested. u free nxt wk\n",
      "The predicted output is:  on time i still got did you reach\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Eh. Take from where? Amk? How to go from yck?\n",
      "The predicted output is:  no lecture then stay in school\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  cannot la.. long hair not nice.. short hair nicer.. reali... haha.. no la.. still fren..btw.. y dun wan to cut?haha..\n",
      "The predicted output is:  haha so what time how is at home from home and wait for your first right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  ANGEL u fall slp liao izit y no response frm u.i still waitin for u ok.\n",
      "The predicted output is:  you finish with you later you tomorrow i have already i've got like to lose like your first right then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Okie okie.. I'll update u bout e situation another day then.. Hee\n",
      "The predicted output is:  ok then i got time then you been meaningful you get seats this from you there will tell you get it by this is at home this from town at home first who are your right please tomorrow\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  But i'm gettin fat sittin ard... I juz wan a change of environment lor... Try diff jobs...\n",
      "The predicted output is:  i can see you are you are you cut yet can give me my lesson sorry about me your headache now you the 12 then tell you girl you get me your parents then did you ok then where\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Hey... So qiao... U oso learn drivin here...\n",
      "The predicted output is:  oh no dancing or do you cut you cut yet by the way can meet in the restaurant really good and will save far thanks before buying our medical checkup that before before me before me right before me\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Can i confirm w ü e time tmr?\n",
      "The predicted output is:  you all where to orchard is at home now i just got time my questions free time my questions got watch that one later thanks study hard to watch there by the way about at orchard is here right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Eh not meetg le...Other days den meet k. Jun goin home le...\n",
      "The predicted output is:  i can sit properly on her hehe because in her hehe in the university in this is it is it it with must have must have got must be if anything well but it's not sure got watch at\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Hello.Wakey wakey.>poke poke< at home ah?Watchin tv?\n",
      "The predicted output is:  hello how are your user very lonely\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Tireness draws across the mind making the body fade flexibility n soon windows of soul begin 2 close N enter the dreamland! OYASUMINASAI! Sweet Dreams!\n",
      "The predicted output is:  same time then where did you i'm quite ok i'm like to see so later you tomorrow the but ask you after 4 then later sorry to orchard ok the wait for mich tomorrow how are your password\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Wat nus des? Ok lor, msg me again...\n",
      "The predicted output is:  you know what time will get me when you hope this the girl thanks so it depends on the girl in this semester so how's your user id and find me before me right who else ok but can\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Crazy its v normal wat. He will do e same 4 audrey they all also.\n",
      "The predicted output is:  i'm not sure how to orchard is also the busy one is also sick so what time will get the but after school then so sweet sure i'll still already can meet by the whole groceries and she can't\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Okay... Ü call us when ü reach... My drivin is at 240 tmr... Ü have 2 lessons? Or only one?\n",
      "The predicted output is:  hi baby it's not my questions so it from your user id and jun to orchard is going my house then so you get by the restaurant really but call it's raining but tomorrow but tomorrow later call me\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "The Actual output is:  Yup... I dont mind... Why?\n",
      "The predicted output is:  haha okay i have already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "for i in validation['source']:\n",
    "  print(\"The Actual output is: \",i)\n",
    "  predicted=predict(i)\n",
    "  print(\"The predicted output is: \",predicted)\n",
    "  print(\">\"*180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnpQs8_gLAQr",
    "outputId": "a2b22e6f-5238-4316-9455-016f6f8eacb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "import nltk.translate.bleu_score as bleu\n",
    "bleu_scores_lst=[]\n",
    "for i in validation[:]['source']:\n",
    "  reference = [i.split(),] # the original\n",
    "  predicted=predict(i)\n",
    "  translation = predicted.split()\n",
    "  values=bleu.sentence_bleu(reference, translation)\n",
    "  bleu_scores_lst.append(values)\n",
    "\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgU2eYtdQpUF",
    "outputId": "a1a59e24-f7aa-424e-fb27-ad8e6e629f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score of these 1000 test data sentences is:  0.19536971776642903\n"
     ]
    }
   ],
   "source": [
    "average_bleu_scores=sum(bleu_scores_lst)/len(bleu_scores_lst)\n",
    "print(\"Average BLEU score of these 1000 test data sentences is: \",average_bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdJlwYZdRpHL",
    "outputId": "158c460a-647e-4324-af24-1bea2dbef569"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4001601601922499,\n",
       " 0,\n",
       " 0,\n",
       " 0.4001601601922499,\n",
       " 0.47587330964125224,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.47587330964125224,\n",
       " 0.4001601601922499,\n",
       " 0,\n",
       " 0.47897362544357464,\n",
       " 0.4001601601922499,\n",
       " 0.4001601601922499,\n",
       " 0.47587330964125224,\n",
       " 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_scores_lst\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Monotonic_Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
