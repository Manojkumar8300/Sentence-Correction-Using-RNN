{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26b-rtwXVieF",
    "outputId": "15acd6aa-42f9-417f-d700-1a60a933dbab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 92.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zhlalfjrVzpM"
   },
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VlTyLFRrV1RL"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#reading the file preprocessed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "OC8gT3JLV4vn",
    "outputId": "ef770f41-9123-4016-b840-17012413132d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)#visulazing the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bA1Pjx46V6H6"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#for removing the last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NSsAiV9yV-6v"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)\n",
    "df['target']=df['target'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "0IW1Mm65WLPv",
    "outputId": "4a7e6f73-6c73-4a52-d8b1-5b483f6b8092"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR3-LuR-WMrW",
    "outputId": "44fe2983-5f8a-448d-9e0a-2cc51f02e594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FYQ5VYCkWP-G"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(len)<170]#removing sentences where source sentence is greater than 170\n",
    "df=df[df['target'].apply(len)<200]#removing snetences where target sentence is greater than 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7_8hG17WZu2",
    "outputId": "52e3da5d-ea54-4737-fa5a-f7f200db8dd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#printing the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwYYQfpCWnRg",
    "outputId": "c6b2ebb4-433e-4265-8a32-92e39d84c829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970,)\n",
      "(20,)\n",
      "(1970,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['source']\n",
    "y=df['target']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01)#splitting in the data in the ratio of 99:1\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd6DdQYVWtls"
   },
   "source": [
    "Target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7sxn1aTWqjs",
    "outputId": "3a46340c-6605-487f-918f-c5adc4d22cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "target_tokenizer= Tokenizer(filters=None,char_level=True,lower=False)#tokenzing the target in character level\n",
    "target_tokenizer.fit_on_texts(y_train)#fitting on the target train\n",
    "target_vocab_size= len(target_tokenizer.word_index) + 1\n",
    "print(len(target_tokenizer.word_index))#printing the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SkOHuAShWvKA"
   },
   "outputs": [],
   "source": [
    "target_encoded_docs_train = target_tokenizer.texts_to_sequences(y_train)#converting target train into sequence\n",
    "target_encoded_docs_test = target_tokenizer.texts_to_sequences(y_test)#converting target test into sequence\n",
    "\n",
    "target_padded_docs_train = pad_sequences(target_encoded_docs_train,padding='post')#padding target train \n",
    "target_padded_docs_test = pad_sequences(target_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding target test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFFdUzXvW-Db"
   },
   "source": [
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBLkfDHuWwbj",
    "outputId": "da347be2-2670-4e34-d489-a681d93e9e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "source_tokenizer= Tokenizer(char_level=True,lower=False)#tokenzing the source in character level\n",
    "source_tokenizer.fit_on_texts(X_train)#fitting on the source train\n",
    "source_vocab_size= len(source_tokenizer.word_index) + 1\n",
    "print(len(source_tokenizer.word_index))#printing the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xqpGT-raWyUj"
   },
   "outputs": [],
   "source": [
    "source_encoded_docs_train = source_tokenizer.texts_to_sequences(X_train)#converting source train into sequence\n",
    "source_encoded_docs_test = source_tokenizer.texts_to_sequences(X_test)#converting source train into sequence\n",
    "\n",
    "source_padded_docs_train = pad_sequences(source_encoded_docs_train,maxlen=target_padded_docs_train.shape[1],padding='post')#padding source train \n",
    "source_padded_docs_test = pad_sequences(source_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding source test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5qowxWnfW0JQ"
   },
   "outputs": [],
   "source": [
    "#we are reshaping because sparse_categorical_entropy expects 3dimensions\n",
    "target_padded_docs_train=target_padded_docs_train.reshape((*target_padded_docs_train.shape,1))\n",
    "target_padded_docs_test=target_padded_docs_test.reshape((*target_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDXDkFBUW2Bo",
    "outputId": "799ac3fa-69d5-4ff3-9c44-66e73f1a8f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 199, 1)\n",
      "(20, 199, 1)\n"
     ]
    }
   ],
   "source": [
    "print(target_padded_docs_train.shape)\n",
    "print(target_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "r8zXZlpjW4NL"
   },
   "outputs": [],
   "source": [
    "#we are reshaping because sparse_categorical_entropy expects 3dimensions\n",
    "source_padded_docs_train=source_padded_docs_train.reshape((*source_padded_docs_train.shape,1))\n",
    "source_padded_docs_test=source_padded_docs_test.reshape((*source_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVdAxcpkW6Bp",
    "outputId": "fe2286fe-1a29-4bcd-e4c8-f9d1ff13391a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 199, 1)\n",
      "(20, 199, 1)\n"
     ]
    }
   ],
   "source": [
    "print(source_padded_docs_train.shape)\n",
    "print(source_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qp2i6fwKdVKW"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train2.csv')\n",
    "y_train.to_csv('y_train2.csv')\n",
    "X_test.to_csv('X_test2.csv')\n",
    "y_test.to_csv('y_test2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ffNGML8kdVN2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(source_encoded_docs_train).to_csv(\"source_encoded_docs_train2.csv\")\n",
    "pd.DataFrame(source_encoded_docs_test).to_csv(\"source_encoded_docs_test2.csv\")\n",
    "pd.DataFrame(target_encoded_docs_train).to_csv(\"target_encoded_docs_train2.csv\")\n",
    "pd.DataFrame(target_encoded_docs_test).to_csv(\"target_encoded_docs_test2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQVqseuWXBYj"
   },
   "source": [
    "Model1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xR1VtvcW77-",
    "outputId": "9f734621-bf5d-46bc-f7af-ab9b44467a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 199)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 199, 256)          26624     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 199, 128)          197120    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 199, 512)          66048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 199, 512)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 199, 91)           46683     \n",
      "=================================================================\n",
      "Total params: 336,475\n",
      "Trainable params: 336,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(199,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,256, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.LSTM(128, return_sequences=True)(embed)  \n",
    "dense=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512, activation='relu'))(lstm1)\n",
    "drop=tf.keras.layers.Dropout(0.5)(dense)\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(drop)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "x4fH-FIzXP2R"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np4JHJ_kXSnJ",
    "outputId": "f46c6064-074d-4e71-b7fc-6e10b2d86072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 9s 648ms/step - loss: 4.0295 - accuracy: 0.3307 - val_loss: 3.0509 - val_accuracy: 0.6756\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 2.5630 - accuracy: 0.6698 - val_loss: 1.3701 - val_accuracy: 0.7176\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.5293 - accuracy: 0.6910 - val_loss: 1.2024 - val_accuracy: 0.6879\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.3614 - accuracy: 0.6641 - val_loss: 1.0989 - val_accuracy: 0.7291\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.3344 - accuracy: 0.6993 - val_loss: 1.0950 - val_accuracy: 0.7302\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.3359 - accuracy: 0.6934 - val_loss: 1.0957 - val_accuracy: 0.7302\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 1.3253 - accuracy: 0.6955 - val_loss: 1.0986 - val_accuracy: 0.7302\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.3172 - accuracy: 0.6998 - val_loss: 1.0917 - val_accuracy: 0.7302\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.3089 - accuracy: 0.6998 - val_loss: 1.0867 - val_accuracy: 0.7302\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.2991 - accuracy: 0.6996 - val_loss: 1.0887 - val_accuracy: 0.7302\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.2875 - accuracy: 0.6998 - val_loss: 1.0894 - val_accuracy: 0.7302\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.2725 - accuracy: 0.6998 - val_loss: 1.0809 - val_accuracy: 0.7307\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.2603 - accuracy: 0.7002 - val_loss: 1.0777 - val_accuracy: 0.7296\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.2479 - accuracy: 0.7006 - val_loss: 1.0753 - val_accuracy: 0.7304\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.2353 - accuracy: 0.7007 - val_loss: 1.0738 - val_accuracy: 0.7302\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.2272 - accuracy: 0.7007 - val_loss: 1.0751 - val_accuracy: 0.7302\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 1.2200 - accuracy: 0.7007 - val_loss: 1.0738 - val_accuracy: 0.7302\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.2142 - accuracy: 0.7009 - val_loss: 1.0675 - val_accuracy: 0.7302\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.2095 - accuracy: 0.7011 - val_loss: 1.0623 - val_accuracy: 0.7302\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.2069 - accuracy: 0.7014 - val_loss: 1.0578 - val_accuracy: 0.7317\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.2027 - accuracy: 0.7017 - val_loss: 1.0584 - val_accuracy: 0.7317\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.2002 - accuracy: 0.7020 - val_loss: 1.0486 - val_accuracy: 0.7319\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.1965 - accuracy: 0.7024 - val_loss: 1.0518 - val_accuracy: 0.7329\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1923 - accuracy: 0.7029 - val_loss: 1.0409 - val_accuracy: 0.7337\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.2019 - accuracy: 0.7034 - val_loss: 1.0625 - val_accuracy: 0.7334\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.1967 - accuracy: 0.7035 - val_loss: 1.0441 - val_accuracy: 0.7349\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.1923 - accuracy: 0.7040 - val_loss: 1.0488 - val_accuracy: 0.7354\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.1869 - accuracy: 0.7046 - val_loss: 1.0453 - val_accuracy: 0.7342\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.1822 - accuracy: 0.7043 - val_loss: 1.0379 - val_accuracy: 0.7342\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.1782 - accuracy: 0.7047 - val_loss: 1.0412 - val_accuracy: 0.7364\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 242ms/step - loss: 1.1746 - accuracy: 0.7055 - val_loss: 1.0311 - val_accuracy: 0.7364\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1713 - accuracy: 0.7058 - val_loss: 1.0314 - val_accuracy: 0.7372\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1661 - accuracy: 0.7055 - val_loss: 1.0245 - val_accuracy: 0.7374\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.1620 - accuracy: 0.7064 - val_loss: 1.0214 - val_accuracy: 0.7369\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.1581 - accuracy: 0.7067 - val_loss: 1.0207 - val_accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1536 - accuracy: 0.7073 - val_loss: 1.0159 - val_accuracy: 0.7399\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.1487 - accuracy: 0.7084 - val_loss: 1.0137 - val_accuracy: 0.7382\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.1442 - accuracy: 0.7090 - val_loss: 1.0124 - val_accuracy: 0.7394\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.1405 - accuracy: 0.7095 - val_loss: 1.0288 - val_accuracy: 0.7405\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.1432 - accuracy: 0.7097 - val_loss: 1.0192 - val_accuracy: 0.7389\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.1373 - accuracy: 0.7103 - val_loss: 1.0044 - val_accuracy: 0.7394\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1358 - accuracy: 0.7103 - val_loss: 1.0054 - val_accuracy: 0.7392\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.1307 - accuracy: 0.7105 - val_loss: 1.0016 - val_accuracy: 0.7397\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 1.1280 - accuracy: 0.7109 - val_loss: 1.0062 - val_accuracy: 0.7422\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.1232 - accuracy: 0.7114 - val_loss: 0.9998 - val_accuracy: 0.7440\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.1171 - accuracy: 0.7132 - val_loss: 0.9826 - val_accuracy: 0.7412\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1198 - accuracy: 0.7135 - val_loss: 0.9919 - val_accuracy: 0.7435\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.1127 - accuracy: 0.7141 - val_loss: 0.9935 - val_accuracy: 0.7425\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 1.1106 - accuracy: 0.7145 - val_loss: 0.9842 - val_accuracy: 0.7442\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.1043 - accuracy: 0.7157 - val_loss: 0.9851 - val_accuracy: 0.7462\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 1.1014 - accuracy: 0.7163 - val_loss: 0.9794 - val_accuracy: 0.7462\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0987 - accuracy: 0.7169 - val_loss: 0.9742 - val_accuracy: 0.7485\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.0934 - accuracy: 0.7175 - val_loss: 0.9830 - val_accuracy: 0.7467\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.0893 - accuracy: 0.7182 - val_loss: 0.9660 - val_accuracy: 0.7467\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.1011 - accuracy: 0.7173 - val_loss: 0.9721 - val_accuracy: 0.7467\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.0963 - accuracy: 0.7173 - val_loss: 0.9701 - val_accuracy: 0.7467\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0872 - accuracy: 0.7182 - val_loss: 0.9799 - val_accuracy: 0.7513\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.0839 - accuracy: 0.7199 - val_loss: 0.9592 - val_accuracy: 0.7525\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 1.0823 - accuracy: 0.7203 - val_loss: 0.9751 - val_accuracy: 0.7427\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0905 - accuracy: 0.7184 - val_loss: 0.9692 - val_accuracy: 0.7490\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0928 - accuracy: 0.7165 - val_loss: 0.9578 - val_accuracy: 0.7472\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0831 - accuracy: 0.7177 - val_loss: 0.9674 - val_accuracy: 0.7420\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0801 - accuracy: 0.7176 - val_loss: 0.9701 - val_accuracy: 0.7452\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0743 - accuracy: 0.7196 - val_loss: 0.9506 - val_accuracy: 0.7495\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.0728 - accuracy: 0.7207 - val_loss: 0.9515 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0667 - accuracy: 0.7216 - val_loss: 0.9716 - val_accuracy: 0.7492\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0658 - accuracy: 0.7217 - val_loss: 0.9490 - val_accuracy: 0.7477\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 262ms/step - loss: 1.0626 - accuracy: 0.7218 - val_loss: 0.9500 - val_accuracy: 0.7490\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0592 - accuracy: 0.7222 - val_loss: 0.9498 - val_accuracy: 0.7490\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0546 - accuracy: 0.7229 - val_loss: 0.9418 - val_accuracy: 0.7475\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0524 - accuracy: 0.7227 - val_loss: 0.9459 - val_accuracy: 0.7513\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 258ms/step - loss: 1.0500 - accuracy: 0.7228 - val_loss: 0.9371 - val_accuracy: 0.7492\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0487 - accuracy: 0.7232 - val_loss: 0.9431 - val_accuracy: 0.7475\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0499 - accuracy: 0.7230 - val_loss: 0.9401 - val_accuracy: 0.7530\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.0455 - accuracy: 0.7230 - val_loss: 0.9307 - val_accuracy: 0.7503\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.0459 - accuracy: 0.7235 - val_loss: 0.9465 - val_accuracy: 0.7447\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0573 - accuracy: 0.7221 - val_loss: 0.9366 - val_accuracy: 0.7515\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0547 - accuracy: 0.7213 - val_loss: 0.9283 - val_accuracy: 0.7513\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 1.0456 - accuracy: 0.7223 - val_loss: 0.9419 - val_accuracy: 0.7475\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0449 - accuracy: 0.7226 - val_loss: 0.9360 - val_accuracy: 0.7482\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.0387 - accuracy: 0.7237 - val_loss: 0.9269 - val_accuracy: 0.7540\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0357 - accuracy: 0.7243 - val_loss: 0.9259 - val_accuracy: 0.7505\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 259ms/step - loss: 1.0325 - accuracy: 0.7246 - val_loss: 0.9286 - val_accuracy: 0.7487\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 1.0299 - accuracy: 0.7248 - val_loss: 0.9287 - val_accuracy: 0.7510\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0277 - accuracy: 0.7249 - val_loss: 0.9232 - val_accuracy: 0.7523\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.0234 - accuracy: 0.7254 - val_loss: 0.9224 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 256ms/step - loss: 1.0234 - accuracy: 0.7256 - val_loss: 0.9175 - val_accuracy: 0.7510\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.0246 - accuracy: 0.7255 - val_loss: 0.9156 - val_accuracy: 0.7535\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.0181 - accuracy: 0.7259 - val_loss: 0.9307 - val_accuracy: 0.7525\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1.0191 - accuracy: 0.7260 - val_loss: 0.9194 - val_accuracy: 0.7543\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1.0133 - accuracy: 0.7265 - val_loss: 0.9205 - val_accuracy: 0.7515\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 259ms/step - loss: 1.0140 - accuracy: 0.7265 - val_loss: 0.9084 - val_accuracy: 0.7523\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0105 - accuracy: 0.7263 - val_loss: 0.9255 - val_accuracy: 0.7503\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1.0168 - accuracy: 0.7261 - val_loss: 0.9594 - val_accuracy: 0.7467\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.0370 - accuracy: 0.7223 - val_loss: 0.9110 - val_accuracy: 0.7520\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.0333 - accuracy: 0.7216 - val_loss: 0.9341 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.0243 - accuracy: 0.7227 - val_loss: 0.9180 - val_accuracy: 0.7455\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.0206 - accuracy: 0.7222 - val_loss: 0.9208 - val_accuracy: 0.7503\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1.0174 - accuracy: 0.7251 - val_loss: 0.9145 - val_accuracy: 0.7538\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.0126 - accuracy: 0.7265 - val_loss: 0.9065 - val_accuracy: 0.7528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36ee2a7bd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=100,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KMFNKCyNXUPl"
   },
   "outputs": [],
   "source": [
    "x=model.predict(source_padded_docs_test[:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "nXMF7_ltY7pV",
    "outputId": "cdcd2631-182b-4364-9e6f-975c0136269a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Photo page..                       <PAD><PAD>   k                    <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "''.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4b1qSMQY9bG",
    "outputId": "7d3f342b-8171-49ce-b267-23003b9cbcfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108    Photo page. You mean the website. OK, I'll go ...\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ftRv_Z3Y_Ho",
    "outputId": "1d5d299a-bd26-4df1-891c-7e24dcf3a551"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108    Photo page... U mean e website huh... Kk, i'll...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMCvd0mRC99_",
    "outputId": "f5986784-65a1-477d-e0a7-e80dce9dc661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Photo page... U mean e website huh... Kk, i'll go mail u now...\n",
      "Actual Output: \n",
      "Photo page. You mean the website. OK, I'll go to mail you now.\n",
      "Predicted Output: \n",
      "Photo page..                       <PAD><PAD>   k                    <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Eh. I'm still at the bus stop... Missed the bus. So i might be later than you\n",
      "Actual Output: \n",
      "I'm still at the bus stop. I missed the bus. So I might be later than you.\n",
      "Predicted Output: \n",
      "Eh.  'm  till  t tte     s    <PAD><PAD>    sss   e                       e   t      <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Tomw depends on wat time si going to meet us lah... If she not so early maybe we meet bugis else meet orchard lor\n",
      "Actual Output: \n",
      "Tomorrow depends on what time Si is going to meet us. If she is not so early, maybe we meet at Bugis, else meet at Orchard.\n",
      "Predicted Output: \n",
      "Tomw deeends on wwt tttm  i   iiggg                                                 e               ee   eeeeeeee e<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Ok. I going soon and also send xyan home at the same time. Call u when reaching k.\n",
      "Actual Output: \n",
      "Ok. I am going soon and also send xyan home at the same time. Call you when reaching.\n",
      "Predicted Output: \n",
      "Ok. I  oingg  on nnn        nd   an   n                 mm                          <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "WHAT NUMBER? MOBILE OR NOT ?\n",
      "Actual Output: \n",
      "What number? Mobile or not?\n",
      "Predicted Output: \n",
      "What n         b  l    e      <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI, R U GAL OR BOY\n",
      "Actual Output: \n",
      "Hi, are you girl or boy?\n",
      "Predicted Output: \n",
      "Hi, Rru                 <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "My painting almost done liao. But my house outside havent start yet. Haiz....\n",
      "Actual Output: \n",
      "My painting is almost done. But my house outside haven't started yet. Sigh.\n",
      "Predicted Output: \n",
      "My paintingg lmo t  onn    o.                  sse   veee  tt tt  tt  aaa   <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Fine. Gt posted to SAFTI as a medic\n",
      "Actual Output: \n",
      "Fine. Got posted to SAFTI as a medic.\n",
      "Predicted Output: \n",
      "Fine. Gt po tte tt  a ti a  a      e<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "No la... Not attached... He's always pesterin me, dunno y... Haha, i find him a jerk oso lor...\n",
      "Actual Output: \n",
      "No. Not attached. He's always pestering me, I don't know why. Haha, I find him a jerk also.\n",
      "Predicted Output: \n",
      "No                   <PAD><PAD><PAD>                                  <PAD><PAD>                               <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "WHAT TIME U WRKIN?\n",
      "Actual Output: \n",
      "What time are you working?\n",
      "Predicted Output: \n",
      "What Ttmm              <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I thk dun wan da glasses lar... Seldom use it anyway... Save some money... Hee...\n",
      "Actual Output: \n",
      "I think I don't want the glasses. Seldom use it anyway. Save some money. Hee.\n",
      "Predicted Output: \n",
      "I thk d n   n         ssssss                                             <PAD>    <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi babe its me thanks for coming even though it didnt go that well!i just wanted my bed! Hope to see you soon love and kisses\n",
      "Actual Output: \n",
      "Hi baby, it's me, thanks for coming, even though it didn't go that well! I just wanted my bed! Hope to see you soon love and kisses.\n",
      "Predicted Output: \n",
      "Hi  abe its me thanns   r  ooonn   eeeee          ddd                                                                                <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hello.... Are you free later for a chat?\n",
      "Actual Output: \n",
      "Hello. Are you free later for a chat?\n",
      "Predicted Output: \n",
      "Hello. I             e         r       <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Me very hungry...  come down faster lei...\n",
      "Actual Output: \n",
      "Me very hungry. You come down faster.\n",
      "Predicted Output: \n",
      "Me very  ynnnyy       o o o  o        ee<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
      "Actual Output: \n",
      "That's better now, I got a roast down me! I'd be better if I had a few drinks down me too! Good Indian?\n",
      "Predicted Output: \n",
      "Mmm mhats  ettttte             aat                                                                        nn<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yup... I will be going with my hall.\n",
      "Actual Output: \n",
      "Yes. I will be going with my hall.\n",
      "Predicted Output: \n",
      "Yes. I      l        g             <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh... oh! Thats the wooden one right? the aluminium one cheaper\n",
      "Actual Output: \n",
      "Huh. Oh! That's the wooden one right? The aluminium one is cheaper.\n",
      "Predicted Output: \n",
      "Huh. I                               <PAD>           i             e<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yupz...Kk...Den i anyhow wear...Vv hot...Haha\n",
      "Actual Output: \n",
      "Yes. Ok. Then I anyhow wear. It's very hot. Haha.\n",
      "Predicted Output: \n",
      "Yes.    k                    <PAD><PAD><PAD>       <PAD><PAD>    <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "So how are you spending yr weekend?\n",
      "Actual Output: \n",
      "So how are you spending your weekend?\n",
      "Predicted Output: \n",
      "So how are you spendinggyr  eeeeed?<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey....I know its rude of me not to do something abt e fone.N i'm sorry it died on u.\n",
      "Actual Output: \n",
      "Hey, I know it's rude of me not to do something about the phone. And I'm sorry it died on you.\n",
      "Predicted Output: \n",
      "Hey. I                                                     <PAD>                          <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=''.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPtBPG5nCQNH",
    "outputId": "d153da06-6c57-4d05-84a1-994765c4178c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3839817133079349, 0, 0.3375804740497263, 0.15042653060571137, 0.46173663094410267, 0.4854917717073234, 0.3976353643835253, 0.5946035575013605, 0, 0.5081327481546147, 0.3549481056010053, 0.3138995505196357, 0.42728700639623407, 0.25650569096216347, 0, 0.22679164443904004, 0.3672056269893592, 0.4172261448611506, 0.43012508513132625, 0.3354232998654124]\n",
      "The Average Bleu Score is:  0.32245004727098137\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if '<' in i:\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfCSjtjEa3jt"
   },
   "source": [
    "Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4aFXQEBZBgK",
    "outputId": "4ee946b1-5d55-40a7-93d9-e5b7cfcec06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 199)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 199, 256)          26624     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 199, 256)          394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 199, 512)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 199, 512)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 199, 91)           46683     \n",
      "=================================================================\n",
      "Total params: 599,131\n",
      "Trainable params: 599,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(199,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,256, input_length=source_padded_docs_train.shape[1])(input)\n",
    "lstm1=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embed)  \n",
    "dense=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(512,activation='relu'))(lstm1)\n",
    "drop=tf.keras.layers.Dropout(0.5)(dense)\n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(drop)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3_1vEVsp5yYk"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKWbYgbma9rb",
    "outputId": "0a1a1b0d-86f7-4309-8bd2-a43eccae4c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 989ms/step - loss: 3.9742 - accuracy: 0.3335 - val_loss: 4.5931 - val_accuracy: 0.6756\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 3.5696 - accuracy: 0.6468 - val_loss: 1.9741 - val_accuracy: 0.6161\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.9752 - accuracy: 0.5189 - val_loss: 1.2263 - val_accuracy: 0.6955\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 1.4786 - accuracy: 0.6602 - val_loss: 1.1741 - val_accuracy: 0.6952\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.4346 - accuracy: 0.6614 - val_loss: 1.1194 - val_accuracy: 0.7286\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 364ms/step - loss: 1.3858 - accuracy: 0.6898 - val_loss: 1.0952 - val_accuracy: 0.7281\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.3693 - accuracy: 0.6989 - val_loss: 1.0850 - val_accuracy: 0.7302\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.3481 - accuracy: 0.6989 - val_loss: 1.0940 - val_accuracy: 0.7281\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 1.3194 - accuracy: 0.6948 - val_loss: 1.1282 - val_accuracy: 0.7279\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2980 - accuracy: 0.6916 - val_loss: 1.1399 - val_accuracy: 0.7279\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2773 - accuracy: 0.6979 - val_loss: 1.0905 - val_accuracy: 0.7302\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.2618 - accuracy: 0.6995 - val_loss: 1.0764 - val_accuracy: 0.7302\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.2526 - accuracy: 0.6998 - val_loss: 1.0866 - val_accuracy: 0.7302\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.2482 - accuracy: 0.6998 - val_loss: 1.0806 - val_accuracy: 0.7302\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.2394 - accuracy: 0.6999 - val_loss: 1.0676 - val_accuracy: 0.7302\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2330 - accuracy: 0.7000 - val_loss: 1.0748 - val_accuracy: 0.7302\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.2281 - accuracy: 0.7003 - val_loss: 1.0798 - val_accuracy: 0.7314\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.2261 - accuracy: 0.7005 - val_loss: 1.0651 - val_accuracy: 0.7314\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.2241 - accuracy: 0.7008 - val_loss: 1.0701 - val_accuracy: 0.7314\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.2206 - accuracy: 0.7009 - val_loss: 1.0672 - val_accuracy: 0.7314\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.2169 - accuracy: 0.7010 - val_loss: 1.0585 - val_accuracy: 0.7314\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.2145 - accuracy: 0.7010 - val_loss: 1.0650 - val_accuracy: 0.7314\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.2126 - accuracy: 0.7011 - val_loss: 1.0647 - val_accuracy: 0.7314\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.2103 - accuracy: 0.7014 - val_loss: 1.0580 - val_accuracy: 0.7337\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.2076 - accuracy: 0.7017 - val_loss: 1.0624 - val_accuracy: 0.7347\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.2054 - accuracy: 0.7018 - val_loss: 1.0490 - val_accuracy: 0.7344\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.2038 - accuracy: 0.7020 - val_loss: 1.0628 - val_accuracy: 0.7347\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.2023 - accuracy: 0.7021 - val_loss: 1.0416 - val_accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.2054 - accuracy: 0.7022 - val_loss: 1.0614 - val_accuracy: 0.7344\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 1.2010 - accuracy: 0.7022 - val_loss: 1.0411 - val_accuracy: 0.7344\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.2002 - accuracy: 0.7022 - val_loss: 1.0594 - val_accuracy: 0.7344\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1984 - accuracy: 0.7023 - val_loss: 1.0489 - val_accuracy: 0.7344\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.1957 - accuracy: 0.7023 - val_loss: 1.0527 - val_accuracy: 0.7344\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.1943 - accuracy: 0.7023 - val_loss: 1.0494 - val_accuracy: 0.7344\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1920 - accuracy: 0.7024 - val_loss: 1.0444 - val_accuracy: 0.7347\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1918 - accuracy: 0.7025 - val_loss: 1.0513 - val_accuracy: 0.7347\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1909 - accuracy: 0.7025 - val_loss: 1.0416 - val_accuracy: 0.7347\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.1890 - accuracy: 0.7025 - val_loss: 1.0471 - val_accuracy: 0.7347\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1872 - accuracy: 0.7027 - val_loss: 1.0443 - val_accuracy: 0.7347\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.1869 - accuracy: 0.7026 - val_loss: 1.0346 - val_accuracy: 0.7347\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.1870 - accuracy: 0.7028 - val_loss: 1.0384 - val_accuracy: 0.7352\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.1830 - accuracy: 0.7029 - val_loss: 1.0376 - val_accuracy: 0.7357\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1817 - accuracy: 0.7030 - val_loss: 1.0325 - val_accuracy: 0.7362\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1833 - accuracy: 0.7030 - val_loss: 1.0210 - val_accuracy: 0.7359\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 1.1918 - accuracy: 0.7032 - val_loss: 1.0431 - val_accuracy: 0.7367\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1848 - accuracy: 0.7032 - val_loss: 1.0258 - val_accuracy: 0.7367\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1819 - accuracy: 0.7035 - val_loss: 1.0475 - val_accuracy: 0.7369\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1803 - accuracy: 0.7035 - val_loss: 1.0222 - val_accuracy: 0.7372\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1787 - accuracy: 0.7036 - val_loss: 1.0411 - val_accuracy: 0.7367\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1764 - accuracy: 0.7039 - val_loss: 1.0273 - val_accuracy: 0.7369\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1742 - accuracy: 0.7040 - val_loss: 1.0238 - val_accuracy: 0.7372\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1717 - accuracy: 0.7042 - val_loss: 1.0369 - val_accuracy: 0.7377\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1716 - accuracy: 0.7041 - val_loss: 1.0224 - val_accuracy: 0.7382\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.1691 - accuracy: 0.7041 - val_loss: 1.0223 - val_accuracy: 0.7387\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 1.1671 - accuracy: 0.7045 - val_loss: 1.0283 - val_accuracy: 0.7387\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.1662 - accuracy: 0.7047 - val_loss: 1.0161 - val_accuracy: 0.7387\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.1644 - accuracy: 0.7048 - val_loss: 1.0244 - val_accuracy: 0.7389\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.1631 - accuracy: 0.7049 - val_loss: 1.0152 - val_accuracy: 0.7384\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.1617 - accuracy: 0.7051 - val_loss: 1.0216 - val_accuracy: 0.7387\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1615 - accuracy: 0.7052 - val_loss: 1.0180 - val_accuracy: 0.7387\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1599 - accuracy: 0.7054 - val_loss: 1.0116 - val_accuracy: 0.7394\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.1585 - accuracy: 0.7056 - val_loss: 1.0123 - val_accuracy: 0.7399\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.1564 - accuracy: 0.7060 - val_loss: 1.0118 - val_accuracy: 0.7397\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1539 - accuracy: 0.7060 - val_loss: 1.0042 - val_accuracy: 0.7399\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 1.1532 - accuracy: 0.7063 - val_loss: 1.0193 - val_accuracy: 0.7389\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.1575 - accuracy: 0.7063 - val_loss: 1.0208 - val_accuracy: 0.7392\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1540 - accuracy: 0.7064 - val_loss: 1.0026 - val_accuracy: 0.7392\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.1529 - accuracy: 0.7069 - val_loss: 1.0180 - val_accuracy: 0.7392\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1514 - accuracy: 0.7067 - val_loss: 0.9968 - val_accuracy: 0.7399\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 1.1498 - accuracy: 0.7071 - val_loss: 1.0110 - val_accuracy: 0.7417\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1470 - accuracy: 0.7073 - val_loss: 0.9977 - val_accuracy: 0.7415\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.1452 - accuracy: 0.7074 - val_loss: 1.0066 - val_accuracy: 0.7417\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.1435 - accuracy: 0.7078 - val_loss: 0.9967 - val_accuracy: 0.7420\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1420 - accuracy: 0.7081 - val_loss: 0.9997 - val_accuracy: 0.7417\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.1395 - accuracy: 0.7085 - val_loss: 0.9920 - val_accuracy: 0.7425\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1381 - accuracy: 0.7086 - val_loss: 1.0012 - val_accuracy: 0.7415\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.1383 - accuracy: 0.7089 - val_loss: 0.9937 - val_accuracy: 0.7422\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1350 - accuracy: 0.7091 - val_loss: 0.9941 - val_accuracy: 0.7427\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.1337 - accuracy: 0.7093 - val_loss: 0.9921 - val_accuracy: 0.7420\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.1320 - accuracy: 0.7101 - val_loss: 0.9889 - val_accuracy: 0.7415\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.1308 - accuracy: 0.7099 - val_loss: 0.9850 - val_accuracy: 0.7422\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1291 - accuracy: 0.7104 - val_loss: 0.9932 - val_accuracy: 0.7422\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.1287 - accuracy: 0.7108 - val_loss: 0.9961 - val_accuracy: 0.7405\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.1305 - accuracy: 0.7103 - val_loss: 0.9911 - val_accuracy: 0.7410\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.1256 - accuracy: 0.7108 - val_loss: 0.9773 - val_accuracy: 0.7432\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.1259 - accuracy: 0.7111 - val_loss: 0.9859 - val_accuracy: 0.7437\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1246 - accuracy: 0.7115 - val_loss: 0.9888 - val_accuracy: 0.7432\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.1241 - accuracy: 0.7114 - val_loss: 0.9881 - val_accuracy: 0.7427\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.1242 - accuracy: 0.7124 - val_loss: 0.9871 - val_accuracy: 0.7425\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.1215 - accuracy: 0.7123 - val_loss: 0.9903 - val_accuracy: 0.7420\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.1215 - accuracy: 0.7129 - val_loss: 0.9796 - val_accuracy: 0.7435\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.1175 - accuracy: 0.7134 - val_loss: 0.9733 - val_accuracy: 0.7440\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.1153 - accuracy: 0.7136 - val_loss: 0.9769 - val_accuracy: 0.7460\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1149 - accuracy: 0.7142 - val_loss: 0.9843 - val_accuracy: 0.7442\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.1129 - accuracy: 0.7142 - val_loss: 0.9785 - val_accuracy: 0.7450\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1117 - accuracy: 0.7145 - val_loss: 0.9703 - val_accuracy: 0.7472\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1085 - accuracy: 0.7149 - val_loss: 0.9649 - val_accuracy: 0.7447\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.1117 - accuracy: 0.7145 - val_loss: 0.9667 - val_accuracy: 0.7450\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.1093 - accuracy: 0.7152 - val_loss: 0.9867 - val_accuracy: 0.7445\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.1069 - accuracy: 0.7162 - val_loss: 0.9626 - val_accuracy: 0.7457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3612e2b9d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=100,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsxrmNGaa_p-",
    "outputId": "6642f10c-7a63-420e-ddba-3d37acdf0659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 394ms/step - loss: 1.1057 - accuracy: 0.7160 - val_loss: 0.9645 - val_accuracy: 0.7460\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.1036 - accuracy: 0.7166 - val_loss: 0.9765 - val_accuracy: 0.7462\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.1021 - accuracy: 0.7174 - val_loss: 0.9615 - val_accuracy: 0.7487\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 1.0997 - accuracy: 0.7174 - val_loss: 0.9702 - val_accuracy: 0.7455\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.0990 - accuracy: 0.7170 - val_loss: 0.9556 - val_accuracy: 0.7467\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.0960 - accuracy: 0.7182 - val_loss: 0.9704 - val_accuracy: 0.7475\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0952 - accuracy: 0.7189 - val_loss: 0.9628 - val_accuracy: 0.7482\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.0926 - accuracy: 0.7179 - val_loss: 0.9533 - val_accuracy: 0.7485\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.0898 - accuracy: 0.7189 - val_loss: 0.9595 - val_accuracy: 0.7467\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.0892 - accuracy: 0.7192 - val_loss: 0.9524 - val_accuracy: 0.7472\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.0863 - accuracy: 0.7194 - val_loss: 0.9556 - val_accuracy: 0.7485\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.0853 - accuracy: 0.7197 - val_loss: 0.9575 - val_accuracy: 0.7465\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.0843 - accuracy: 0.7201 - val_loss: 0.9569 - val_accuracy: 0.7487\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 1.0835 - accuracy: 0.7197 - val_loss: 0.9476 - val_accuracy: 0.7490\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.0811 - accuracy: 0.7203 - val_loss: 0.9583 - val_accuracy: 0.7477\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 1.0838 - accuracy: 0.7208 - val_loss: 0.9690 - val_accuracy: 0.7457\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.0873 - accuracy: 0.7194 - val_loss: 0.9434 - val_accuracy: 0.7497\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.0788 - accuracy: 0.7214 - val_loss: 0.9536 - val_accuracy: 0.7472\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.0771 - accuracy: 0.7216 - val_loss: 0.9412 - val_accuracy: 0.7477\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.0744 - accuracy: 0.7216 - val_loss: 0.9445 - val_accuracy: 0.7487\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0722 - accuracy: 0.7225 - val_loss: 0.9432 - val_accuracy: 0.7477\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.0701 - accuracy: 0.7228 - val_loss: 0.9419 - val_accuracy: 0.7503\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0680 - accuracy: 0.7222 - val_loss: 0.9377 - val_accuracy: 0.7487\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0665 - accuracy: 0.7231 - val_loss: 0.9395 - val_accuracy: 0.7492\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.0651 - accuracy: 0.7233 - val_loss: 0.9435 - val_accuracy: 0.7508\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.0742 - accuracy: 0.7228 - val_loss: 0.9871 - val_accuracy: 0.7425\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.1019 - accuracy: 0.7158 - val_loss: 0.9395 - val_accuracy: 0.7475\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.0921 - accuracy: 0.7165 - val_loss: 0.9533 - val_accuracy: 0.7435\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0887 - accuracy: 0.7166 - val_loss: 0.9423 - val_accuracy: 0.7480\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.0840 - accuracy: 0.7172 - val_loss: 0.9477 - val_accuracy: 0.7495\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.0802 - accuracy: 0.7185 - val_loss: 0.9419 - val_accuracy: 0.7485\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0756 - accuracy: 0.7198 - val_loss: 0.9362 - val_accuracy: 0.7497\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.0720 - accuracy: 0.7208 - val_loss: 0.9390 - val_accuracy: 0.7503\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.0688 - accuracy: 0.7215 - val_loss: 0.9332 - val_accuracy: 0.7497\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0664 - accuracy: 0.7221 - val_loss: 0.9315 - val_accuracy: 0.7497\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 1.0639 - accuracy: 0.7225 - val_loss: 0.9280 - val_accuracy: 0.7482\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.0618 - accuracy: 0.7224 - val_loss: 0.9262 - val_accuracy: 0.7503\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0598 - accuracy: 0.7234 - val_loss: 0.9347 - val_accuracy: 0.7508\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.0582 - accuracy: 0.7234 - val_loss: 0.9196 - val_accuracy: 0.7495\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.0592 - accuracy: 0.7234 - val_loss: 0.9217 - val_accuracy: 0.7510\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.0555 - accuracy: 0.7238 - val_loss: 0.9255 - val_accuracy: 0.7510\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 1.0523 - accuracy: 0.7243 - val_loss: 0.9183 - val_accuracy: 0.7520\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0500 - accuracy: 0.7241 - val_loss: 0.9222 - val_accuracy: 0.7513\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0479 - accuracy: 0.7244 - val_loss: 0.9147 - val_accuracy: 0.7508\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.0466 - accuracy: 0.7249 - val_loss: 0.9149 - val_accuracy: 0.7513\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 1.0456 - accuracy: 0.7248 - val_loss: 0.9176 - val_accuracy: 0.7528\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.0436 - accuracy: 0.7252 - val_loss: 0.9126 - val_accuracy: 0.7525\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 1.0409 - accuracy: 0.7254 - val_loss: 0.9089 - val_accuracy: 0.7525\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.0408 - accuracy: 0.7256 - val_loss: 0.9087 - val_accuracy: 0.7530\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 1.0383 - accuracy: 0.7253 - val_loss: 0.9115 - val_accuracy: 0.7540\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 384ms/step - loss: 1.0401 - accuracy: 0.7257 - val_loss: 0.9344 - val_accuracy: 0.7543\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 1.0507 - accuracy: 0.7247 - val_loss: 0.9046 - val_accuracy: 0.7533\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 1.0391 - accuracy: 0.7256 - val_loss: 0.9121 - val_accuracy: 0.7540\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 393ms/step - loss: 1.0374 - accuracy: 0.7260 - val_loss: 0.9068 - val_accuracy: 0.7560\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 1.0361 - accuracy: 0.7254 - val_loss: 0.9078 - val_accuracy: 0.7538\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.0322 - accuracy: 0.7269 - val_loss: 0.9083 - val_accuracy: 0.7535\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 1.0303 - accuracy: 0.7271 - val_loss: 0.9045 - val_accuracy: 0.7513\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.0318 - accuracy: 0.7265 - val_loss: 0.9014 - val_accuracy: 0.7550\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.0284 - accuracy: 0.7270 - val_loss: 0.9016 - val_accuracy: 0.7558\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 1.0254 - accuracy: 0.7272 - val_loss: 0.9033 - val_accuracy: 0.7508\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0243 - accuracy: 0.7272 - val_loss: 0.9051 - val_accuracy: 0.7560\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.0250 - accuracy: 0.7268 - val_loss: 0.8984 - val_accuracy: 0.7508\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.0210 - accuracy: 0.7277 - val_loss: 0.8953 - val_accuracy: 0.7530\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 380ms/step - loss: 1.0186 - accuracy: 0.7282 - val_loss: 0.8973 - val_accuracy: 0.7555\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.0169 - accuracy: 0.7283 - val_loss: 0.9028 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.0255 - accuracy: 0.7263 - val_loss: 0.8930 - val_accuracy: 0.7550\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 1.0219 - accuracy: 0.7273 - val_loss: 0.9110 - val_accuracy: 0.7508\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.0196 - accuracy: 0.7278 - val_loss: 0.8932 - val_accuracy: 0.7535\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0159 - accuracy: 0.7284 - val_loss: 0.8991 - val_accuracy: 0.7548\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 1.0178 - accuracy: 0.7285 - val_loss: 0.9049 - val_accuracy: 0.7553\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0187 - accuracy: 0.7280 - val_loss: 0.8888 - val_accuracy: 0.7530\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0146 - accuracy: 0.7285 - val_loss: 0.8951 - val_accuracy: 0.7535\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0119 - accuracy: 0.7286 - val_loss: 0.8888 - val_accuracy: 0.7538\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 1.0066 - accuracy: 0.7292 - val_loss: 0.8956 - val_accuracy: 0.7528\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 1.0046 - accuracy: 0.7297 - val_loss: 0.8897 - val_accuracy: 0.7550\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0036 - accuracy: 0.7293 - val_loss: 0.8830 - val_accuracy: 0.7530\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 1.0021 - accuracy: 0.7297 - val_loss: 0.8853 - val_accuracy: 0.7520\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.9988 - accuracy: 0.7299 - val_loss: 0.8832 - val_accuracy: 0.7558\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 379ms/step - loss: 0.9983 - accuracy: 0.7302 - val_loss: 0.8836 - val_accuracy: 0.7560\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.9967 - accuracy: 0.7303 - val_loss: 0.8854 - val_accuracy: 0.7518\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.9997 - accuracy: 0.7300 - val_loss: 0.8771 - val_accuracy: 0.7538\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 381ms/step - loss: 0.9944 - accuracy: 0.7303 - val_loss: 0.8817 - val_accuracy: 0.7553\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.9918 - accuracy: 0.7312 - val_loss: 0.8780 - val_accuracy: 0.7573\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.9885 - accuracy: 0.7311 - val_loss: 0.8916 - val_accuracy: 0.7520\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 1.0144 - accuracy: 0.7268 - val_loss: 0.8836 - val_accuracy: 0.7533\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0202 - accuracy: 0.7247 - val_loss: 0.8879 - val_accuracy: 0.7530\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 1.0122 - accuracy: 0.7254 - val_loss: 0.8868 - val_accuracy: 0.7487\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 1.0023 - accuracy: 0.7277 - val_loss: 0.8834 - val_accuracy: 0.7550\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.9998 - accuracy: 0.7293 - val_loss: 0.8868 - val_accuracy: 0.7530\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.9948 - accuracy: 0.7306 - val_loss: 0.8951 - val_accuracy: 0.7508\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.9924 - accuracy: 0.7309 - val_loss: 0.8838 - val_accuracy: 0.7535\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 369ms/step - loss: 0.9894 - accuracy: 0.7308 - val_loss: 0.8803 - val_accuracy: 0.7533\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.9878 - accuracy: 0.7307 - val_loss: 0.8786 - val_accuracy: 0.7515\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 373ms/step - loss: 0.9830 - accuracy: 0.7316 - val_loss: 0.8748 - val_accuracy: 0.7535\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.9799 - accuracy: 0.7322 - val_loss: 0.8824 - val_accuracy: 0.7543\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.9804 - accuracy: 0.7319 - val_loss: 0.8784 - val_accuracy: 0.7545\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.9781 - accuracy: 0.7323 - val_loss: 0.8754 - val_accuracy: 0.7535\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.9733 - accuracy: 0.7325 - val_loss: 0.8747 - val_accuracy: 0.7553\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 376ms/step - loss: 0.9747 - accuracy: 0.7328 - val_loss: 0.8796 - val_accuracy: 0.7563\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 371ms/step - loss: 0.9815 - accuracy: 0.7318 - val_loss: 0.8754 - val_accuracy: 0.7523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f357deb3290>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=100,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "r3wdkXcvbdJY"
   },
   "outputs": [],
   "source": [
    "model.save_weights('model2.h5')\n",
    "x=model.predict(source_padded_docs_test[:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "ZkFtFZ-OjgWY",
    "outputId": "63cdaf77-3434-428a-8137-6cd3a8d59237"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Photo page.          ee e              k            <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "''.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtrY2bc2jjRW",
    "outputId": "e4622a72-bb58-4dfe-b7b7-1a3ff52a20bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108    Photo page. You mean the website. OK, I'll go ...\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REBdZmnWjmUQ",
    "outputId": "e8b07c22-b4b4-482a-cb25-9fc0097e326e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108    Photo page... U mean e website huh... Kk, i'll...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cy8ac7IYc1em",
    "outputId": "d0cb02b2-c415-4c3e-a4b3-c8a0ab7a65a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Photo page... U mean e website huh... Kk, i'll go mail u now...\n",
      "Actual Output: \n",
      "Photo page. You mean the website. OK, I'll go to mail you now.\n",
      "Predicted Output: \n",
      "Photo page.          ee e              k            <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Eh. I'm still at the bus stop... Missed the bus. So i might be later than you\n",
      "Actual Output: \n",
      "I'm still at the bus stop. I missed the bus. So I might be later than you.\n",
      "Predicted Output: \n",
      "Eh   'm  till  t t e     ss p                           i         e  t     <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Tomw depends on wat time si going to meet us lah... If she not so early maybe we meet bugis else meet orchard lor\n",
      "Actual Output: \n",
      "Tomorrow depends on what time Si is going to meet us. If she is not so early, maybe we meet at Bugis, else meet at Orchard.\n",
      "Predicted Output: \n",
      "Tomw depeeds  n              ii                                                    eeee             e ee eeeee <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Ok. I going soon and also send xyan home at the same time. Call u when reaching k.\n",
      "Actual Output: \n",
      "Ok. I am going soon and also send xyan home at the same time. Call you when reaching.\n",
      "Predicted Output: \n",
      "Ok. I ggingg oon  nd also send xyan  ome at the same  ime   allll  wee  eachinn k<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "WHAT NUMBER? MOBILE OR NOT ?\n",
      "Actual Output: \n",
      "What number? Mobile or not?\n",
      "Predicted Output: \n",
      "What n   er    m  e     o <PAD>  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI, R U GAL OR BOY\n",
      "Actual Output: \n",
      "Hi, are you girl or boy?\n",
      "Predicted Output: \n",
      "Hi, R  oo               <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "My painting almost done liao. But my house outside havent start yet. Haiz....\n",
      "Actual Output: \n",
      "My painting is almost done. But my house outside haven't started yet. Sigh.\n",
      "Predicted Output: \n",
      "My painting  lmost  one                 ss   u sss    eee  ttttt <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Fine. Gt posted to SAFTI as a medic\n",
      "Actual Output: \n",
      "Fine. Got posted to SAFTI as a medic.\n",
      "Predicted Output: \n",
      "Fine. G     tte tt                   <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "No la... Not attached... He's always pesterin me, dunno y... Haha, i find him a jerk oso lor...\n",
      "Actual Output: \n",
      "No. Not attached. He's always pestering me, I don't know why. Haha, I find him a jerk also.\n",
      "Predicted Output: \n",
      "No. a.         tt hee                 eeteein                                      <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "WHAT TIME U WRKIN?\n",
      "Actual Output: \n",
      "What time are you working?\n",
      "Predicted Output: \n",
      "What Ti m           <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I thk dun wan da glasses lar... Seldom use it anyway... Save some money... Hee...\n",
      "Actual Output: \n",
      "I think I don't want the glasses. Seldom use it anyway. Save some money. Hee.\n",
      "Predicted Output: \n",
      "I thk   n              ss                                         m  <PAD><PAD><PAD><PAD><PAD><PAD> <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi babe its me thanks for coming even though it didnt go that well!i just wanted my bed! Hope to see you soon love and kisses\n",
      "Actual Output: \n",
      "Hi baby, it's me, thanks for coming, even though it didn't go that well! I just wanted my bed! Hope to see you soon love and kisses.\n",
      "Predicted Output: \n",
      "Hi babe its me ttaa         o      eee    o                 tt                                             ooo o          ss<PAD>s<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hello.... Are you free later for a chat?\n",
      "Actual Output: \n",
      "Hello. Are you free later for a chat?\n",
      "Predicted Output: \n",
      "Hello.             ree    er f r a  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Me very hungry...  come down faster lei...\n",
      "Actual Output: \n",
      "Me very hungry. You come down faster.\n",
      "Predicted Output: \n",
      "Me very  ungry.   u u               <PAD>e<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
      "Actual Output: \n",
      "That's better now, I got a roast down me! I'd be better if I had a few drinks down me too! Good Indian?\n",
      "Predicted Output: \n",
      "Mmm  hatss etter                                                                                              <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yup... I will be going with my hall.\n",
      "Actual Output: \n",
      "Yes. I will be going with my hall.\n",
      "Predicted Output: \n",
      "Yes. I              ng  ii<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh... oh! Thats the wooden one right? the aluminium one cheaper\n",
      "Actual Output: \n",
      "Huh. Oh! That's the wooden one right? The aluminium one is cheaper.\n",
      "Predicted Output: \n",
      "Huh.             t                   ?                     e <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Yupz...Kk...Den i anyhow wear...Vv hot...Haha\n",
      "Actual Output: \n",
      "Yes. Ok. Then I anyhow wear. It's very hot. Haha.\n",
      "Predicted Output: \n",
      "Yes..   k.    n           e      v  <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "So how are you spending yr weekend?\n",
      "Actual Output: \n",
      "So how are you spending your weekend?\n",
      "Predicted Output: \n",
      "So how are you spending yr weekend?<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey....I know its rude of me not to do something abt e fone.N i'm sorry it died on u.\n",
      "Actual Output: \n",
      "Hey, I know it's rude of me not to do something about the phone. And I'm sorry it died on you.\n",
      "Predicted Output: \n",
      "Hey. II                               o      i                          i   iidd    <PAD> <PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=''.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRHARpB8dD1L",
    "outputId": "93c7bb1e-2fe6-4298-b0bf-7c4853cfcc3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1942053406068837, 0, 0, 0.29456425448249246, 0.4924790605054523, 0.4854917717073234, 0.2086130724305753, 0.4428500142691474, 0.3508439695638686, 0.5266403878479265, 0.35782241396102615, 0.31947155212313627, 0.5491004867761125, 0.25650569096216347, 0, 0.2928298013714698, 0.36889397323344053, 0, 0.6431870218238024, 0]\n",
      "The Average Bleu Score is:  0.289174940583241\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if '<' in i:\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3N58Ha1DdJCi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentence_correction_characterlevel_manytomany_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
