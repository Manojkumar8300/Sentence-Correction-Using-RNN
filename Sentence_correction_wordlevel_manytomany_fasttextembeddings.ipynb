{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cxx7myitnx4h",
    "outputId": "e866302f-c2af-4d5a-9048-596cb477918f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n",
      "To: /content/preprocessed_data.csv\n",
      "\r",
      "  0% 0.00/300k [00:00<?, ?B/s]\r",
      "100% 300k/300k [00:00<00:00, 43.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1OurDQUtbWQacvT32HMqFL7vIUrSMllOp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBohsaDGxFEy",
    "outputId": "9491aac1-bb93-4bc3-ec57-b99f48222570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE6GC72uxFLP",
    "outputId": "98c75315-a3ad-4a88-dc73-ec333a229fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fasttext-crawl-300d-2m.zip to /content\n",
      " 99% 1.42G/1.44G [00:22<00:00, 111MB/s] \n",
      "100% 1.44G/1.44G [00:22<00:00, 68.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d yekenot/fasttext-crawl-300d-2m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx2hjm41xFQm",
    "outputId": "5702ce0e-b06a-406f-eb6c-63b61e42d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1545551987 bytes (1474 MiB)\n",
      "\n",
      "Extracting archive: fasttext-crawl-300d-2m.zip\n",
      "--\n",
      "Path = fasttext-crawl-300d-2m.zip\n",
      "Type = zip\n",
      "Physical Size = 1545551987\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% - crawl-300d-2M.vec\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       4516698366\n",
      "Compressed: 1545551987\n"
     ]
    }
   ],
   "source": [
    "!7z e fasttext-crawl-300d-2m.zip -o/content -r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gqplyfv9n1mw"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hldZyWWwxFVV",
    "outputId": "a00c7a68-dafc-4c02-c6bb-cdbca27eb57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fasttext Model\n",
      "Done. 2000000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Reading fast text vectors in python: https://stackoverflow.com/a/38230349/4084039\n",
    "def fasttextModel(gloveFile):\n",
    "    print (\"Loading Fasttext Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}#for storing word and the corresponding embedding vector for that word\n",
    "    for line in f:\n",
    "        splitLine = line.split()#splitting the line and storing it in a list\n",
    "        word = splitLine[0]#getting the first element and storing it in word\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])#obtaining corresponding vector for that word\n",
    "        model[word] = embedding#storing word as key and embedding vector for that word as value\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "model = fasttextModel('/content/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WsavarFgn8Nz"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data.csv')#reading data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "9AWotYpxn-F7",
    "outputId": "8584ac38-b4d1-4263-d8d1-6faccac5c048"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?\\n</td>\n",
       "      <td>Do you want me to reserve seat for you or not?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm thai. what do u do?\\n</td>\n",
       "      <td>I'm Thai. What do you do?\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                             target\n",
       "0           0  ...   Do you want me to reserve seat for you or not?\\n\n",
       "1           1  ...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2           2  ...  They become more expensive already. Mine is li...\n",
       "3           3  ...                        I'm Thai. What do you do?\\n\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)#displaying top 4 datapoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cSbtR_HldLZo"
   },
   "outputs": [],
   "source": [
    "def preprocess(x):#removing last character\n",
    "  x=x[:-1]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKafzf6ToWkC"
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(preprocess)#preprocessing source data\n",
    "df['target']=df['target'].apply(preprocess)#preprocessing target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "xuh4SgNaoYS7",
    "outputId": "f5a3f19c-6067-4e02-f7d9-a3d2d2a85d73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U wan me to \"chop\" seat 4 u nt?</td>\n",
       "      <td>Do you want me to reserve seat for you or not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup. U reaching. We order some durian pastry a...</td>\n",
       "      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They become more ex oredi... Mine is like 25.....</td>\n",
       "      <td>They become more expensive already. Mine is li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm thai. what do u do?</td>\n",
       "      <td>I'm Thai. What do you do?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi! How did your week go? Haven heard from you...</td>\n",
       "      <td>Hi! How did your week go? Haven't heard from y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source                                             target\n",
       "0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n",
       "1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n",
       "2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n",
       "3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n",
       "4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['source','target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZEm82GcoZ3L",
    "outputId": "f05459b8-5e57-40d2-dace-cab35be9313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DJ84ehWAoj8H"
   },
   "outputs": [],
   "source": [
    "df=df[df['source'].apply(len)<170]#removing source sentences of length greater than or equal to 170\n",
    "df=df[df['target'].apply(len)<200]#removing target sentences of length greater than or equal to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H2tW5L9omLr",
    "outputId": "f9a5176a-ab3b-47eb-f4c3-2cf07c3c91a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape#shape of DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fl5VZWaaoqGn",
    "outputId": "94ee1dd8-08e1-480a-c08d-e715c4c4fd2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970,)\n",
      "(20,)\n",
      "(1970,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df['source']\n",
    "y=df['target']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01)#splitting the data in the ratio 99:1\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "u1NbCZg3rpI5"
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_test.to_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbfvxkdGo_lk"
   },
   "source": [
    "Target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSCnXKY2owi5",
    "outputId": "383c48f6-2667-4bed-b319-4a779cd07d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032\n"
     ]
    }
   ],
   "source": [
    "target_tokenizer= Tokenizer()#tokenization on target\n",
    "target_tokenizer.fit_on_texts(y_train)#fitting on ytrain\n",
    "target_vocab_size= len(target_tokenizer.word_index) + 1#target vocab size\n",
    "print(len(target_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gxTYBa17pCtV"
   },
   "outputs": [],
   "source": [
    "target_encoded_docs_train = target_tokenizer.texts_to_sequences(y_train)#converting text to integers\n",
    "target_encoded_docs_test = target_tokenizer.texts_to_sequences(y_test)#converting text to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MhJLucaWpEbZ"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_train = pad_sequences(target_encoded_docs_train,padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VK90pD5pF1n",
    "outputId": "e37105ef-6f41-4c37-c6f7-f487e361ad5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZexKHcNJpHW2"
   },
   "outputs": [],
   "source": [
    "target_padded_docs_test = pad_sequences(target_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzkkdeOspJYS",
    "outputId": "551a8787-2683-4cbf-bd3b-f48320a58d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_padded_docs_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNdQqGlgpNij"
   },
   "source": [
    "Source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9xK62nUpLQX",
    "outputId": "264df537-2b0d-4a4d-d4b6-670d21d7df62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3703\n"
     ]
    }
   ],
   "source": [
    "source_tokenizer= Tokenizer()#tokenization on source\n",
    "source_tokenizer.fit_on_texts(X_train)#fitting to X_train\n",
    "source_vocab_size= len(source_tokenizer.word_index) + 1#source vocab size\n",
    "print(len(source_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YSP7v2ylpQkB"
   },
   "outputs": [],
   "source": [
    "source_encoded_docs_train = source_tokenizer.texts_to_sequences(X_train)#converting text to sequence\n",
    "source_encoded_docs_test = source_tokenizer.texts_to_sequences(X_test)#converting text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Bn9h_emepTUT"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_train = pad_sequences(source_encoded_docs_train,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrJjoty8pU31",
    "outputId": "aeef8608-3152-40fe-d1e8-b4458653be3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 43)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QfLn6qRFpWPY"
   },
   "outputs": [],
   "source": [
    "source_padded_docs_test = pad_sequences(source_encoded_docs_test,maxlen=target_padded_docs_train.shape[1],padding='post')#padding to maxlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jC1CxZ69pXr-",
    "outputId": "146e529a-c3c8-474a-be3f-740423b51a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 43)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_padded_docs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HbleYK91pbP4"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "\n",
    "target_padded_docs_train=target_padded_docs_train.reshape((*target_padded_docs_train.shape,1))\n",
    "target_padded_docs_test=target_padded_docs_test.reshape((*target_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6-DnH2Opc-R",
    "outputId": "6902f66f-3db2-434b-bb79-02978e491fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(target_padded_docs_train.shape)\n",
    "print(target_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4yZxwxPqpfQ6"
   },
   "outputs": [],
   "source": [
    "#we are reshaping the dataset because the sparese_categorical_crossentropy requires data to be three dimensional\n",
    "\n",
    "source_padded_docs_train=source_padded_docs_train.reshape((*source_padded_docs_train.shape,1))\n",
    "source_padded_docs_test=source_padded_docs_test.reshape((*source_padded_docs_test.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zo2683qsphSW",
    "outputId": "6b5ff627-9ec9-4ee7-8fbf-5698ec6d601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1970, 43, 1)\n",
      "(20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "print(source_padded_docs_train.shape)\n",
    "print(source_padded_docs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "j3ho8eL5vPMX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(source_encoded_docs_train).to_csv(\"source_encoded_docs_train.csv\")\n",
    "pd.DataFrame(source_encoded_docs_test).to_csv(\"source_encoded_docs_test.csv\")\n",
    "pd.DataFrame(target_encoded_docs_train).to_csv(\"target_encoded_docs_train.csv\")\n",
    "pd.DataFrame(target_encoded_docs_test).to_csv(\"target_encoded_docs_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "rH-UwBk3xeeA"
   },
   "outputs": [],
   "source": [
    "#creating embedding matrix\n",
    "embedding_matrix = np.zeros((source_vocab_size, 300))\n",
    "for word, i in source_tokenizer.word_index.items():\n",
    "    embedding_vector = model.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hflb_uDoxeuI",
    "outputId": "71f0f85d-48a6-4862-c49c-a3aeccba5d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3704, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex4KJakfpto9"
   },
   "source": [
    "Model1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlt5EKECpo4Z",
    "outputId": "8a47817a-f184-44d3-fb38-4ce291d17bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 43, 300)           1111200   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 43, 128)           219648    \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 43, 3033)          391257    \n",
      "=================================================================\n",
      "Total params: 1,722,105\n",
      "Trainable params: 610,905\n",
      "Non-trainable params: 1,111,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,300,weights=[embedding_matrix],input_length=source_padded_docs_train.shape[1],trainable=False)(input)\n",
    "lstm1=tf.keras.layers.LSTM(128, return_sequences=True)(embed)  \n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(lstm1)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()                                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XT-t_UjdprW2"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl-JYNZhp1Pa",
    "outputId": "5418908c-abbc-40b1-8e6e-e5ca67300ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 14s 542ms/step - loss: 7.9000 - accuracy: 0.3258 - val_loss: 6.3978 - val_accuracy: 0.6814\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 5.9089 - accuracy: 0.6740 - val_loss: 4.0366 - val_accuracy: 0.6814\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 3.5780 - accuracy: 0.6740 - val_loss: 2.5258 - val_accuracy: 0.6814\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 2.7380 - accuracy: 0.6737 - val_loss: 2.9426 - val_accuracy: 0.6814\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 3.0946 - accuracy: 0.6737 - val_loss: 2.9639 - val_accuracy: 0.6814\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 3.0431 - accuracy: 0.6737 - val_loss: 2.7388 - val_accuracy: 0.6814\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 2.7995 - accuracy: 0.6737 - val_loss: 2.5578 - val_accuracy: 0.6814\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.6768 - accuracy: 0.6740 - val_loss: 2.5907 - val_accuracy: 0.6837\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 2.7035 - accuracy: 0.6759 - val_loss: 2.5467 - val_accuracy: 0.6837\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 2.6301 - accuracy: 0.6757 - val_loss: 2.4369 - val_accuracy: 0.6837\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 2.5237 - accuracy: 0.6756 - val_loss: 2.3866 - val_accuracy: 0.6872\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 2.4805 - accuracy: 0.6766 - val_loss: 2.3524 - val_accuracy: 0.6872\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 2.4363 - accuracy: 0.6766 - val_loss: 2.2853 - val_accuracy: 0.6872\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.3663 - accuracy: 0.6768 - val_loss: 2.2185 - val_accuracy: 0.6884\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 2.3002 - accuracy: 0.6784 - val_loss: 2.1702 - val_accuracy: 0.6884\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 2.2507 - accuracy: 0.6789 - val_loss: 2.1286 - val_accuracy: 0.6907\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.2092 - accuracy: 0.6787 - val_loss: 2.0997 - val_accuracy: 0.6884\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 2.1720 - accuracy: 0.6786 - val_loss: 2.0669 - val_accuracy: 0.6895\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.1344 - accuracy: 0.6805 - val_loss: 2.0358 - val_accuracy: 0.6919\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 2.1012 - accuracy: 0.6821 - val_loss: 2.0027 - val_accuracy: 0.6919\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 2.0770 - accuracy: 0.6873 - val_loss: 1.9834 - val_accuracy: 0.6942\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.0548 - accuracy: 0.6903 - val_loss: 1.9644 - val_accuracy: 0.6919\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 2.0354 - accuracy: 0.6911 - val_loss: 1.9430 - val_accuracy: 0.6942\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 2.0174 - accuracy: 0.6918 - val_loss: 1.9276 - val_accuracy: 0.6953\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 2.0004 - accuracy: 0.6918 - val_loss: 1.9112 - val_accuracy: 0.6930\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.9818 - accuracy: 0.6919 - val_loss: 1.8940 - val_accuracy: 0.6942\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.9616 - accuracy: 0.6928 - val_loss: 1.8747 - val_accuracy: 0.6977\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.9408 - accuracy: 0.6949 - val_loss: 1.8585 - val_accuracy: 0.7023\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.9196 - accuracy: 0.6978 - val_loss: 1.8417 - val_accuracy: 0.7035\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.8981 - accuracy: 0.6991 - val_loss: 1.8260 - val_accuracy: 0.7047\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.8762 - accuracy: 0.7004 - val_loss: 1.8115 - val_accuracy: 0.7058\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.8564 - accuracy: 0.7016 - val_loss: 1.7919 - val_accuracy: 0.7070\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 1.8339 - accuracy: 0.7040 - val_loss: 1.7763 - val_accuracy: 0.7128\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.8128 - accuracy: 0.7064 - val_loss: 1.7558 - val_accuracy: 0.7105\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.7905 - accuracy: 0.7083 - val_loss: 1.7424 - val_accuracy: 0.7174\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.7671 - accuracy: 0.7118 - val_loss: 1.7254 - val_accuracy: 0.7221\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.7449 - accuracy: 0.7155 - val_loss: 1.7112 - val_accuracy: 0.7279\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.7216 - accuracy: 0.7208 - val_loss: 1.6903 - val_accuracy: 0.7267\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.6983 - accuracy: 0.7233 - val_loss: 1.6748 - val_accuracy: 0.7302\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.6742 - accuracy: 0.7264 - val_loss: 1.6576 - val_accuracy: 0.7314\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.6527 - accuracy: 0.7293 - val_loss: 1.6454 - val_accuracy: 0.7372\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 1.6293 - accuracy: 0.7323 - val_loss: 1.6332 - val_accuracy: 0.7395\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.6061 - accuracy: 0.7346 - val_loss: 1.6162 - val_accuracy: 0.7407\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.5830 - accuracy: 0.7381 - val_loss: 1.5977 - val_accuracy: 0.7407\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.5606 - accuracy: 0.7406 - val_loss: 1.5836 - val_accuracy: 0.7488\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.5388 - accuracy: 0.7446 - val_loss: 1.5693 - val_accuracy: 0.7512\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.5173 - accuracy: 0.7468 - val_loss: 1.5512 - val_accuracy: 0.7488\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.4945 - accuracy: 0.7496 - val_loss: 1.5388 - val_accuracy: 0.7512\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 1.4740 - accuracy: 0.7514 - val_loss: 1.5251 - val_accuracy: 0.7523\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.4522 - accuracy: 0.7538 - val_loss: 1.5122 - val_accuracy: 0.7535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdd62ee5c90>"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V846HOJzzZPQ",
    "outputId": "40e5283e-de8c-416c-d91f-541ab7d15494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 1.4318 - accuracy: 0.7570 - val_loss: 1.5012 - val_accuracy: 0.7558\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.4119 - accuracy: 0.7588 - val_loss: 1.4879 - val_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.3912 - accuracy: 0.7616 - val_loss: 1.4809 - val_accuracy: 0.7570\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.3718 - accuracy: 0.7639 - val_loss: 1.4719 - val_accuracy: 0.7593\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.3536 - accuracy: 0.7662 - val_loss: 1.4642 - val_accuracy: 0.7640\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.3356 - accuracy: 0.7684 - val_loss: 1.4547 - val_accuracy: 0.7640\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.3175 - accuracy: 0.7714 - val_loss: 1.4461 - val_accuracy: 0.7663\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.3049 - accuracy: 0.7743 - val_loss: 1.4354 - val_accuracy: 0.7709\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.2862 - accuracy: 0.7749 - val_loss: 1.4347 - val_accuracy: 0.7698\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.2666 - accuracy: 0.7775 - val_loss: 1.4219 - val_accuracy: 0.7756\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.2512 - accuracy: 0.7798 - val_loss: 1.4201 - val_accuracy: 0.7767\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.2332 - accuracy: 0.7818 - val_loss: 1.4153 - val_accuracy: 0.7837\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.2179 - accuracy: 0.7837 - val_loss: 1.4051 - val_accuracy: 0.7826\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.2040 - accuracy: 0.7852 - val_loss: 1.4050 - val_accuracy: 0.7814\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.1877 - accuracy: 0.7877 - val_loss: 1.4030 - val_accuracy: 0.7767\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 1.1736 - accuracy: 0.7891 - val_loss: 1.3962 - val_accuracy: 0.7814\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.1605 - accuracy: 0.7903 - val_loss: 1.3934 - val_accuracy: 0.7826\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.1446 - accuracy: 0.7924 - val_loss: 1.3894 - val_accuracy: 0.7826\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.1321 - accuracy: 0.7928 - val_loss: 1.3856 - val_accuracy: 0.7849\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.1188 - accuracy: 0.7956 - val_loss: 1.3801 - val_accuracy: 0.7860\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.1059 - accuracy: 0.7968 - val_loss: 1.3851 - val_accuracy: 0.7837\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.0959 - accuracy: 0.7984 - val_loss: 1.3745 - val_accuracy: 0.7849\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0825 - accuracy: 0.7997 - val_loss: 1.3753 - val_accuracy: 0.7884\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 1.0683 - accuracy: 0.8015 - val_loss: 1.3692 - val_accuracy: 0.7872\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 1.0570 - accuracy: 0.8034 - val_loss: 1.3686 - val_accuracy: 0.7860\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0461 - accuracy: 0.8049 - val_loss: 1.3703 - val_accuracy: 0.7837\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.0450 - accuracy: 0.8061 - val_loss: 1.3621 - val_accuracy: 0.7802\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 1.0258 - accuracy: 0.8076 - val_loss: 1.3689 - val_accuracy: 0.7919\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 1.0154 - accuracy: 0.8103 - val_loss: 1.3576 - val_accuracy: 0.7860\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 1.0025 - accuracy: 0.8114 - val_loss: 1.3580 - val_accuracy: 0.7872\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.9906 - accuracy: 0.8136 - val_loss: 1.3545 - val_accuracy: 0.7907\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.9804 - accuracy: 0.8150 - val_loss: 1.3499 - val_accuracy: 0.7860\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.9708 - accuracy: 0.8167 - val_loss: 1.3459 - val_accuracy: 0.7860\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.9604 - accuracy: 0.8180 - val_loss: 1.3474 - val_accuracy: 0.7884\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.9490 - accuracy: 0.8195 - val_loss: 1.3437 - val_accuracy: 0.7895\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.9391 - accuracy: 0.8212 - val_loss: 1.3473 - val_accuracy: 0.7895\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.9304 - accuracy: 0.8224 - val_loss: 1.3405 - val_accuracy: 0.7919\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.9220 - accuracy: 0.8235 - val_loss: 1.3635 - val_accuracy: 0.7953\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.9493 - accuracy: 0.8205 - val_loss: 1.3883 - val_accuracy: 0.7965\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.9714 - accuracy: 0.8195 - val_loss: 1.3331 - val_accuracy: 0.7895\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.9365 - accuracy: 0.8226 - val_loss: 1.3686 - val_accuracy: 0.7907\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.9257 - accuracy: 0.8251 - val_loss: 1.3489 - val_accuracy: 0.7895\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.9110 - accuracy: 0.8265 - val_loss: 1.3295 - val_accuracy: 0.7953\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.9032 - accuracy: 0.8268 - val_loss: 1.3496 - val_accuracy: 0.7907\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.8888 - accuracy: 0.8298 - val_loss: 1.3387 - val_accuracy: 0.7907\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.8783 - accuracy: 0.8308 - val_loss: 1.3274 - val_accuracy: 0.7942\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.8699 - accuracy: 0.8318 - val_loss: 1.3279 - val_accuracy: 0.7907\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.8574 - accuracy: 0.8326 - val_loss: 1.3367 - val_accuracy: 0.7895\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.8501 - accuracy: 0.8332 - val_loss: 1.3306 - val_accuracy: 0.7919\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.8399 - accuracy: 0.8357 - val_loss: 1.3322 - val_accuracy: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdd62b6e990>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "YiFHeHQ0p2-H"
   },
   "outputs": [],
   "source": [
    "x=model.predict(source_padded_docs_test[:1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "kLpjZU_jqXpa",
    "outputId": "2bdec40c-2242-4e6f-b24f-c4094bad5d0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'hey i am still having breakfast <PAD> if you reach there first can help love and me want 12 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://machinelearningmastery.com\n",
    "\n",
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "\n",
    "' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sGCpWeiqdWm",
    "outputId": "d7c2e7c9-ff15-485d-b44b-b8a78d1cd18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866    I am still having breakfast. If you reach ther...\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skB3G_F2qfP_",
    "outputId": "6b10b3e9-939b-4afd-836a-2344cc33cd06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866    Hey i am still having breakfast eh. If you rea...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikH9dtb8sw5C",
    "outputId": "796c3178-7a25-469b-d469-6bee0264ec52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey i am still having breakfast eh. If you reach there first can help rebecca and me chope seats?\n",
      "Actual Output: \n",
      "I am still having breakfast. If you reach there first can you help me and Rebecca reserve seats?\n",
      "Predicted Output: \n",
      "hey i am still having breakfast if you reach there first can help love and me want 12\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh  take then how i take bus later... Inside got money a not...\n",
      "Actual Output: \n",
      "If you take then how I take bus later? Inside got money or not?\n",
      "Predicted Output: \n",
      "huh you take then how i take bus later then out have a not\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi neva worry bout da truth coz the truth will lead me 2 ur heart. It's the least a unique person like u deserve. Sleep tight or morning\n",
      "Actual Output: \n",
      "Hi, never worry about the truth because the truth will lead me to your heart. It's the least that a unique person like you deserve. Sleep tight or morning.\n",
      "Predicted Output: \n",
      "hi never worry about the because the will me for your your it's the is a exciting person like you you sleep have one another\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Take so long\n",
      "Actual Output: \n",
      "Take so long.\n",
      "Predicted Output: \n",
      "take so long\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey where r  im here liao\n",
      "Actual Output: \n",
      "Hey, where are you? I'm here.\n",
      "Predicted Output: \n",
      "hey where are you i'm here\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi everyone hows ur day ?\n",
      "Actual Output: \n",
      "Hi everyone, how's your day?\n",
      "Predicted Output: \n",
      "hi everyone how's your day\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha- if no need make up  near my wkplace  not wk too late.can consider.tt is if  can find such a place.ay,abt a mth ago she say she wk ere la. Hee-\n",
      "Actual Output: \n",
      "Haha. If no need to make up and near my workplace and does not work too late. Can consider. That is if you can find such a place. AY, about a month ago, she said she worked there.\n",
      "Predicted Output: \n",
      "haha if no need make up and near my and not week too late free you that is if you can find a this this good a a a very very she very sleep but hehe\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How i noe... Last time tis one is on offer wat...\n",
      "Actual Output: \n",
      "How I know. Last time this one is on offer.\n",
      "Predicted Output: \n",
      "how i know the time this time is is only what\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I reached already\n",
      "Actual Output: \n",
      "I reached already.\n",
      "Predicted Output: \n",
      "i reached already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haiyoh... It was so crowded... We didnt buy anything... Haha... Lots of pple in town. So mon we go facial with  then go shopping?\n",
      "Actual Output: \n",
      "Ouch. It was so crowded. We didn't buy anything. Haha. There are lots of people in town. So Monday we go facial with you then go shopping?\n",
      "Predicted Output: \n",
      "violyn it was so crowded we didn't buy anything haha good of people in town so monday we go with you then go go\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI MERINA NICE 2 CHAT WITH U. UR HP NO PLS. WHAT IS UR RACE?\n",
      "Actual Output: \n",
      "Hi Merina. It's nice to chat with you. Your hand phone number please. What is your race?\n",
      "Predicted Output: \n",
      "hi dom nice to chat with you your your number please what is your your\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... After my drivin den free lor... Y?\n",
      "Actual Output: \n",
      "After my driving then I will be free. Why?\n",
      "Predicted Output: \n",
      "hmm after my driving then free why\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Erm anything lor...Can bring tmr? Thx =)\n",
      "Actual Output: \n",
      "Can anything be brought tomorrow? Thanks.\n",
      "Predicted Output: \n",
      "no anything i can bring tomorrow thanks\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Okay... they arent open on public holidays\n",
      "Actual Output: \n",
      "Okay. They aren't open on public holidays.\n",
      "Predicted Output: \n",
      "ok they aren't open on\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... I'm carrying a broom with me so really paiseh to walk into lecture with it. I'm coming straight from home mah... Cya later then.\n",
      "Actual Output: \n",
      "Haha. I'm carrying a broom with me. So I'm really sorry to walk into lecture with it. I'm coming straight from home. See you later then.\n",
      "Predicted Output: \n",
      "haha i'm a a me so really embarrassing to to into lecture with it off from home later later\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... I'm watchin w my frens oredi... Paiseh...\n",
      "Actual Output: \n",
      "Hmm. I'm watching with my friends already. It's embarrassing.\n",
      "Predicted Output: \n",
      "hmm i'm watching with my friends already haha\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey...  've got driving today? my driving at 240.\n",
      "Actual Output: \n",
      "Hey. You have got driving today? My driving is at 2:40.\n",
      "Predicted Output: \n",
      "hey you got driving today my driving at 15 17\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "then it can moisturise our skin. and rub in circular motion. u wash face, tone,then put a bit of jelly and cream onto ur hand,and tap it on your face,\n",
      "Actual Output: \n",
      "Then it can moisturise our skin and rub in circular motion. You wash face, tone, then put a bit of jelly and cream onto your hand, and tap it on your face.\n",
      "Predicted Output: \n",
      "then it can our skin and in you and and then then a bit of and and your and it on your eyes\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I'm pubbin now, gee, cant go online...After my drivin ah, hmmm, den where ur meetin....\n",
      "Actual Output: \n",
      "I'm in pub now. I can't go online. After my driving, then where are you meeting?\n",
      "Predicted Output: \n",
      "violyn i'm now why can't go go after my driving i i then where you are\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... Not accurate right....\n",
      "Actual Output: \n",
      "Haha. Not accurate, right?\n",
      "Predicted Output: \n",
      "haha not right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OsqiQqLEtCnU",
    "outputId": "a3fe088c-9d41-476c-a263-b71dbb567a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2911892337378932, 0.21142141714303078, 0.14463972129203845, 0.7598356856515925, 0.5081327481546147, 0.5623413251903491, 0.21662732770853732, 0.4063798282013443, 0.7598356856515925, 0.16504659724801518, 0.17795291340072017, 0.30895757752065417, 0.6147881529512643, 0.3769486629893372, 0.1584557519176515, 0.3050975216056289, 0.41545589177443254, 0.28513533990048395, 0.4914498405430853, 0]\n",
      "The Average Bleu Score is:  0.35798456112911325\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1tc_fxeuI6I"
   },
   "source": [
    "Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjUr0ohmqi8p",
    "outputId": "4fc6be67-068e-4b24-98eb-0e39ae5c9e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 43)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 43, 300)           1111200   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 43, 256)           439296    \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 43, 3033)          779481    \n",
      "=================================================================\n",
      "Total params: 2,329,977\n",
      "Trainable params: 1,218,777\n",
      "Non-trainable params: 1,111,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input=tf.keras.layers.Input(shape=(43,))\n",
    "embed=tf.keras.layers.Embedding(source_vocab_size,300,weights=[embedding_matrix],input_length=source_padded_docs_train.shape[1],trainable=False)(input)\n",
    "lstm1=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embed)  \n",
    "output=tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(target_vocab_size, activation='softmax'))(lstm1)\n",
    "model=tf.keras.models.Model(inputs=input,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "iXpqxfOhuNTz"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4g-6RMYuP_H",
    "outputId": "71bc89f7-aeea-45be-a500-be7c4b8303c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 3s 849ms/step - loss: 7.9556 - accuracy: 0.3262 - val_loss: 6.6151 - val_accuracy: 0.6907\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 5.7774 - accuracy: 0.6827 - val_loss: 3.0524 - val_accuracy: 0.6814\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 3.1042 - accuracy: 0.6737 - val_loss: 3.1649 - val_accuracy: 0.6814\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 3.2320 - accuracy: 0.6737 - val_loss: 2.7467 - val_accuracy: 0.6814\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 2.7685 - accuracy: 0.6747 - val_loss: 2.4998 - val_accuracy: 0.6837\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 240ms/step - loss: 2.6061 - accuracy: 0.6786 - val_loss: 2.3973 - val_accuracy: 0.6895\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 2.4415 - accuracy: 0.6799 - val_loss: 2.2410 - val_accuracy: 0.6895\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 2.3152 - accuracy: 0.6780 - val_loss: 2.1987 - val_accuracy: 0.6907\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 245ms/step - loss: 2.2456 - accuracy: 0.6825 - val_loss: 2.0994 - val_accuracy: 0.6953\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 2.1551 - accuracy: 0.6886 - val_loss: 2.0266 - val_accuracy: 0.6942\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 2.0836 - accuracy: 0.6907 - val_loss: 1.9746 - val_accuracy: 0.6953\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 2.0330 - accuracy: 0.6924 - val_loss: 1.9445 - val_accuracy: 0.6953\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 2.0021 - accuracy: 0.6946 - val_loss: 1.9227 - val_accuracy: 0.6988\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.9777 - accuracy: 0.6968 - val_loss: 1.8978 - val_accuracy: 0.6965\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.9512 - accuracy: 0.6977 - val_loss: 1.8775 - val_accuracy: 0.6965\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.9257 - accuracy: 0.6984 - val_loss: 1.8562 - val_accuracy: 0.6977\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.8984 - accuracy: 0.6995 - val_loss: 1.8364 - val_accuracy: 0.7012\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.8719 - accuracy: 0.7014 - val_loss: 1.8179 - val_accuracy: 0.7058\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 255ms/step - loss: 1.8448 - accuracy: 0.7038 - val_loss: 1.7973 - val_accuracy: 0.7116\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.8165 - accuracy: 0.7067 - val_loss: 1.7767 - val_accuracy: 0.7140\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.7868 - accuracy: 0.7098 - val_loss: 1.7547 - val_accuracy: 0.7163\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 1.7564 - accuracy: 0.7134 - val_loss: 1.7322 - val_accuracy: 0.7233\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.7239 - accuracy: 0.7176 - val_loss: 1.7102 - val_accuracy: 0.7291\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 248ms/step - loss: 1.6907 - accuracy: 0.7226 - val_loss: 1.6875 - val_accuracy: 0.7360\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.6557 - accuracy: 0.7277 - val_loss: 1.6653 - val_accuracy: 0.7395\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.6198 - accuracy: 0.7327 - val_loss: 1.6416 - val_accuracy: 0.7442\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.5834 - accuracy: 0.7383 - val_loss: 1.6168 - val_accuracy: 0.7419\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.5469 - accuracy: 0.7431 - val_loss: 1.5945 - val_accuracy: 0.7453\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.5101 - accuracy: 0.7476 - val_loss: 1.5752 - val_accuracy: 0.7535\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.4734 - accuracy: 0.7526 - val_loss: 1.5530 - val_accuracy: 0.7570\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.4366 - accuracy: 0.7575 - val_loss: 1.5287 - val_accuracy: 0.7605\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 251ms/step - loss: 1.4002 - accuracy: 0.7624 - val_loss: 1.5085 - val_accuracy: 0.7651\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 249ms/step - loss: 1.3639 - accuracy: 0.7669 - val_loss: 1.4891 - val_accuracy: 0.7698\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.3284 - accuracy: 0.7717 - val_loss: 1.4709 - val_accuracy: 0.7744\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 254ms/step - loss: 1.2938 - accuracy: 0.7771 - val_loss: 1.4579 - val_accuracy: 0.7744\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 250ms/step - loss: 1.2605 - accuracy: 0.7818 - val_loss: 1.4413 - val_accuracy: 0.7802\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.2287 - accuracy: 0.7859 - val_loss: 1.4324 - val_accuracy: 0.7837\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.1971 - accuracy: 0.7907 - val_loss: 1.4179 - val_accuracy: 0.7849\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 252ms/step - loss: 1.1672 - accuracy: 0.7946 - val_loss: 1.4094 - val_accuracy: 0.7872\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 1.1382 - accuracy: 0.7996 - val_loss: 1.3959 - val_accuracy: 0.7884\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 247ms/step - loss: 1.1106 - accuracy: 0.8030 - val_loss: 1.3886 - val_accuracy: 0.7907\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 256ms/step - loss: 1.0839 - accuracy: 0.8079 - val_loss: 1.3777 - val_accuracy: 0.7872\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 251ms/step - loss: 1.0590 - accuracy: 0.8113 - val_loss: 1.3712 - val_accuracy: 0.7860\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 1.0351 - accuracy: 0.8151 - val_loss: 1.3662 - val_accuracy: 0.7872\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 254ms/step - loss: 1.0116 - accuracy: 0.8187 - val_loss: 1.3628 - val_accuracy: 0.7872\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 0.9898 - accuracy: 0.8212 - val_loss: 1.3549 - val_accuracy: 0.7884\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 256ms/step - loss: 0.9694 - accuracy: 0.8238 - val_loss: 1.3513 - val_accuracy: 0.7884\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 255ms/step - loss: 0.9498 - accuracy: 0.8262 - val_loss: 1.3483 - val_accuracy: 0.7919\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 0.9304 - accuracy: 0.8280 - val_loss: 1.3375 - val_accuracy: 0.7919\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 0.9133 - accuracy: 0.8294 - val_loss: 1.3405 - val_accuracy: 0.7942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdd575f1dd0>"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(source_padded_docs_train,target_padded_docs_train,batch_size=1024,epochs=50,\n",
    "          validation_data=(source_padded_docs_test,target_padded_docs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "8VE32KpbuR-2"
   },
   "outputs": [],
   "source": [
    "x=model.predict(source_padded_docs_test[7:8])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "T373_iPAuVgd",
    "outputId": "9105be06-1ed0-46c6-dce6-93fba362947f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'how i know i time this one is on <PAD> what <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "index_to_words[0] = '<PAD>'\n",
    "\n",
    "' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVToi8w8uXmD",
    "outputId": "f0323c6b-96e9-4c6b-c8e5-6f11d8f8511f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128    How I know. Last time this one is on offer.\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y_test[7:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCJBUmaiuaBc",
    "outputId": "074cc6eb-a461-403d-92b0-6f453e79e601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    How i noe... Last time tis one is on offer wat...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps4y3XayuccE",
    "outputId": "a8c11ee2-a50b-4d9f-bf17-f0bc311459f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "Hey i am still having breakfast eh. If you reach there first can help rebecca and me chope seats?\n",
      "Actual Output: \n",
      "I am still having breakfast. If you reach there first can you help me and Rebecca reserve seats?\n",
      "Predicted Output: \n",
      "hey i am still having day i if you reach there the can help michelle and me buy\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Huh  take then how i take bus later... Inside got money a not...\n",
      "Actual Output: \n",
      "If you take then how I take bus later? Inside got money or not?\n",
      "Predicted Output: \n",
      "huh you you then how i take bus later and got money a not\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi neva worry bout da truth coz the truth will lead me 2 ur heart. It's the least a unique person like u deserve. Sleep tight or morning\n",
      "Actual Output: \n",
      "Hi, never worry about the truth because the truth will lead me to your heart. It's the least that a unique person like you deserve. Sleep tight or morning.\n",
      "Predicted Output: \n",
      "hi never worry about the because the will me for your heart it's the one a a person like you you sleep good or morning\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Take so long\n",
      "Actual Output: \n",
      "Take so long.\n",
      "Predicted Output: \n",
      "take so long\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey where r  im here liao\n",
      "Actual Output: \n",
      "Hey, where are you? I'm here.\n",
      "Predicted Output: \n",
      "hey where are you i'm here\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hi everyone hows ur day ?\n",
      "Actual Output: \n",
      "Hi everyone, how's your day?\n",
      "Predicted Output: \n",
      "hi everyone how's your day\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha- if no need make up  near my wkplace  not wk too late.can consider.tt is if  can find such a place.ay,abt a mth ago she say she wk ere la. Hee-\n",
      "Actual Output: \n",
      "Haha. If no need to make up and near my workplace and does not work too late. Can consider. That is if you can find such a place. AY, about a month ago, she said she worked there.\n",
      "Predicted Output: \n",
      "haha if no need make up and near my and not month so late can i that is if you can find a place you about a month ago she says she good not hee\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "How i noe... Last time tis one is on offer wat...\n",
      "Actual Output: \n",
      "How I know. Last time this one is on offer.\n",
      "Predicted Output: \n",
      "how i know i time this one is on what\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I reached already\n",
      "Actual Output: \n",
      "I reached already.\n",
      "Predicted Output: \n",
      "i reached already\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haiyoh... It was so crowded... We didnt buy anything... Haha... Lots of pple in town. So mon we go facial with  then go shopping?\n",
      "Actual Output: \n",
      "Ouch. It was so crowded. We didn't buy anything. Haha. There are lots of people in town. So Monday we go facial with you then go shopping?\n",
      "Predicted Output: \n",
      "yes it was so crowded we didn't buy anything haha of of people in town so so we go and you then go shopping\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "HI MERINA NICE 2 CHAT WITH U. UR HP NO PLS. WHAT IS UR RACE?\n",
      "Actual Output: \n",
      "Hi Merina. It's nice to chat with you. Your hand phone number please. What is your race?\n",
      "Predicted Output: \n",
      "hi merina nice to chat with you your hand number please what is your\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... After my drivin den free lor... Y?\n",
      "Actual Output: \n",
      "After my driving then I will be free. Why?\n",
      "Predicted Output: \n",
      "hmm after my driving then free why\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Erm anything lor...Can bring tmr? Thx =)\n",
      "Actual Output: \n",
      "Can anything be brought tomorrow? Thanks.\n",
      "Predicted Output: \n",
      "er anything you can bring tomorrow thanks\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Okay... they arent open on public holidays\n",
      "Actual Output: \n",
      "Okay. They aren't open on public holidays.\n",
      "Predicted Output: \n",
      "ok they aren't open on\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... I'm carrying a broom with me so really paiseh to walk into lecture with it. I'm coming straight from home mah... Cya later then.\n",
      "Actual Output: \n",
      "Haha. I'm carrying a broom with me. So I'm really sorry to walk into lecture with it. I'm coming straight from home. See you later then.\n",
      "Predicted Output: \n",
      "haha i'm a with me so really to to walk in lecture for this coming on from home my tomorrow later then\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hmmm.... I'm watchin w my frens oredi... Paiseh...\n",
      "Actual Output: \n",
      "Hmm. I'm watching with my friends already. It's embarrassing.\n",
      "Predicted Output: \n",
      "hmm i'm watching with my friend already embarrassing\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Hey...  've got driving today? my driving at 240.\n",
      "Actual Output: \n",
      "Hey. You have got driving today? My driving is at 2:40.\n",
      "Predicted Output: \n",
      "hey you got driving today my driving at total\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "then it can moisturise our skin. and rub in circular motion. u wash face, tone,then put a bit of jelly and cream onto ur hand,and tap it on your face,\n",
      "Actual Output: \n",
      "Then it can moisturise our skin and rub in circular motion. You wash face, tone, then put a bit of jelly and cream onto your hand, and tap it on your face.\n",
      "Predicted Output: \n",
      "then it can our skin and and you to and then the a a of the the your the and the on your\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "I'm pubbin now, gee, cant go online...After my drivin ah, hmmm, den where ur meetin....\n",
      "Actual Output: \n",
      "I'm in pub now. I can't go online. After my driving, then where are you meeting?\n",
      "Predicted Output: \n",
      "yes yes now i can't go in after my driving my i then where your to\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Input text: \n",
      "Haha... Not accurate right....\n",
      "Actual Output: \n",
      "Haha. Not accurate, right?\n",
      "Predicted Output: \n",
      "haha not right\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "def prediction(x):\n",
    "\n",
    "  index_to_words = {id: word for word, id in target_tokenizer.word_index.items()}\n",
    "  index_to_words[0] = '<PAD>'\n",
    "\n",
    "  y=' '.join([index_to_words[prediction] for prediction in np.argmax(x, 1)])\n",
    "  return y\n",
    "for i in range(20):\n",
    "  print(\"Input text: \")\n",
    "  a=list(X_test[i:i+1])\n",
    "  print(a[0])\n",
    "\n",
    "  print(\"Actual Output: \")\n",
    "  b=list(y_test[i:i+1])\n",
    "  print(b[0])\n",
    "\n",
    "  print(\"Predicted Output: \")\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  print(' '.join(y_lst))\n",
    "  print('>'*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HTs2bpuv50q",
    "outputId": "162c459c-0815-42a5-ad82-457d0afcac50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3575297164449809, 0.5828233954152654, 0.14715613818513176, 0.7598356856515925, 0.5081327481546147, 0.5623413251903491, 0.2428662778132657, 0.392814650900513, 0.7598356856515925, 0.3026565453571514, 0.18336673852940621, 0.30895757752065417, 0.6147881529512643, 0.3769486629893372, 0.3114852603245108, 0.32260135189272865, 0.38875142041440197, 0.1788409894677479, 0.4728708045015879, 0]\n",
      "The Average Bleu Score is:  0.3887301563678047\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "bleu_score=[]\n",
    "for i in range(20):\n",
    "  b=list(y_test[i:i+1])\n",
    "  x=model.predict(source_padded_docs_test[i:i+1])\n",
    "  y=prediction(x[0])\n",
    "  y=y.split(' ')\n",
    "  y_lst=[]\n",
    "  for i in y:\n",
    "    if i=='<PAD>':\n",
    "      continue\n",
    "    else:\n",
    "      y_lst.append(i)\n",
    "  bleu_score.append(bleu.sentence_bleu([b[0].split(),],y_lst))\n",
    "print(bleu_score)\n",
    "print(\"The Average Bleu Score is: \",sum(bleu_score)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IZlJ5yUv8cF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sentence_correction_wordlevel_manytomany_fasttextembeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
